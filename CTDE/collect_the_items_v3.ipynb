{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the items - discrete actions\n",
    "\n",
    "in order to be able to use rllib's DQN is necessary to implement a new version of the environment in which actions are discrete instead of continuous. \n",
    "\n",
    "Still the agents' goal is the same as before: collecting all the items in the environment minimizing the number of steps by collaborating together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vectors import Vector2D\n",
    "from utils.canvas import CanvasWithBorders\n",
    "from utils.algo_utils import (save_algo, load_algo)\n",
    "from utils.metrics import (save_dict_as_json, load_json_as_dict)\n",
    "from utils.simulations import (simulate_episode, simulate_random_episode, dqn_result_format)\n",
    "\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiDiscrete\n",
    "from gymnasium.spaces.utils import flatten, flatten_space\n",
    "from IPython.display import clear_output\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "from typing import Set\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentConfiguration: \n",
    "    def __init__(self, n_agents, n_targets, agent_range, movement_granularity, speed_granularity, spawn_area=100, visible_nbrs=1, visible_targets=1, max_steps=None, cache_size=1):\n",
    "        # parameters that shouldn't affect the agents' behaviour\n",
    "        self.n_agents = n_agents\n",
    "        self.n_targets = n_targets\n",
    "        self.spawn_area = spawn_area\n",
    "        self.max_steps = max_steps\n",
    "        # parameters that affect the agents' behavious\n",
    "        self.agent_range = agent_range\n",
    "        # parameters that affect the observation space\n",
    "        self.visible_nbrs = visible_nbrs\n",
    "        self.visible_targets = visible_targets\n",
    "        self.cache_size = cache_size\n",
    "        # parameters that affect the action space\n",
    "        self.movement_granularity = movement_granularity\n",
    "        self.speed_granularity = speed_granularity\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        return EnvironmentConfiguration(\n",
    "            self.n_agents, \n",
    "            self.n_targets, \n",
    "            self.agent_range, \n",
    "            self.movement_granularity, \n",
    "            self.speed_granularity, \n",
    "            self.spawn_area, \n",
    "            self.visible_nbrs, \n",
    "            self.visible_targets, \n",
    "            self.max_steps, \n",
    "            self.cache_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectTheItems(MultiAgentEnv):\n",
    "    canvas = None\n",
    "    CANVAS_WIDTH, CANVAS_HEIGHT = 300.0, 300.0\n",
    "\n",
    "    def __init__(self, config: EnvironmentConfiguration):\n",
    "        assert config.n_agents > config.visible_nbrs\n",
    "        assert config.movement_granularity % 2 == 1\n",
    "\n",
    "        self.n_agents = config.n_agents\n",
    "        self.n_targets = config.n_targets\n",
    "        self.spawn_area = config.spawn_area\n",
    "        self.max_steps = config.max_steps\n",
    "        self.agent_range = config.agent_range\n",
    "        self.visible_nbrs = config.visible_nbrs\n",
    "        self.visible_targets = config.visible_targets\n",
    "        self.cache_size = config.cache_size\n",
    "        self.movement_granularity = config.movement_granularity\n",
    "        self.speed_granularity = config.speed_granularity\n",
    "\n",
    "        self.agents_ids = ['agent-' + str(i) for i in range(self.n_agents)]\n",
    "        self.observation_space = self.observation_space('agent-0')\n",
    "        self.action_space = self.action_space('agent-0')\n",
    "\n",
    "    def unflatten_observation_space(self, agent):\n",
    "        direction = Box(low=-1, high=1, shape=(2,1), dtype=np.float32)\n",
    "        distance = Box(low=-np.inf, high=np.inf, shape=(1,1), dtype=np.float32)\n",
    "\n",
    "        nbrs = Dict({f\"nbr-{i}\": Dict({'direction': direction, 'distance': distance}) for i in range(self.visible_nbrs)})\n",
    "        targets = Dict({f\"target-{i}\": Dict({'direction': direction, 'distance': distance}) for i in range(self.visible_targets)})\n",
    "\n",
    "        time_t_obs = Dict({\"nbrs\": nbrs, \"targets\": targets})\n",
    "\n",
    "        return Dict({f\"t[-{t}]\": time_t_obs for t in range(0, self.cache_size)})\n",
    "\n",
    "    def observation_space(self, agent):\n",
    "        return flatten_space(self.unflatten_observation_space(agent))\n",
    "\n",
    "    def __continuous_action(self, discrete_action):\n",
    "        action_tuple = (discrete_action // (self.movement_granularity*self.speed_granularity), \n",
    "                        (discrete_action % (self.movement_granularity*self.speed_granularity)) // (self.speed_granularity), \n",
    "                        discrete_action % self.speed_granularity)\n",
    "\n",
    "        return [(2*(action_tuple[0] / (self.movement_granularity-1))-1),\n",
    "                (2*(action_tuple[1] / (self.movement_granularity-1))-1),\n",
    "                (action_tuple[2]) / float(self.speed_granularity-1)]\n",
    "\n",
    "    def action_space(self, agent):\n",
    "        \"\"\"\n",
    "        direction_x = Discrete(self.movement_granularity)#Box(low=-1.0, high=1.0, shape=(2,1), dtype=np.float32)\n",
    "        direction_y = Discrete(self.movement_granularity)\n",
    "        speed = Discrete(self.speed_granularity)#Box(0.0, 1.0, dtype=np.float32)\n",
    "        return Tuple([direction_x, direction_y, speed])\n",
    "        \"\"\"\n",
    "        return Discrete(self.movement_granularity * self.movement_granularity * self.speed_granularity)\n",
    "    \n",
    "    def __get_time_t_observation(self, agent):\n",
    "        nbrs_distance_vectors = [Vector2D.distance_vector(self.agents_pos[agent], self.agents_pos[nbr])  \n",
    "                            for nbr in self.__get_n_closest_neighbours(agent, self.visible_nbrs)]\n",
    "\n",
    "        targets_distance_vectors = [Vector2D.distance_vector(self.agents_pos[agent], self.targets_pos[target])  \n",
    "                            for target in self.__get_n_closest_targets(agent, self.visible_targets)]\n",
    "\n",
    "        nbrs = {\n",
    "            f\"nbr-{i}\": {\n",
    "                \"direction\": Vector2D.unit_vector(nbrs_distance_vectors[i]).to_np_array(),\n",
    "                \"distance\": np.log(1 + Vector2D.norm(nbrs_distance_vectors[i])) #1 - np.exp(-alpha * x)\n",
    "            }\n",
    "            for i in range(len(nbrs_distance_vectors))\n",
    "        }\n",
    "    \n",
    "        targets = {\n",
    "            f\"target-{i}\": {\n",
    "                \"direction\": Vector2D.unit_vector(targets_distance_vectors[i]).to_np_array(),\n",
    "                \"distance\": np.log(1 + Vector2D.norm(targets_distance_vectors[i])) #1 - np.exp(-alpha * x)\n",
    "            }\n",
    "            for i in range(len(targets_distance_vectors))\n",
    "        }\n",
    "        \n",
    "        for i in range(len(targets_distance_vectors), self.visible_targets):\n",
    "            targets[f\"target-{i}\"] = {\n",
    "                \"direction\": np.array([0,0], dtype=np.int32),\n",
    "                \"distance\": -1 #1 - np.exp(-alpha * x)\n",
    "            }\n",
    "\n",
    "        obs = {\n",
    "            \"nbrs\": nbrs,\n",
    "            \"targets\": targets\n",
    "        }\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def __get_observation(self, agent):\n",
    "        if len(self.observation_cache[agent]) == 0:\n",
    "            self.observation_cache[agent] = [self.__get_time_t_observation(agent)]*self.cache_size\n",
    "        else:\n",
    "            self.observation_cache[agent] = [self.__get_time_t_observation(agent)] + self.observation_cache[agent]\n",
    "            self.observation_cache[agent].pop()\n",
    "\n",
    "        obs = {\n",
    "            f\"t[-{t}]\": self.observation_cache[agent][t]\n",
    "            for t in range(0, self.cache_size)\n",
    "        }\n",
    "\n",
    "        return flatten(self.unflatten_observation_space(agent), obs)\n",
    "\n",
    "    def rgb_to_hex(self, r, g, b):\n",
    "        return f'#{r:02x}{g:02x}{b:02x}'\n",
    "\n",
    "    def __get_local_reward(self, agent, action):\n",
    "        # reward_1: small bonus if the agent collects an item\n",
    "        reward_1 = +5 if agent in self.collectors else 0\n",
    "\n",
    "        # reward_2: malus if the agent collides with another agent \n",
    "        reward_2= sum([-2 if Vector2D.distance(self.agents_pos[agent], self.agents_pos[nbr]) < self.agent_range*2 else 0 for nbr in self.__get_other_agents(agent)])\n",
    "\n",
    "        # reward_3: -1 at each step\n",
    "        reward_3 = -1\n",
    "\n",
    "        # reward_4: positive reward if the agent moves toward the closest targets, negative otherwise\n",
    "        distance_diff = ([Vector2D.distance(self.agent_old_pos[agent], self.targets_pos[target]) -\n",
    "                    Vector2D.distance(self.agents_pos[agent], self.targets_pos[target])\n",
    "            for target in self.closest_targets[agent]])\n",
    "        \n",
    "        reward_4 = max(distance_diff) if len(distance_diff) > 0 else 0\n",
    "\n",
    "        self.info[agent] = {\"info\": {f\"r2: {reward_2}, r3: {reward_3}, r4: {reward_4}\"}}\n",
    "        return  reward_2 + reward_3 + reward_4*3\n",
    "\n",
    "    def __get_global_reward(self):\n",
    "        return self.global_reward * 100\n",
    "    \n",
    "    def __get_other_agents(self, agent):\n",
    "        return [other for other in self.agents_ids if other != agent]\n",
    "\n",
    "    def __get_n_closest_neighbours(self, agent, n=1):\n",
    "        distances = {other: Vector2D.distance(self.agents_pos[agent], self.agents_pos[other]) for other in self.__get_other_agents(agent)}\n",
    "        return [neighbour[0] for neighbour in sorted(list(distances.items()), key=lambda d: d[1])[:n]]\n",
    "        # return {neighbour[0]: neighbour[1] for neighbour in sorted(list(dst.items()), key=lambda d: d[0])[:n]}\n",
    "\n",
    "    def __get_n_closest_targets(self, agent, n=1):\n",
    "        n = min(n, len(self.targets_pos.keys()))\n",
    "        distances = {target: Vector2D.distance(self.agents_pos[agent], pos) for target, pos in self.targets_pos.items()}\n",
    "        self.closest_targets[agent] = [target[0] for target in sorted(list(distances.items()), key=lambda d: d[1])[:n]]\n",
    "        return self.closest_targets[agent]\n",
    "\n",
    "    def __update_agent_position(self, agent, action):\n",
    "        unit_movement = Vector2D(action[0], action[1])\n",
    "        self.agent_old_pos[agent] = self.agents_pos[agent]\n",
    "        self.agents_pos[agent] = Vector2D.sum(self.agents_pos[agent], Vector2D.mul(unit_movement, action[2]))\n",
    "\n",
    "    def __collect_items(self):\n",
    "        self.collectors = []\n",
    "        uncollected_targets = {}\n",
    "        for target, target_pos in self.targets_pos.items():\n",
    "            collected = False\n",
    "            for agent in self.agents_pos.values():\n",
    "                if Vector2D.distance(target_pos, agent) < self.agent_range:\n",
    "                    collected = True\n",
    "                    self.collectors.append(agent)\n",
    "            if not collected:\n",
    "                uncollected_targets[target] = target_pos\n",
    "        self.targets_pos = uncollected_targets\n",
    "\n",
    "    def __collect_items_and_compute_global_reward(self):\n",
    "        old_uncollected_items = len(self.targets_pos.keys())\n",
    "        self.__collect_items()\n",
    "        updated_uncollected_items = len(self.targets_pos.keys())\n",
    "        self.global_reward = old_uncollected_items - updated_uncollected_items\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.steps = 0\n",
    "        self.agents_pos = {agent: Vector2D.get_random_point(max_x=self.spawn_area, max_y=self.spawn_area) for agent in self.agents_ids}\n",
    "        self.agent_old_pos = dict(self.agents_pos)\n",
    "        self.targets_pos = {f\"target-{i}\": Vector2D.get_random_point(max_x=self.spawn_area, max_y=self.spawn_area) for i in range(self.n_targets)}\n",
    "        self.collectors = []\n",
    "        self.closest_targets = {}\n",
    "        self.info = {}\n",
    "        self.observation_cache = {agent: [] for agent in self.agents_ids}\n",
    "        return {agent: self.__get_observation(agent) for agent in self.agents_ids}, {}\n",
    "     \n",
    "    def step(self, actions):\n",
    "        self.steps += 1\n",
    "        observations, rewards, terminated, truncated, infos = {}, {}, {}, {}, {}\n",
    "\n",
    "        for agent, action in actions.items():\n",
    "            self.__update_agent_position(agent, self.__continuous_action(action))\n",
    "\n",
    "        self.__collect_items_and_compute_global_reward()\n",
    "\n",
    "        for agent, action in actions.items():\n",
    "            observations[agent] = self.__get_observation(agent)\n",
    "            rewards[agent] = self.__get_local_reward(agent, self.__continuous_action(action)) + self.__get_global_reward()\n",
    "            terminated[agent] = False\n",
    "            truncated[agent] = False\n",
    "            infos[agent] = self.info[agent]\n",
    "\n",
    "        truncated['__all__'] = False\n",
    "        if len(self.targets_pos.keys()) == 0:\n",
    "            terminated['__all__'] = True\n",
    "        elif self.max_steps != None and self.steps == self.max_steps:\n",
    "            terminated['__all__'] = True\n",
    "        else:\n",
    "            terminated['__all__'] = False\n",
    "\n",
    "        return observations, rewards, terminated, truncated, infos\n",
    "     \n",
    "    def rgb_to_hex(self, r, g, b):\n",
    "        return f'#{r:02x}{g:02x}{b:02x}'\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def get_agent_ids(self):\n",
    "       return self.agents\n",
    "\n",
    "\n",
    "class RenderableCollectTheItems(CollectTheItems):\n",
    "    def __init__(self, config: EnvironmentConfiguration):\n",
    "        super().__init__(config)\n",
    "        self.agent_colors = {agent: self.rgb_to_hex(rnd.randint(0, 255), rnd.randint(0, 255), rnd.randint(0, 255)) for agent in self.agents_ids}\n",
    "\n",
    "        self.unit = self.CANVAS_WIDTH/float(self.spawn_area)\n",
    "        self.render_size_agent = max(self.unit,1)\n",
    "        self.render_size_agent_range = self.unit*self.agent_range\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def __position_in_frame(self, position_in_env):\n",
    "        return [((self.spawn_area-position_in_env[0])/self.spawn_area)*self.CANVAS_WIDTH,\n",
    "                        ((self.spawn_area-position_in_env[1])/self.spawn_area)*self.CANVAS_HEIGHT,]\n",
    "\n",
    "    def render(self):\n",
    "        with hold_canvas():\n",
    "            if self.canvas == None:\n",
    "                self.canvas = CanvasWithBorders(width=self.CANVAS_WIDTH, height=self.CANVAS_HEIGHT)\n",
    "                display(self.canvas)\n",
    "\n",
    "            self.canvas.clear()\n",
    "\n",
    "            self.canvas.fill_style = \"red\"\n",
    "            for target in self.targets_pos.values():\n",
    "                self.canvas.draw_circle(pos=self.__position_in_frame(target.to_np_array()), \n",
    "                                        radius=1, \n",
    "                                        fill_color=\"red\")\n",
    "\n",
    "            for agent in self.agents_ids:\n",
    "                self.canvas.draw_circle(pos=self.__position_in_frame(self.agents_pos[agent].to_np_array()), \n",
    "                                        radius=self.render_size_agent/2.0, \n",
    "                                        fill_color=self.agent_colors[agent],\n",
    "                                        border_color=\"black\")\n",
    "\n",
    "                self.canvas.draw_circle(pos=self.__position_in_frame(self.agents_pos[agent].to_np_array()), \n",
    "                                        radius=self.render_size_agent_range, \n",
    "                                        border_color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space:  Discrete(125)\n",
      "observation space:  Dict('t[-0]': Dict('nbrs': Dict('nbr-0': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'nbr-1': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'nbr-2': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32))), 'targets': Dict('target-0': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'target-1': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'target-2': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)))), 't[-1]': Dict('nbrs': Dict('nbr-0': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'nbr-1': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'nbr-2': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32))), 'targets': Dict('target-0': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'target-1': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'target-2': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)))), 't[-2]': Dict('nbrs': Dict('nbr-0': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'nbr-1': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'nbr-2': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32))), 'targets': Dict('target-0': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'target-1': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)), 'target-2': Dict('direction': Box(-1.0, 1.0, (2, 1), float32), 'distance': Box(-inf, inf, (1, 1), float32)))))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b395a1cb6b39460cbd958e5f859680c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 2,\n",
    "    spawn_area = 100,\n",
    "    max_steps=300,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=3,\n",
    "    movement_granularity=5,\n",
    "    speed_granularity=5)\n",
    "\n",
    "env = RenderableCollectTheItems(env_config)\n",
    "\n",
    "print(\"action space: \", env.action_space)\n",
    "print(\"observation space: \", env.unflatten_observation_space(\"agent-0\"))\n",
    "\n",
    "simulate_random_episode(env, 100, sleep_between_frames=0.03, print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 10,\n",
    "    spawn_area = 200,\n",
    "    max_steps=300,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=3,\n",
    "    movement_granularity=5,\n",
    "    speed_granularity=5)\n",
    "\n",
    "register_env(\"collect_the_items?algo=DQN&method=CTDE\", lambda _: RenderableCollectTheItems(env_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restart ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-07-04 14:07:07,790\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdqn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdqn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNConfig\n\u001b[1;32m      3\u001b[0m training_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      5\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mDQNConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_network_update_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdouble_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdueling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_runners\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_env_runners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollect_the_items?algo=DQN&method=CTDE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m clear_output()\n\u001b[1;32m     21\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_episode_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m     24\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm_config.py:859\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator, use_copy)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    857\u001b[0m     algo_class \u001b[38;5;241m=\u001b[39m get_trainable_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class)\n\u001b[0;32m--> 859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgo_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_copy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:554\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# TODO: Don't dump sampler results into top-level.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     },\n\u001b[1;32m    552\u001b[0m }\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:158\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, storage)\u001b[0m\n\u001b[1;32m    154\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStorageContext on the TRAINABLE:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstorage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_logfiles(stdout_file, stderr_file)\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:640\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moff_policy_estimation_methods \u001b[38;5;241m=\u001b[39m ope_dict\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# Create a set of env runner actors via a EnvRunnerGroup.\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mEnvRunnerGroup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_env_runners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39msync_weights(inference_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:169\u001b[0m, in \u001b[0;36mEnvRunnerGroup.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_env_runners, local_env_runner, logdir, _setup, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _setup:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_env_runners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_env_runners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_env_runner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_env_runner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# EnvRunnerGroup creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# be initialized properly (due to some errors in the EnvRunners's\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# constructor).\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# errors.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:239\u001b[0m, in \u001b[0;36mEnvRunnerGroup._setup\u001b[0;34m(self, validate_env, config, num_env_runners, local_env_runner)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds_shards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_env_runners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env_runners_after_construction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    248\u001b[0m     local_env_runner\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_manager\u001b[38;5;241m.\u001b[39mnum_actors() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39maction_space)\n\u001b[1;32m    253\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:748\u001b[0m, in \u001b[0;36mEnvRunnerGroup.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Validate here, whether all remote workers have been constructed properly\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# and are \"up and running\". Establish initial states.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m--> 748\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_healthy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;66;03m# Simiply raise the error, which will get handled by the try-except\u001b[39;00m\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;66;03m# clause around the _setup().\u001b[39;00m\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m    754\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:622\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    616\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[1;32m    617\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    618\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    619\u001b[0m )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:476\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[0;32m--> 476\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/worker.py:2854\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2852\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2853\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2854\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3812\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:571\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.dqn.dqn import DQNConfig\n",
    "\n",
    "training_iterations = 30\n",
    "\n",
    "algo = (DQNConfig()\n",
    "        .training(\n",
    "            gamma=0.95,\n",
    "            lr=0.001,\n",
    "            train_batch_size=32,\n",
    "            n_step=1,\n",
    "            target_network_update_freq=500,\n",
    "            double_q=True,\n",
    "            dueling=True)\n",
    "        .env_runners(num_env_runners=1)\n",
    "        .resources(num_gpus=0)  \n",
    "        .environment(\"collect_the_items?algo=DQN&method=CTDE\")\n",
    "    ).build()\n",
    "\n",
    "clear_output()\n",
    "\n",
    "metrics = {\n",
    "    \"mean_episode_length\": [],\n",
    "    \"mean_reward\": []\n",
    "}\n",
    "\n",
    "out = \"\"\n",
    "for i in range(training_iterations):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += dqn_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    metrics[\"mean_episode_length\"].append(result['sampler_results']['episode_len_mean'])\n",
    "    metrics[\"mean_reward\"].append(result['sampler_results']['episode_reward_mean'])\n",
    "    simulate_episode(RenderableCollectTheItems(env_config), algo, 500, sleep_between_frames=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f870432d510>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(21, 5))\n",
    "\n",
    "ax1.plot(metrics[\"mean_episode_length\"], linestyle='-', color='r', label='Mean episode length')\n",
    "ax2.plot(metrics[\"mean_reward\"], linestyle='-', color='y', label='Mean reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name = \"collect_the_items?algo=DQN&method=CTDE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Algorithm checkpoint has been created inside directory: 'TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/c/Users/nicol/Desktop/Universit/tesi/thesis-MARL_in_Aggregate_Computing/CTDE/algos/collect_the_items?algo=DQN&method=CTDE), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 4.8280158042907715, 'mean_q': 157.53335571289062, 'min_q': 38.10633087158203, 'max_q': 371.29168701171875, 'cur_lr': 0.001}, 'td_error': array([-1.7874939e+01, -9.1105263e+01, -6.3267975e+00,  8.7053680e+00,\n",
      "       -8.5085907e+01,  5.4938927e+00, -2.9582428e+01, -3.7129089e+01,\n",
      "       -7.5896912e+00, -1.1905212e+00, -9.2197113e+01, -3.8870682e+01,\n",
      "        5.7523041e+00,  2.1991730e+01, -3.7046227e+01,  2.6754852e+01,\n",
      "        2.2421265e+00,  9.1459351e+00,  6.8840714e+00, -3.3142090e-02,\n",
      "        1.9923599e+01,  1.0348709e+01,  1.6755657e+01,  4.3000183e+00,\n",
      "        9.7249298e+00,  2.6508865e+00, -6.5407593e+01, -2.1958405e+01,\n",
      "        9.9109192e+00,  2.0137985e+01,  1.0655914e+01, -8.4368484e+01],\n",
      "      dtype=float32), 'mean_td_error': -13.262104034423828, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 32.0, 'num_grad_updates_lifetime': 29000.0, 'diff_num_grad_updates_vs_sampler_policy': 28999.0}}, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 928000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 928000, 'last_target_update_ts': 29501, 'num_target_updates': 58}, 'sampler_results': {'episode_reward_max': 4885.6792777105165, 'episode_reward_min': 3326.8182022875144, 'episode_reward_mean': 4464.716127997774, 'episode_len_mean': 102.82, 'episode_media': {}, 'episodes_this_iter': 10, 'episodes_timesteps_total': 10282, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4371.139048112276, 4647.459588447587, 4341.651763329823, 4489.032745830773, 4684.628515182816, 4728.64092707628, 4366.5763882525025, 4778.707497397271, 4777.275610301914, 4434.00413055645, 4585.712772870368, 4453.187425415697, 4530.665798573628, 4566.8309314528615, 4076.4471681146424, 4602.851667228285, 4125.429935810194, 4630.761167550075, 4673.311792462489, 4418.279517333859, 4304.310614377563, 4532.741499550974, 4343.953479439146, 4282.511369606445, 4368.766852853708, 4686.929504478114, 3326.8182022875144, 4035.0772759968677, 4331.126270796121, 4551.267521439597, 4451.796624986866, 4616.829454870641, 4503.172824596826, 4724.93423545276, 4462.464827895799, 4666.516083817104, 4367.498222205582, 4484.277211762297, 4520.774957629879, 3925.6951455783437, 4289.129081431618, 4383.449117277514, 4510.137299140841, 4534.44143336124, 4405.173358291737, 4520.123495400791, 4412.905759834543, 4471.887562555516, 4457.794841289782, 4793.535710424853, 4450.235116610424, 4305.918366721859, 4124.422520600463, 4630.817002479366, 4734.526868108845, 4553.398688219829, 4420.857948201293, 4515.351072502304, 4072.2941210124986, 4215.95960084207, 4761.44376307436, 4483.404050574186, 4342.557573246748, 4531.824315917967, 4351.884041809604, 4489.09935160497, 4288.129906799681, 4436.790301301207, 4349.370995969521, 3730.6082581308306, 4637.284610859078, 4702.2923099266245, 4381.536614821169, 4636.175316021624, 4380.10999205179, 4477.976391686119, 4885.6792777105165, 4530.609470175225, 4449.070930674221, 4369.879446731486, 4808.191189852259, 4404.48064757349, 4749.22340934214, 4124.251308947615, 4738.901109786016, 4365.899024479627, 4627.563814799363, 4744.946769763423, 4718.57272643973, 4757.34205584477, 4474.7278525489, 4377.488899393125, 4468.896105273723, 4034.7338979510823, 4303.963670149615, 4457.949137591255, 4375.905595647575, 4870.409033010708, 4540.874119376026, 4739.149977690593], 'episode_lengths': [59, 144, 121, 84, 90, 88, 58, 95, 116, 59, 75, 73, 114, 133, 135, 68, 185, 91, 156, 95, 117, 124, 117, 55, 84, 137, 177, 135, 120, 200, 157, 74, 108, 100, 73, 100, 99, 70, 99, 163, 67, 51, 93, 173, 91, 131, 102, 160, 91, 105, 99, 88, 94, 113, 88, 66, 56, 97, 67, 76, 97, 124, 47, 124, 132, 71, 75, 72, 57, 214, 94, 129, 96, 100, 67, 73, 102, 104, 114, 97, 125, 56, 109, 134, 82, 109, 188, 86, 108, 90, 177, 77, 77, 104, 49, 63, 103, 110, 100, 90]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.08855443856198, 'mean_inference_ms': 1.7262376932184071, 'mean_action_processing_ms': 0.24761266134652993, 'mean_env_wait_ms': 1.94549102200804, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.013257980346679688, 'StateBufferConnector_ms': 0.012418031692504883, 'ViewRequirementAgentConnector_ms': 0.4386258125305176}, 'num_episodes': 10, 'episode_return_max': 4885.6792777105165, 'episode_return_min': 3326.8182022875144, 'episode_return_mean': 4464.716127997774}, 'env_runner_results': {'episode_reward_max': 4885.6792777105165, 'episode_reward_min': 3326.8182022875144, 'episode_reward_mean': 4464.716127997774, 'episode_len_mean': 102.82, 'episode_media': {}, 'episodes_this_iter': 10, 'episodes_timesteps_total': 10282, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4371.139048112276, 4647.459588447587, 4341.651763329823, 4489.032745830773, 4684.628515182816, 4728.64092707628, 4366.5763882525025, 4778.707497397271, 4777.275610301914, 4434.00413055645, 4585.712772870368, 4453.187425415697, 4530.665798573628, 4566.8309314528615, 4076.4471681146424, 4602.851667228285, 4125.429935810194, 4630.761167550075, 4673.311792462489, 4418.279517333859, 4304.310614377563, 4532.741499550974, 4343.953479439146, 4282.511369606445, 4368.766852853708, 4686.929504478114, 3326.8182022875144, 4035.0772759968677, 4331.126270796121, 4551.267521439597, 4451.796624986866, 4616.829454870641, 4503.172824596826, 4724.93423545276, 4462.464827895799, 4666.516083817104, 4367.498222205582, 4484.277211762297, 4520.774957629879, 3925.6951455783437, 4289.129081431618, 4383.449117277514, 4510.137299140841, 4534.44143336124, 4405.173358291737, 4520.123495400791, 4412.905759834543, 4471.887562555516, 4457.794841289782, 4793.535710424853, 4450.235116610424, 4305.918366721859, 4124.422520600463, 4630.817002479366, 4734.526868108845, 4553.398688219829, 4420.857948201293, 4515.351072502304, 4072.2941210124986, 4215.95960084207, 4761.44376307436, 4483.404050574186, 4342.557573246748, 4531.824315917967, 4351.884041809604, 4489.09935160497, 4288.129906799681, 4436.790301301207, 4349.370995969521, 3730.6082581308306, 4637.284610859078, 4702.2923099266245, 4381.536614821169, 4636.175316021624, 4380.10999205179, 4477.976391686119, 4885.6792777105165, 4530.609470175225, 4449.070930674221, 4369.879446731486, 4808.191189852259, 4404.48064757349, 4749.22340934214, 4124.251308947615, 4738.901109786016, 4365.899024479627, 4627.563814799363, 4744.946769763423, 4718.57272643973, 4757.34205584477, 4474.7278525489, 4377.488899393125, 4468.896105273723, 4034.7338979510823, 4303.963670149615, 4457.949137591255, 4375.905595647575, 4870.409033010708, 4540.874119376026, 4739.149977690593], 'episode_lengths': [59, 144, 121, 84, 90, 88, 58, 95, 116, 59, 75, 73, 114, 133, 135, 68, 185, 91, 156, 95, 117, 124, 117, 55, 84, 137, 177, 135, 120, 200, 157, 74, 108, 100, 73, 100, 99, 70, 99, 163, 67, 51, 93, 173, 91, 131, 102, 160, 91, 105, 99, 88, 94, 113, 88, 66, 56, 97, 67, 76, 97, 124, 47, 124, 132, 71, 75, 72, 57, 214, 94, 129, 96, 100, 67, 73, 102, 104, 114, 97, 125, 56, 109, 134, 82, 109, 188, 86, 108, 90, 177, 77, 77, 104, 49, 63, 103, 110, 100, 90]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.08855443856198, 'mean_inference_ms': 1.7262376932184071, 'mean_action_processing_ms': 0.24761266134652993, 'mean_env_wait_ms': 1.94549102200804, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.013257980346679688, 'StateBufferConnector_ms': 0.012418031692504883, 'ViewRequirementAgentConnector_ms': 0.4386258125305176}, 'num_episodes': 10, 'episode_return_max': 4885.6792777105165, 'episode_return_min': 3326.8182022875144, 'episode_return_mean': 4464.716127997774}, 'episode_reward_max': 4885.6792777105165, 'episode_reward_min': 3326.8182022875144, 'episode_reward_mean': 4464.716127997774, 'episode_len_mean': 102.82, 'episodes_this_iter': 10, 'episodes_timesteps_total': 10282, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [4371.139048112276, 4647.459588447587, 4341.651763329823, 4489.032745830773, 4684.628515182816, 4728.64092707628, 4366.5763882525025, 4778.707497397271, 4777.275610301914, 4434.00413055645, 4585.712772870368, 4453.187425415697, 4530.665798573628, 4566.8309314528615, 4076.4471681146424, 4602.851667228285, 4125.429935810194, 4630.761167550075, 4673.311792462489, 4418.279517333859, 4304.310614377563, 4532.741499550974, 4343.953479439146, 4282.511369606445, 4368.766852853708, 4686.929504478114, 3326.8182022875144, 4035.0772759968677, 4331.126270796121, 4551.267521439597, 4451.796624986866, 4616.829454870641, 4503.172824596826, 4724.93423545276, 4462.464827895799, 4666.516083817104, 4367.498222205582, 4484.277211762297, 4520.774957629879, 3925.6951455783437, 4289.129081431618, 4383.449117277514, 4510.137299140841, 4534.44143336124, 4405.173358291737, 4520.123495400791, 4412.905759834543, 4471.887562555516, 4457.794841289782, 4793.535710424853, 4450.235116610424, 4305.918366721859, 4124.422520600463, 4630.817002479366, 4734.526868108845, 4553.398688219829, 4420.857948201293, 4515.351072502304, 4072.2941210124986, 4215.95960084207, 4761.44376307436, 4483.404050574186, 4342.557573246748, 4531.824315917967, 4351.884041809604, 4489.09935160497, 4288.129906799681, 4436.790301301207, 4349.370995969521, 3730.6082581308306, 4637.284610859078, 4702.2923099266245, 4381.536614821169, 4636.175316021624, 4380.10999205179, 4477.976391686119, 4885.6792777105165, 4530.609470175225, 4449.070930674221, 4369.879446731486, 4808.191189852259, 4404.48064757349, 4749.22340934214, 4124.251308947615, 4738.901109786016, 4365.899024479627, 4627.563814799363, 4744.946769763423, 4718.57272643973, 4757.34205584477, 4474.7278525489, 4377.488899393125, 4468.896105273723, 4034.7338979510823, 4303.963670149615, 4457.949137591255, 4375.905595647575, 4870.409033010708, 4540.874119376026, 4739.149977690593], 'episode_lengths': [59, 144, 121, 84, 90, 88, 58, 95, 116, 59, 75, 73, 114, 133, 135, 68, 185, 91, 156, 95, 117, 124, 117, 55, 84, 137, 177, 135, 120, 200, 157, 74, 108, 100, 73, 100, 99, 70, 99, 163, 67, 51, 93, 173, 91, 131, 102, 160, 91, 105, 99, 88, 94, 113, 88, 66, 56, 97, 67, 76, 97, 124, 47, 124, 132, 71, 75, 72, 57, 214, 94, 129, 96, 100, 67, 73, 102, 104, 114, 97, 125, 56, 109, 134, 82, 109, 188, 86, 108, 90, 177, 77, 77, 104, 49, 63, 103, 110, 100, 90]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 2.08855443856198, 'mean_inference_ms': 1.7262376932184071, 'mean_action_processing_ms': 0.24761266134652993, 'mean_env_wait_ms': 1.94549102200804, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.013257980346679688, 'StateBufferConnector_ms': 0.012418031692504883, 'ViewRequirementAgentConnector_ms': 0.4386258125305176}, 'num_episodes': 10, 'episode_return_max': 4885.6792777105165, 'episode_return_min': 3326.8182022875144, 'episode_return_mean': 4464.716127997774, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 928000, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 928000, 'num_env_steps_sampled_this_iter': 1000, 'num_env_steps_trained_this_iter': 32000, 'num_env_steps_sampled_throughput_per_sec': 30.740293847407475, 'num_env_steps_trained_throughput_per_sec': 983.6894031170392, 'timesteps_total': 30000, 'num_env_steps_sampled_lifetime': 30000, 'num_agent_steps_sampled_lifetime': 120000, 'num_steps_trained_this_iter': 32000, 'agent_timesteps_total': 120000, 'timers': {'training_iteration_time_ms': 33311.696, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 30.989, 'sample_time_ms': 12.037, 'load_time_ms': 0.132, 'load_throughput': 242401.532, 'learn_time_ms': 6.882, 'learn_throughput': 4649.747, 'synch_weights_time_ms': 3.771}, 'counters': {'num_env_steps_sampled': 30000, 'num_env_steps_trained': 928000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 928000, 'last_target_update_ts': 29501, 'num_target_updates': 58}, 'done': False, 'episodes_total': 231, 'training_iteration': 30, 'trial_id': 'default', 'date': '2024-07-04_10-57-24', 'timestamp': 1720083444, 'time_this_iter_s': 32.5365993976593, 'time_total_s': 1011.770566701889, 'pid': 7519, 'hostname': 'LAPTOP-9AD2MD1C', 'node_ip': '172.22.114.43', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'collect_the_items?algo=DQN&method=CTDE', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.95, 'lr': 0.001, 'grad_clip': 40.0, 'grad_clip_by': 'global_norm', 'train_batch_size': 32, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7fec789102c0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'epsilon': [(0, 1.0), (10000, 0.05)], 'target_network_update_freq': 500, 'num_steps_sampled_before_learning_starts': 1000, 'store_buffer_in_checkpoints': False, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'tau': 1.0, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'before_learn_on_batch': None, 'training_intensity': None, 'td_error_loss_fn': 'huber', 'categorical_distribution_temperature': 1.0, 'replay_buffer_config': {'type': <class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>, 'prioritized_replay': -1, 'capacity': 50000, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'replay_sequence_length': 1, 'worker_side_prioritization': False}, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 1011.770566701889, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 40.793749999999996, 'ram_util_percent': 92.02916666666668}})'.\n"
     ]
    }
   ],
   "source": [
    "save_algo(algo, algo_name)\n",
    "save_dict_as_json(metrics, f\"metrics/{algo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 14:05:22,276\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "2024-07-04 14:05:26,940\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "algo = load_algo(\"collect_the_items?algo=DQN&method=CTDE\")\n",
    "metrics = load_json_as_dict(f\"metrics/{\"collect_the_items?algo=DQN&method=CTDE\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b348d21bae0047839d2e0027a960e82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_config = env_config.__deepcopy__(None)\n",
    "new_config.spawn_area = 200\n",
    "new_config.n_targets = 20\n",
    "env = RenderableCollectTheItems(new_config)\n",
    "simulate_episode(env, algo, steps=500, sleep_between_frames=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rayEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
