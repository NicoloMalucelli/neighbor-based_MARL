{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the items\n",
    "\n",
    "the agents goal is to collect all the items in the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vectors import Vector2D\n",
    "from utils.canvas import CanvasWithBorders\n",
    "from utils.algo_utils import (save_algo, load_algo)\n",
    "from utils.simulations import (simulate_episode, simulate_random_episode, ppo_result_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "import random as rnd\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiDiscrete\n",
    "from gymnasium.spaces.utils import flatten, flatten_space\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "\n",
    "class EnvironmentConfiguration: \n",
    "    def __init__(self, n_agents, n_targets, agent_range, spawn_area=100, visible_nbrs=1, visible_targets=1, max_steps=None, cache_size=1):\n",
    "        # parameters that shouldn't affect the agents' behaviour\n",
    "        self.n_agents = n_agents\n",
    "        self.n_targets = n_targets\n",
    "        self.spawn_area = spawn_area\n",
    "        self.max_steps = max_steps\n",
    "        # parameters that affect the agents' behavious\n",
    "        self.agent_range = agent_range\n",
    "        # parameters that affect the observation space\n",
    "        self.visible_nbrs = visible_nbrs\n",
    "        self.visible_targets = visible_targets\n",
    "        self.cache_size = cache_size\n",
    "\n",
    "class KeepTheDistance(MultiAgentEnv):\n",
    "    canvas = None\n",
    "    CANVAS_WIDTH, CANVAS_HEIGHT = 300.0, 300.0\n",
    "\n",
    "    def __init__(self, config: EnvironmentConfiguration):\n",
    "        assert config.n_agents > config.visible_nbrs\n",
    "\n",
    "        self.n_agents = config.n_agents\n",
    "        self.n_targets = config.n_targets\n",
    "        self.spawn_area = config.spawn_area\n",
    "        self.max_steps = config.max_steps\n",
    "        self.agent_range = config.agent_range\n",
    "        self.visible_nbrs = config.visible_nbrs\n",
    "        self.visible_targets = config.visible_targets\n",
    "        self.cache_size = config.cache_size\n",
    "\n",
    "        self.agents_ids = ['agent-' + str(i) for i in range(self.n_agents)]\n",
    "        self.agent_colors = {agent: self.rgb_to_hex(rnd.randint(0, 255), rnd.randint(0, 255), rnd.randint(0, 255)) for agent in self.agents_ids}\n",
    "        self.observation_space = self.observation_space('agent-0')\n",
    "        self.action_space = self.action_space(\"\")\n",
    "\n",
    "    def unflatten_observation_space(self, agent):\n",
    "        direction = Box(low=-1, high=1, shape=(2,1), dtype=np.float32)\n",
    "        distance = Box(low=-np.inf, high=np.inf, shape=(1,1), dtype=np.float32)\n",
    "\n",
    "        nbrs = Dict({f\"nbr-{i}\": Dict({'direction': direction, 'distance': distance}) for i in range(self.visible_nbrs)})\n",
    "        targets = Dict({f\"target-{i}\": Dict({'direction': direction, 'distance': distance}) for i in range(self.visible_targets)})\n",
    "\n",
    "        time_t_obs = Dict({\"nbrs\": nbrs, \"targets\": targets})\n",
    "\n",
    "        return Dict({f\"t[-{t}]\": time_t_obs for t in range(0, self.cache_size)})\n",
    "\n",
    "    def observation_space(self, agent):\n",
    "        return flatten_space(self.unflatten_observation_space(agent))\n",
    "\n",
    "    def action_space(self, agent):\n",
    "        direction = Box(low=-1.0, high=1.0, shape=(2,1), dtype=np.float32)\n",
    "        speed = Box(0.0, 1.0, dtype=np.float32)\n",
    "        return flatten_space(Tuple([direction, speed]))\n",
    "    \n",
    "    def __get_time_t_observation(self, agent):\n",
    "        nbrs_distance_vectors = [Vector2D.distance_vector(self.agents_pos[agent], self.agents_pos[nbr])  \n",
    "                            for nbr in self.__get_n_closest_neighbours(agent, self.visible_nbrs)]\n",
    "\n",
    "        targets_distance_vectors = [Vector2D.distance_vector(self.agents_pos[agent], self.targets_pos[target])  \n",
    "                            for target in self.__get_n_closest_targets(agent, self.visible_targets)]\n",
    "\n",
    "        nbrs = {\n",
    "            f\"nbr-{i}\": {\n",
    "                \"direction\": Vector2D.unit_vector(nbrs_distance_vectors[i]).to_np_array(),\n",
    "                \"distance\": np.log(1 + Vector2D.norm(nbrs_distance_vectors[i])) #1 - np.exp(-alpha * x)\n",
    "            }\n",
    "            for i in range(len(nbrs_distance_vectors))\n",
    "        }\n",
    "    \n",
    "        targets = {\n",
    "            f\"target-{i}\": {\n",
    "                \"direction\": Vector2D.unit_vector(targets_distance_vectors[i]).to_np_array(),\n",
    "                \"distance\": np.log(1 + Vector2D.norm(targets_distance_vectors[i])) #1 - np.exp(-alpha * x)\n",
    "            }\n",
    "            for i in range(len(targets_distance_vectors))\n",
    "        }\n",
    "        \n",
    "        for i in range(len(targets_distance_vectors), self.visible_targets):\n",
    "            targets[f\"target-{i}\"] = {\n",
    "                \"direction\": np.array([0,0], dtype=np.int32),\n",
    "                \"distance\": -1 #1 - np.exp(-alpha * x)\n",
    "            }\n",
    "\n",
    "        obs = {\n",
    "            \"nbrs\": nbrs,\n",
    "            \"targets\": targets\n",
    "        }\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def __get_observation(self, agent):\n",
    "        if len(self.observation_cache[agent]) == 0:\n",
    "            self.observation_cache[agent] = [self.__get_time_t_observation(agent)]*self.cache_size\n",
    "        else:\n",
    "            self.observation_cache[agent] = [self.__get_time_t_observation(agent)] + self.observation_cache[agent]\n",
    "            self.observation_cache[agent].pop()\n",
    "\n",
    "        obs = {\n",
    "            f\"t[-{t}]\": self.observation_cache[agent][t]\n",
    "            for t in range(0, self.cache_size)\n",
    "        }\n",
    "\n",
    "        return flatten(self.unflatten_observation_space(agent), obs)\n",
    "\n",
    "    def rgb_to_hex(self, r, g, b):\n",
    "        return f'#{r:02x}{g:02x}{b:02x}'\n",
    "\n",
    "    def __get_local_reward(self, agent, action):\n",
    "        # reward_1: small bonus if the agent collects an item\n",
    "        reward_1 = +5 if agent in self.collectors else 0\n",
    "\n",
    "        # reward_2: malus if the agent collides with another agent \n",
    "        reward_2= sum([-2 if Vector2D.distance(self.agents_pos[agent], self.agents_pos[nbr]) < self.agent_range*2 else 0 for nbr in self.__get_other_agents(agent)])\n",
    "\n",
    "        # reward_3: -1 at each step\n",
    "        reward_3 = -1\n",
    "\n",
    "        # reward_4: positive reward if the agent moves toward the closest targets, negative otherwise\n",
    "        distance_diff = ([Vector2D.distance(self.agent_old_pos[agent], self.targets_pos[target]) -\n",
    "                    Vector2D.distance(self.agents_pos[agent], self.targets_pos[target])\n",
    "            for target in self.closest_targets[agent]])\n",
    "        \n",
    "        reward_4 = max(distance_diff) if len(distance_diff) > 0 else 0\n",
    "\n",
    "        self.info[agent] = {\"info\": {f\"r2: {reward_2}, r3: {reward_3}, r4: {reward_4}\"}}\n",
    "        return  reward_2 + reward_3 + reward_4*3\n",
    "\n",
    "    def __get_global_reward(self):\n",
    "        return self.global_reward * 100\n",
    "    \n",
    "    def __get_other_agents(self, agent):\n",
    "        return [other for other in self.agents_ids if other != agent]\n",
    "\n",
    "    def __get_n_closest_neighbours(self, agent, n=1):\n",
    "        distances = {other: Vector2D.distance(self.agents_pos[agent], self.agents_pos[other]) for other in self.__get_other_agents(agent)}\n",
    "        return [neighbour[0] for neighbour in sorted(list(distances.items()), key=lambda d: d[1])[:n]]\n",
    "        # return {neighbour[0]: neighbour[1] for neighbour in sorted(list(dst.items()), key=lambda d: d[0])[:n]}\n",
    "\n",
    "    def __get_n_closest_targets(self, agent, n=1):\n",
    "        n = min(n, len(self.targets_pos.keys()))\n",
    "        distances = {target: Vector2D.distance(self.agents_pos[agent], pos) for target, pos in self.targets_pos.items()}\n",
    "        self.closest_targets[agent] = [target[0] for target in sorted(list(distances.items()), key=lambda d: d[1])[:n]]\n",
    "        return self.closest_targets[agent]\n",
    "\n",
    "    def __update_agent_position(self, agent, action):\n",
    "        unit_movement = Vector2D(action[0], action[1])\n",
    "        self.agent_old_pos[agent] = self.agents_pos[agent]\n",
    "        self.agents_pos[agent] = Vector2D.sum(self.agents_pos[agent], Vector2D.mul(unit_movement, action[2]))\n",
    "\n",
    "    def __collect_items(self):\n",
    "        self.collectors = []\n",
    "        uncollected_targets = {}\n",
    "        for target, target_pos in self.targets_pos.items():\n",
    "            collected = False\n",
    "            for agent in self.agents_pos.values():\n",
    "                if Vector2D.distance(target_pos, agent) < self.agent_range:\n",
    "                    collected = True\n",
    "                    self.collectors.append(agent)\n",
    "            if not collected:\n",
    "                uncollected_targets[target] = target_pos\n",
    "        self.targets_pos = uncollected_targets\n",
    "\n",
    "    def __collect_items_and_compute_global_reward(self):\n",
    "        old_uncollected_items = len(self.targets_pos.keys())\n",
    "        self.__collect_items()\n",
    "        updated_uncollected_items = len(self.targets_pos.keys())\n",
    "        self.global_reward = old_uncollected_items - updated_uncollected_items\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.steps = 0\n",
    "        self.agents_pos = {agent: Vector2D.get_random_point(max_x=self.spawn_area, max_y=self.spawn_area) for agent in self.agents_ids}\n",
    "        self.agent_old_pos = dict(self.agents_pos)\n",
    "        self.targets_pos = {f\"target-{i}\": Vector2D.get_random_point(max_x=self.spawn_area, max_y=self.spawn_area) for i in range(self.n_targets)}\n",
    "        self.collectors = []\n",
    "        self.closest_targets = {}\n",
    "        self.info = {}\n",
    "        self.observation_cache = {agent: [] for agent in self.agents_ids}\n",
    "        return {agent: self.__get_observation(agent) for agent in self.agents_ids}, {}\n",
    "     \n",
    "    def step(self, actions):\n",
    "        self.steps += 1\n",
    "        observations, rewards, terminated, truncated, infos = {}, {}, {}, {}, {}\n",
    "\n",
    "        for agent, action in actions.items():\n",
    "            self.__update_agent_position(agent, action)\n",
    "\n",
    "        self.__collect_items_and_compute_global_reward()\n",
    "\n",
    "        for agent, action in actions.items():\n",
    "            observations[agent] = self.__get_observation(agent)\n",
    "            rewards[agent] = self.__get_local_reward(agent, action) + self.__get_global_reward()\n",
    "            terminated[agent] = False\n",
    "            truncated[agent] = False\n",
    "            infos[agent] = self.info[agent]\n",
    "\n",
    "        truncated['__all__'] = False\n",
    "        if len(self.targets_pos.keys()) == 0:\n",
    "            terminated['__all__'] = True\n",
    "        elif self.max_steps != None and self.steps == self.max_steps:\n",
    "            terminated['__all__'] = True\n",
    "        else:\n",
    "            terminated['__all__'] = False\n",
    "\n",
    "        return observations, rewards, terminated, truncated, infos\n",
    "     \n",
    "    def rgb_to_hex(self, r, g, b):\n",
    "        return f'#{r:02x}{g:02x}{b:02x}'\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def get_agent_ids(self):\n",
    "       return self.agents\n",
    "\n",
    "\n",
    "class RenderableKeepTheDistance(KeepTheDistance):\n",
    "    def render(self):\n",
    "        if self.canvas is None:\n",
    "            self.canvas = CanvasWithBorders(width=self.CANVAS_WIDTH, height=self.CANVAS_HEIGHT)\n",
    "            display(self.canvas)\n",
    "        \n",
    "        with hold_canvas():\n",
    "            unit = self.CANVAS_WIDTH/float(self.spawn_area)\n",
    "            agent_render_size = max(unit,1)\n",
    "            agent_range_render_size = unit*self.agent_range\n",
    "            top_left, bottom_right = (0.0,0.0), (self.spawn_area, self.spawn_area)\n",
    "            self.canvas.clear()\n",
    "\n",
    "            self.canvas.fill_style = \"red\"\n",
    "            for target in self.targets_pos.values():\n",
    "                raw_pos = target.to_np_array()\n",
    "\n",
    "                target_pos_in_frame = [((raw_pos[0]-top_left[0])/(bottom_right[0]-top_left[0]))*self.CANVAS_WIDTH,\n",
    "                        ((raw_pos[1]-top_left[1])/(bottom_right[1]-top_left[1]))*self.CANVAS_HEIGHT,]\n",
    "                \n",
    "                self.canvas.fill_circle(\n",
    "                    target_pos_in_frame[0],\n",
    "                    target_pos_in_frame[1],\n",
    "                    1\n",
    "                )\n",
    "\n",
    "            for agent in self.agents_ids:\n",
    "                raw_pos = self.agents_pos[agent].to_np_array()\n",
    "                color = self.agent_colors[agent]\n",
    "                \n",
    "                agent_pos_in_frame = [((raw_pos[0]-top_left[0])/(bottom_right[0]-top_left[0]))*self.CANVAS_WIDTH,\n",
    "                            ((raw_pos[1]-top_left[1])/(bottom_right[1]-top_left[1]))*self.CANVAS_HEIGHT,]\n",
    "\n",
    "                self.canvas.fill_style = color\n",
    "                self.canvas.fill_circle(\n",
    "                    agent_pos_in_frame[0],\n",
    "                    agent_pos_in_frame[1],\n",
    "                    agent_render_size/2.0\n",
    "                )\n",
    "                \n",
    "                self.canvas.stroke_style = \"black\"\n",
    "                self.canvas.stroke_circle(\n",
    "                    agent_pos_in_frame[0],\n",
    "                    agent_pos_in_frame[1],\n",
    "                    agent_render_size/2.0\n",
    "                )\n",
    "\n",
    "                self.canvas.stroke_style = \"red\"\n",
    "                self.canvas.stroke_circle(\n",
    "                    agent_pos_in_frame[0],\n",
    "                    agent_pos_in_frame[1],\n",
    "                    agent_range_render_size\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.          1.609438    0.9486833   0.31622776  4.002937\n",
      "  0.97618705 -0.21693046  4.3142343   0.73994005  0.6726728   3.8198683\n",
      "  0.9067211  -0.42173076  3.8799877   0.          0.         -1.\n",
      "  0.          1.          1.609438    0.9486833   0.31622776  4.002937\n",
      "  0.97618705 -0.21693046  4.3142343   0.73994005  0.6726728   3.8198683\n",
      "  0.9067211  -0.42173076  3.8799877   0.          0.         -1.\n",
      "  0.          1.          1.609438    0.9486833   0.31622776  4.002937\n",
      "  0.97618705 -0.21693046  4.3142343   0.73994005  0.6726728   3.8198683\n",
      "  0.9067211  -0.42173076  3.8799877   0.          0.         -1.        ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ae6a5906994eaea5664410782b5bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 2,\n",
    "    spawn_area = 100,\n",
    "    max_steps=300,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=3)\n",
    "\n",
    "env = RenderableKeepTheDistance(env_config)\n",
    "\n",
    "print(env.reset()[0]['agent-0'])\n",
    "env.render()\n",
    "simulate_random_episode(env, 100, sleep_between_frames=0.03, print_info=False)\n",
    "#env.step({'agent-1': (1,1,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## policy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect_the_items?visible_nbrs=3&visible_targets=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 5,\n",
    "    spawn_area = 100,\n",
    "    max_steps=500,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3)\n",
    "register_env(\"collect_the_items?visible_nbrs=3&visible_targets=3\", lambda _: KeepTheDistance(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:36:01,164\tWARNING deprecation.py:50 -- DeprecationWarning: `_enable_new_api_stack` has been deprecated. Use `AlgorithmConfig._enable_new_api_stack` instead. This will raise an error in the future!\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/nicolo/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-06-25 15:36:01,240\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "2024-06-25 15:36:01,241\tWARNING deprecation.py:50 -- DeprecationWarning: `max_num_worker_restarts` has been deprecated. Use `AlgorithmConfig.max_num_env_runner_restarts` instead. This will raise an error in the future!\n",
      "2024-06-25 15:36:04,602\tINFO worker.py:1749 -- Started a local Ray instance.\n",
      "2024-06-25 15:36:16,076\tINFO trainable.py:161 -- Trainable.setup took 14.837 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2024-06-25 15:36:16,081\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "algo = load_algo(\"collect_the_items?visible_nbrs=3&visible_targets=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [1] => episode_reward_mean: -893.9480659760416, episode_len_mean: 500.0, agent_steps_trained: 16384, env_steps_trained: 4096, entropy: 4.264709077278773, learning_rate: 0.0010000000000000005\n",
      "iteration [2] => episode_reward_mean: -482.5269048987643, episode_len_mean: 500.0, agent_steps_trained: 32768, env_steps_trained: 8192, entropy: 4.250036556273699, learning_rate: 0.0010000000000000005\n",
      "iteration [3] => episode_reward_mean: -456.72925837565737, episode_len_mean: 500.0, agent_steps_trained: 49152, env_steps_trained: 12288, entropy: 4.297442886109153, learning_rate: 0.0010000000000000005\n",
      "iteration [4] => episode_reward_mean: -340.454066931658, episode_len_mean: 500.0, agent_steps_trained: 65536, env_steps_trained: 16384, entropy: 4.245982205743591, learning_rate: 0.0010000000000000005\n",
      "iteration [5] => episode_reward_mean: -282.55356669564907, episode_len_mean: 500.0, agent_steps_trained: 81920, env_steps_trained: 20480, entropy: 4.3182781174778935, learning_rate: 0.0010000000000000005\n",
      "iteration [6] => episode_reward_mean: -155.4006950508849, episode_len_mean: 495.6734693877551, agent_steps_trained: 98304, env_steps_trained: 24576, entropy: 4.095665505900979, learning_rate: 0.0010000000000000005\n",
      "iteration [7] => episode_reward_mean: -170.31263790185733, episode_len_mean: 496.280701754386, agent_steps_trained: 114688, env_steps_trained: 28672, entropy: 4.1652046302954355, learning_rate: 0.0010000000000000005\n",
      "iteration [8] => episode_reward_mean: -140.28288216075325, episode_len_mean: 496.73846153846154, agent_steps_trained: 131072, env_steps_trained: 32768, entropy: 4.028250763316949, learning_rate: 0.0010000000000000005\n",
      "iteration [9] => episode_reward_mean: -67.64798060477267, episode_len_mean: 494.36486486486484, agent_steps_trained: 147456, env_steps_trained: 36864, entropy: 4.0959240061541395, learning_rate: 0.0010000000000000005\n",
      "iteration [10] => episode_reward_mean: 31.433234651336434, episode_len_mean: 494.3170731707317, agent_steps_trained: 163840, env_steps_trained: 40960, entropy: 4.015162252883116, learning_rate: 0.0010000000000000005\n",
      "iteration [11] => episode_reward_mean: 109.83308596720103, episode_len_mean: 494.8791208791209, agent_steps_trained: 180224, env_steps_trained: 45056, entropy: 4.183094247803092, learning_rate: 0.0010000000000000005\n",
      "iteration [12] => episode_reward_mean: 161.97234068349485, episode_len_mean: 495.0, agent_steps_trained: 196608, env_steps_trained: 49152, entropy: 4.118913087372978, learning_rate: 0.0010000000000000005\n",
      "iteration [13] => episode_reward_mean: 247.69513278784038, episode_len_mean: 495.05, agent_steps_trained: 212992, env_steps_trained: 53248, entropy: 4.135496456176043, learning_rate: 0.0010000000000000005\n",
      "iteration [14] => episode_reward_mean: 278.7508679862651, episode_len_mean: 495.05, agent_steps_trained: 229376, env_steps_trained: 57344, entropy: 4.2294053205599385, learning_rate: 0.0010000000000000005\n",
      "iteration [15] => episode_reward_mean: 355.19821502332854, episode_len_mean: 495.05, agent_steps_trained: 245760, env_steps_trained: 61440, entropy: 4.030528401955962, learning_rate: 0.0010000000000000005\n",
      "iteration [16] => episode_reward_mean: 392.5667159093087, episode_len_mean: 492.34, agent_steps_trained: 262144, env_steps_trained: 65536, entropy: 4.058777433137099, learning_rate: 0.0010000000000000005\n",
      "iteration [17] => episode_reward_mean: 447.433691250075, episode_len_mean: 492.34, agent_steps_trained: 278528, env_steps_trained: 69632, entropy: 3.9979191459715366, learning_rate: 0.0010000000000000005\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3367cb7c6589410ebefd7002ecca1c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.2643908632480816'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4526919536127565'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.6163850526939001'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9115470541304731'}}}\n",
      "reward:  {'agent-0': 98.20682741025576, 'agent-1': 100.35807586083827, 'agent-2': 97.1508448419183, 'agent-3': 101.73464116239143} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.04922439851821281'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.49854683643052056'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9311736831189492'}}}\n",
      "reward:  {'agent-0': -1.1476731955546384, 'agent-1': -1.0, 'agent-2': 0.49564050929156167, 'agent-3': 1.7935210493568476} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9560678197059218'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.501254330774346'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.063036819199688'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2596069168079289'}}}\n",
      "reward:  {'agent-0': 1.8682034591177654, 'agent-1': 0.503762992323038, 'agent-2': 2.189110457599064, 'agent-3': -0.22117924957621327} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.18438364201073654'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5203300606260584'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.39545625232500115'}}}\n",
      "reward:  {'agent-0': -0.4468490739677904, 'agent-1': 0.5609901818781751, 'agent-2': -1.0, 'agent-3': 0.18636875697500344} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.012087200560763733'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.20148605831088062'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.04778268927221063'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.027982353044549768'}}}\n",
      "reward:  {'agent-0': -1.0362616016822912, 'agent-1': -0.39554182506735813, 'agent-2': -0.8566519321833681, 'agent-3': -0.9160529408663507} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.0720502262457714'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.0566599340036742'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.16250324264505167'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7052740526042882'}}}\n",
      "reward:  {'agent-0': -1.2161506787373142, 'agent-1': 2.1699798020110226, 'agent-2': -0.512490272064845, 'agent-3': 1.1158221578128646} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19340652649051293'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3857224052284831'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4569404574489937'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6273528200289178'}}}\n",
      "reward:  {'agent-0': -0.4197804205284612, 'agent-1': 0.15716721568544934, 'agent-2': 0.3708213723469811, 'agent-3': 0.8820584600867534} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.4472987177751122'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3545296264203728'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2896902937752941'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4545747169538714'}}}\n",
      "reward:  {'agent-0': -2.3418961533253366, 'agent-1': 0.06358887926111834, 'agent-2': -0.13092911867411772, 'agent-3': 0.36372415086161425} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.545239686372831'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7520330042001753'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5692287189288763'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4866366215831093'}}}\n",
      "reward:  {'agent-0': 0.6357190591184931, 'agent-1': 1.2560990126005258, 'agent-2': 0.7076861567866288, 'agent-3': 0.4599098647493278} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2547168711127412'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07725604924641516'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5237790590349327'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4185204694008817'}}}\n",
      "reward:  {'agent-0': -0.23584938666177635, 'agent-1': -0.7682318522607545, 'agent-2': 0.5713371771047981, 'agent-3': 0.25556140820264517} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.45112858738476547'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9663657750304537'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.0995916238160177'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.2692030316670397'}}}\n",
      "reward:  {'agent-0': 0.3533857621542964, 'agent-1': 1.8990973250913612, 'agent-2': 2.298774871448053, 'agent-3': 2.807609095001119} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5581894579948568'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2607232684758465'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.19177274681377554'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4802127963846132'}}}\n",
      "reward:  {'agent-0': 0.6745683739845703, 'agent-1': -0.21783019457246056, 'agent-2': -1.5753182404413266, 'agent-3': 0.4406383891538397} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.7580851789372574'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6549362947127122'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.39124678051125983'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7029184836820619'}}}\n",
      "reward:  {'agent-0': -3.274255536811772, 'agent-1': 0.9648088841381366, 'agent-2': 0.17374034153377949, 'agent-3': 1.1087554510461857} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.5894170855451506'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.20645957878310384'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27074303600965166'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7140233600049868'}}}\n",
      "reward:  {'agent-0': -2.768251256635452, 'agent-1': -0.3806212636506885, 'agent-2': -0.18777089197104502, 'agent-3': 1.1420700800149604} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5896848334274338'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8374177532556573'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.01950968313933288'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.34931831711734773'}}}\n",
      "reward:  {'agent-0': 0.7690545002823015, 'agent-1': 1.5122532597669718, 'agent-2': -0.9414709505820014, 'agent-3': 0.047954951352043196} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6878835392118958'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9240764749253287'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09729631186176846'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5433047949278951'}}}\n",
      "reward:  {'agent-0': 1.0636506176356875, 'agent-1': 1.7722294247759862, 'agent-2': -0.7081110644146946, 'agent-3': 0.6299143847836852} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19921508795262355'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.22397055789116393'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21651185208504842'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.030857993520772453'}}}\n",
      "reward:  {'agent-0': -0.40235473614212935, 'agent-1': -0.3280883263265082, 'agent-2': -0.35046444374485475, 'agent-3': -0.9074260194376826} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7497360994247231'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.723612470184797'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.44499567552499286'}}}\n",
      "reward:  {'agent-0': 1.2492082982741692, 'agent-1': -1.0, 'agent-2': 1.170837410554391, 'agent-3': 0.3349870265749786} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7341695466425122'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.3100956439136198'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.0, 'agent-2': 1.2025086399275366, 'agent-3': 2.9302869317408593} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5239273785646859'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.22590368763282953'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.041125957158421045'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4989183828432395'}}}\n",
      "reward:  {'agent-0': 0.5717821356940576, 'agent-1': -0.3222889371015114, 'agent-2': -1.1233778714752631, 'agent-3': 0.4967551485297186} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4654609392784579'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.38558967176122394'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.456548245575938'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.0532662911383355'}}}\n",
      "reward:  {'agent-0': 0.39638281783537366, 'agent-1': 0.15676901528367182, 'agent-2': 0.36964473672781395, 'agent-3': 2.1597988734150064} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7687062347726794'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09833737427814526'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.11765796176576515'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6222329611564277'}}}\n",
      "reward:  {'agent-0': 1.3061187043180382, 'agent-1': -0.7049878771655642, 'agent-2': -1.3529738852972955, 'agent-3': 0.866698883469283} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6874026501966597'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1437315537792756'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.04790526344915946'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.25899419786455624'}}}\n",
      "reward:  {'agent-0': 1.062207950589979, 'agent-1': -0.5688053386621732, 'agent-2': -1.1437157903474784, 'agent-3': -0.22301740640633128} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6922172978647865'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.26221848274730064'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22576162154891932'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.37206211205802475'}}}\n",
      "reward:  {'agent-0': 1.0766518935943594, 'agent-1': -0.21334455175809808, 'agent-2': -0.32271513535324203, 'agent-3': 0.11618633617407426} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2084296900240048'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.24983134479975178'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.26890981082604526'}}}\n",
      "reward:  {'agent-0': -0.3747109299279856, 'agent-1': -1.0, 'agent-2': -0.2505059656007447, 'agent-3': -0.19327056752186422} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19382842314117'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2388055381090055'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.35998601077277925'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.472657209507199'}}}\n",
      "reward:  {'agent-0': -0.41851473057649, 'agent-1': -0.28358338567298347, 'agent-2': 0.07995803231833776, 'agent-3': 0.4179716285215971} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.20077554022653032'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3181695430429272'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.013524854502726669'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.42107392395713816'}}}\n",
      "reward:  {'agent-0': -0.397673379320409, 'agent-1': -0.04549137087121835, 'agent-2': -1.04057456350818, 'agent-3': 0.2632217718714145} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.39238398226093807'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4452766648994988'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6290985079533371'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7141931295743653'}}}\n",
      "reward:  {'agent-0': -2.177151946782814, 'agent-1': 0.3358299946984964, 'agent-2': 0.8872955238600113, 'agent-3': 1.142579388723096} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.00014092350932060072'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09929581068413285'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2825515355973245'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4028786866053604'}}}\n",
      "reward:  {'agent-0': -0.9995772294720382, 'agent-1': -0.7021125679476015, 'agent-2': -0.15234539320802654, 'agent-3': 0.20863605981608124} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6388362730541104'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3882218690881132'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.34810017765287427'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.14481597069459085'}}}\n",
      "reward:  {'agent-0': 0.9165088191623312, 'agent-1': 0.16466560726433954, 'agent-2': 0.044300532958622796, 'agent-3': -0.5655520879162275} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6535383437793953'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10128837109632371'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5305494828803532'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9654350705440429'}}}\n",
      "reward:  {'agent-0': 0.960615031338186, 'agent-1': -0.6961348867110289, 'agent-2': 0.5916484486410596, 'agent-3': 1.8963052116321286} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.050382296122165826'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.032222403040762515'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8165141336130368'}}}\n",
      "reward:  {'agent-0': -0.8488531116335025, 'agent-1': -1.0, 'agent-2': -0.9033327908777125, 'agent-3': 1.4495424008391105} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.812357279634945'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.49476953723459616'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6042173738636265'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5099536581848838'}}}\n",
      "reward:  {'agent-0': 1.437071838904835, 'agent-1': 0.48430861170378847, 'agent-2': 0.8126521215908795, 'agent-3': 0.5298609745546514} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.007320298084522392'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.05501984889854228'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.016318380048737424'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0983940676610402'}}}\n",
      "reward:  {'agent-0': -1.0219608942535672, 'agent-1': -0.8349404533043732, 'agent-2': -1.0489551401462123, 'agent-3': -0.7048177970168794} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.43358215918829046'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3873388105110216'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09513885869728966'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4816844616669904'}}}\n",
      "reward:  {'agent-0': 0.3007464775648714, 'agent-1': 0.16201643153306478, 'agent-2': -0.714583423908131, 'agent-3': 0.44505338500097125} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1166626404772444'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.030520658193847'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5166725048676568'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.08724321169776061'}}}\n",
      "reward:  {'agent-0': -0.6500120785682668, 'agent-1': 2.0915619745815413, 'agent-2': 0.5500175146029704, 'agent-3': -1.2617296350932818} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.798828677453109'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.36117280426891085'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5997382567425227'}}}\n",
      "reward:  {'agent-0': 1.3964860323593271, 'agent-1': -1.0, 'agent-2': 0.08351841280673256, 'agent-3': 0.799214770227568} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8668967279286264'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.23161663296742319'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.004121381561209'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6161281824561708'}}}\n",
      "reward:  {'agent-0': 1.6006901837858791, 'agent-1': -0.30515010109773044, 'agent-2': 2.0123641446836267, 'agent-3': 0.8483845473685125} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0195194436617712'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.188241164784813'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1765113791370787'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5608010212699046'}}}\n",
      "reward:  {'agent-0': 2.0585583309853135, 'agent-1': -0.435276505645561, 'agent-2': -0.4704658625887639, 'agent-3': 0.6824030638097138} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5024187165369369'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.28618279364573596'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.002372488771520409'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8527973976731271'}}}\n",
      "reward:  {'agent-0': 0.5072561496108108, 'agent-1': -0.14145161906279213, 'agent-2': -0.9928825336854388, 'agent-3': 1.5583921930193814} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7041512257775295'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3216738062775839'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.18818784902512675'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1158316127988872'}}}\n",
      "reward:  {'agent-0': 1.1124536773325886, 'agent-1': -0.03497858116724828, 'agent-2': -0.43543645292461974, 'agent-3': -0.6525051616033384} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4615711938710021'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.022354770524206202'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3663578241671175'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5620276538588609'}}}\n",
      "reward:  {'agent-0': 0.3847135816130063, 'agent-1': -0.9329356884273814, 'agent-2': 0.09907347250135246, 'agent-3': 0.6860829615765827} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7253556727566419'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3653065166780749'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.28861310821640274'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5457567901946447'}}}\n",
      "reward:  {'agent-0': 1.1760670182699258, 'agent-1': 0.0959195500342247, 'agent-2': -0.1341606753507918, 'agent-3': 0.6372703705839342} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0221843284437426'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1328288046477546'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5169158857911071'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9494992519660794'}}}\n",
      "reward:  {'agent-0': 2.066552985331228, 'agent-1': -0.6015135860567362, 'agent-2': 0.5507476573733214, 'agent-3': 1.8484977558982383} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6959168862217169'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06637159044716512'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.03429772765431949'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 1.0877506586651506, 'agent-1': -0.8008852286585046, 'agent-2': -0.8971068170370415, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.18081751462815987'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6597361285643686'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9680304125999157'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1607121908173763'}}}\n",
      "reward:  {'agent-0': -0.4575474561155204, 'agent-1': 0.9792083856931058, 'agent-2': 1.9040912377997472, 'agent-3': -0.5178634275478711} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5050376739953961'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3523165207813008'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9659853076138845'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12206378797142037'}}}\n",
      "reward:  {'agent-0': 0.5151130219861884, 'agent-1': 0.05694956234390247, 'agent-2': 1.8979559228416534, 'agent-3': -0.6338086360857389} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.23386837184134635'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1067587528002818'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.47924579867089534'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5781199621289081'}}}\n",
      "reward:  {'agent-0': -0.29839488447596096, 'agent-1': -0.6797237415991546, 'agent-2': 0.437737396012686, 'agent-3': 0.7343598863867244} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1437934614188947'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5542484309868598'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9134459439716771'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3382299541768887'}}}\n",
      "reward:  {'agent-0': -0.5686196157433159, 'agent-1': 0.6627452929605795, 'agent-2': 1.7403378319150313, 'agent-3': 0.014689862530666176} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9069327196983039'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.13099934970484384'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6632851655755871'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3601245446611756'}}}\n",
      "reward:  {'agent-0': 1.7207981590949117, 'agent-1': -0.6070019508854685, 'agent-2': 0.9898554967267614, 'agent-3': 0.08037363398352682} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.31693561184631847'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.26255839201533604'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2885412703941981'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.08092772217860045'}}}\n",
      "reward:  {'agent-0': -0.0491931644610446, 'agent-1': -0.21232482395399188, 'agent-2': -0.13437618881740576, 'agent-3': -0.7572168334641987} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6274209166568099'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.04405831273545502'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.40687734185637225'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5901655093531275'}}}\n",
      "reward:  {'agent-0': 0.8822627499704296, 'agent-1': -0.8678250617936349, 'agent-2': 0.22063202556911676, 'agent-3': 0.7704965280593825} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.636034780106634'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.39288490765063244'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.47485637727536556'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.45560084368753984'}}}\n",
      "reward:  {'agent-0': 0.9081043403199018, 'agent-1': 0.17865472295189733, 'agent-2': -2.4245691318260967, 'agent-3': 0.3668025310626195} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8851734944907008'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.047965100240826786'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22549289960299035'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.03547267714528246'}}}\n",
      "reward:  {'agent-0': 1.6555204834721025, 'agent-1': -0.8561046992775196, 'agent-2': -0.32352130119102895, 'agent-3': -0.8935819685641526} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.031020458402601'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.17685471633542704'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22715142618601192'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5202576668753878'}}}\n",
      "reward:  {'agent-0': 2.093061375207803, 'agent-1': -0.4694358509937189, 'agent-2': -0.31854572144196425, 'agent-3': 0.5607730006261633} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.25580803795693896'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10293873747898985'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2503665319563453'}}}\n",
      "reward:  {'agent-0': -0.23257588612918312, 'agent-1': -0.6911837875630304, 'agent-2': -1.0, 'agent-3': -0.24890040413096415} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.46447105202977923'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5907778176001521'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.15305446165957193'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.757534411317863'}}}\n",
      "reward:  {'agent-0': 0.3934131560893377, 'agent-1': 0.7723334528004564, 'agent-2': -0.5408366150212842, 'agent-3': 1.272603233953589} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.09042149178361569'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.12948934315271288'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5420254587071796'}}}\n",
      "reward:  {'agent-0': -0.7287355246491529, 'agent-1': -0.6115319705418614, 'agent-2': -1.0, 'agent-3': 0.6260763761215387} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.048619632168723115'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.054727149507975525'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10749682351443823'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3643487525443092'}}}\n",
      "reward:  {'agent-0': -0.8541411034938307, 'agent-1': -0.8358185514760734, 'agent-2': -0.6775095294566853, 'agent-3': 0.09304625763292762} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5169610404337135'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.007775371691110422'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.025332550954807687'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2825718757621445'}}}\n",
      "reward:  {'agent-0': 0.5508831213011405, 'agent-1': -0.9766738849266687, 'agent-2': -1.075997652864423, 'agent-3': -0.15228437271356654} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.15197413210946564'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.16043155433584388'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5879868102437307'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.045618876537375286'}}}\n",
      "reward:  {'agent-0': -0.5440776036716031, 'agent-1': -0.5187053369924683, 'agent-2': 0.763960430731192, 'agent-3': -0.8631433703878741} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4859712647157508'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.41063164510714323'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.0, 'agent-2': 0.4579137941472524, 'agent-3': 0.23189493532142968} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.06539111741194858'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.22822163324083178'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.04190130585926255'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1372308112968028'}}}\n",
      "reward:  {'agent-0': -1.1961733522358458, 'agent-1': -0.31533510027750467, 'agent-2': -0.8742960824222124, 'agent-3': -0.5883075661095916} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3801367984602493'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.49424913455072783'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.16708341445103514'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2962314920225708'}}}\n",
      "reward:  {'agent-0': 0.14041039538074784, 'agent-1': 0.4827474036521835, 'agent-2': -1.5012502433531054, 'agent-3': -0.11130552393228754} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7245932792953624'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4043102228919331'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5879575938393238'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3713067155373224'}}}\n",
      "reward:  {'agent-0': 1.1737798378860873, 'agent-1': 0.21293066867579924, 'agent-2': 0.7638727815179713, 'agent-3': 0.11392014661196725} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.26046461018837874'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.31800519283587647'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.42978832833051683'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12343379559002177'}}}\n",
      "reward:  {'agent-0': -0.21860616943486377, 'agent-1': -0.045984421492370586, 'agent-2': 0.2893649849915505, 'agent-3': -0.6296986132299347} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.89244145962018'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6623940177639618'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6984266426505812'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.13782181707886565'}}}\n",
      "reward:  {'agent-0': 1.6773243788605399, 'agent-1': 0.9871820532918854, 'agent-2': 1.0952799279517436, 'agent-3': -0.586534548763403} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6430826655790014'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.333487772262103'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.42160992233633365'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5053079870525252'}}}\n",
      "reward:  {'agent-0': 100.929247996737, 'agent-1': 100.00046331678631, 'agent-2': 100.264829767009, 'agent-3': 100.51592396115757} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.10766382382674067'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.0179580739929754'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6876781051954879'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.18350700249872887'}}}\n",
      "reward:  {'agent-0': -0.677008528519778, 'agent-1': 2.0538742219789263, 'agent-2': 1.0630343155864637, 'agent-3': -0.4494789925038134} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.39204661363032756'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07916652430449744'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15307721331571855'}}}\n",
      "reward:  {'agent-0': 0.17613984089098267, 'agent-1': -0.7625004270865077, 'agent-2': -1.0, 'agent-3': -0.5407683600528443} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2718613794473157'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06585435038458698'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2588454850907027'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15427951536486262'}}}\n",
      "reward:  {'agent-0': -0.1844158616580529, 'agent-1': -0.8024369488462391, 'agent-2': -0.22346354472789187, 'agent-3': -0.5371614539054121} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.067504410261094'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.00864523777077153'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.17203305640833833'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15613433395887455'}}}\n",
      "reward:  {'agent-0': -1.202513230783282, 'agent-1': -0.9740642866876854, 'agent-2': -0.483900830774985, 'agent-3': -0.5315969981233764} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.23788118726295693'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4966787283118208'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.36348748573021794'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.744001004105435'}}}\n",
      "reward:  {'agent-0': -0.2863564382111292, 'agent-1': 0.4900361849354624, 'agent-2': 0.09046245719065382, 'agent-3': 1.232003012316305} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.22625056953965128'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.14786723791755918'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7132140017220081'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8342199397459424'}}}\n",
      "reward:  {'agent-0': -0.32124829138104616, 'agent-1': -0.5563982862473225, 'agent-2': 1.1396420051660243, 'agent-3': 1.5026598192378273} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.029531895175736622'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5456484464328071'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.04559575841739161'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1323440691093438'}}}\n",
      "reward:  {'agent-0': -0.9114043144727901, 'agent-1': 0.6369453392984212, 'agent-2': -0.8632127247478252, 'agent-3': 2.3970322073280315} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2462329659616742'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.30614637200878647'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.007764770923103'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.26130110211497737, 'agent-1': -0.08156088397364059, 'agent-2': 2.023294312769309, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.37386978498415147'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10391185659334212'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3957190264179573'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.1216093549524544, 'agent-1': -0.6882644302199736, 'agent-2': 0.18715707925387193, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.06275736082716321'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.23436890250886577'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6107339898101856'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.556524489455029'}}}\n",
      "reward:  {'agent-0': -0.8117279175185104, 'agent-1': -0.2968932924734027, 'agent-2': 0.8322019694305567, 'agent-3': 0.6695734683650869} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5501232655866346'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.49440351707747254'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.28343813794536743'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.18786436366728054'}}}\n",
      "reward:  {'agent-0': 0.6503697967599038, 'agent-1': 0.48321055123241763, 'agent-2': -0.1496855861638977, 'agent-3': -0.43640690899815837} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6129997090681485'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.11873540386153536'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9927477949399304'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1650172168736148'}}}\n",
      "reward:  {'agent-0': 0.8389991272044455, 'agent-1': -0.6437937884153939, 'agent-2': 1.9782433848197911, 'agent-3': -0.5049483493791556} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0389060164546038'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.20062099046638693'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.17305908889021282'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.24768617983122'}}}\n",
      "reward:  {'agent-0': 2.1167180493638114, 'agent-1': -0.3981370286008392, 'agent-2': -0.48082273332936154, 'agent-3': -0.25694146050634004} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7784559455783508'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9682108134604093'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09605101055572618'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11423465540659805'}}}\n",
      "reward:  {'agent-0': 1.3353678367350525, 'agent-1': 1.9046324403812278, 'agent-2': -0.7118469683328215, 'agent-3': -0.6572960337802058} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6547760515188585'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.044363329331012835'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21630669082973597'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.227600896153497'}}}\n",
      "reward:  {'agent-0': 0.9643281545565756, 'agent-1': -0.8669100120069615, 'agent-2': -0.3510799275107921, 'agent-3': -0.31719731153950903} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.34304486322545813'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8803527613472966'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.550424427154482'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.30066962377594564'}}}\n",
      "reward:  {'agent-0': 0.02913458967637439, 'agent-1': 1.6410582840418897, 'agent-2': 0.6512732814634461, 'agent-3': -0.09799112867216309} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3493234265192342'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.22818935079068936'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.8058777977885114'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.012284093610126945'}}}\n",
      "reward:  {'agent-0': 0.04797027955770261, 'agent-1': -0.3154319476279319, 'agent-2': 1.4176333933655343, 'agent-3': -0.9631477191696192} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6747277421110596'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.14557951311728345'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.890041129658627'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12218694081454373'}}}\n",
      "reward:  {'agent-0': 1.0241832263331787, 'agent-1': -0.5632614606481496, 'agent-2': 1.670123388975881, 'agent-3': -0.6334391775563688} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8666545919897644'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2305400277877503'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.02726724103356659'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3182210796954834'}}}\n",
      "reward:  {'agent-0': 1.599963775969293, 'agent-1': -0.30837991663674913, 'agent-2': -0.9181982768993002, 'agent-3': -0.04533676091354977} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.05557185857455238'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8089468635107409'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6691671079227746'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.038696748038653084'}}}\n",
      "reward:  {'agent-0': -1.1667155757236571, 'agent-1': 1.4268405905322226, 'agent-2': 1.0075013237683237, 'agent-3': -0.8839097558840407} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.05344566994568822'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.014895181297845284'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.0000777435264325'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.8396629901629353, 'agent-1': -0.9553144561064641, 'agent-2': 2.0002332305792976, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6361217000125734'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2358617696086469'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3606593223954633'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.27542847876367915'}}}\n",
      "reward:  {'agent-0': 0.9083651000377202, 'agent-1': -0.29241469117405927, 'agent-2': 0.08197796718638983, 'agent-3': -0.17371456370896254} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7936552496280171'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.859085476731579'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2668426445210983'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.27646496082716254'}}}\n",
      "reward:  {'agent-0': 1.3809657488840514, 'agent-1': 1.577256430194737, 'agent-2': -0.19947206643670512, 'agent-3': -0.17060511751851237} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.09336025322284058'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.059436758799833456'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.009047246894979821'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15637426679208488'}}}\n",
      "reward:  {'agent-0': -1.2800807596685218, 'agent-1': -0.8216897236004996, 'agent-2': -1.0271417406849395, 'agent-3': -0.5308771996237454} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0472352026750187'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.47869862576783717'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7923730338070136'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9030303251019802'}}}\n",
      "reward:  {'agent-0': 2.141705608025056, 'agent-1': 0.4360958773035115, 'agent-2': 1.3771191014210409, 'agent-3': 1.7090909753059407} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.4047179266895924'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.14473815023738013'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3659406022521523'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.09218423555081046'}}}\n",
      "reward:  {'agent-0': 3.214153780068777, 'agent-1': -0.5657855492878596, 'agent-2': 0.09782180675645691, 'agent-3': -0.7234472933475686} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.18445228954436743'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7788820414990489'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.014069325743307104'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5313800185368578'}}}\n",
      "reward:  {'agent-0': -0.4466431313668977, 'agent-1': 1.3366461244971468, 'agent-2': -0.9577920227700787, 'agent-3': 0.5941400556105734} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9304588853344171'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.40204420542666597'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.0034541205399349906'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.13709622461301052'}}}\n",
      "reward:  {'agent-0': 1.7913766560032514, 'agent-1': 0.2061326162799979, 'agent-2': -1.010362361619805, 'agent-3': -0.5887113261609684} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5964653938547642'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8804791003646386'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.226109547543075'}}}\n",
      "reward:  {'agent-0': 0.7893961815642925, 'agent-1': 1.6414373010939158, 'agent-2': -1.0, 'agent-3': -0.321671357370775} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.733564216412617'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.19748969285653573'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.010459542189408921'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5771963975997352'}}}\n",
      "reward:  {'agent-0': 1.2006926492378511, 'agent-1': -0.4075309214303928, 'agent-2': -0.9686213734317732, 'agent-3': 0.7315891927992055} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.38470236237731115'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.27935904852531124'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0959583333719749'}}}\n",
      "reward:  {'agent-0': 0.15410708713193344, 'agent-1': -0.1619228544240663, 'agent-2': -1.0, 'agent-3': -0.7121249998840753} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.902478724475742'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0326096418303905'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1706665388785069'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.004610679448561'}}}\n",
      "reward:  {'agent-0': 1.7074361734272259, 'agent-1': -0.9021710745088285, 'agent-2': -0.48800038336447926, 'agent-3': 2.013832038345683} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.16624717679963652'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.27306264080270637'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0023791712855683045'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.066531850307058'}}}\n",
      "reward:  {'agent-0': -0.5012584696010904, 'agent-1': -0.1808120775918809, 'agent-2': -0.9928624861432951, 'agent-3': -0.800404449078826} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5781576687407721'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.013277938892372276'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.05704995291018378'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1978734658168051'}}}\n",
      "reward:  {'agent-0': 0.7344730062223164, 'agent-1': -0.9601661833228832, 'agent-2': -0.8288501412694487, 'agent-3': -0.4063796025495847} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2704131574818547'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08720596693027005'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.23620812599248708'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.47320186631832684'}}}\n",
      "reward:  {'agent-0': -0.18876052755443595, 'agent-1': -0.7383820992091898, 'agent-2': -0.29137562202253875, 'agent-3': 0.4196055989549805} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9158779669068196'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.167574744291489'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19790164602891736'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3831832315196806'}}}\n",
      "reward:  {'agent-0': 1.7476339007204587, 'agent-1': -0.497275767125533, 'agent-2': -0.40629506191324793, 'agent-3': 0.14954969455904177} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6226776991507705'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.33671545515117884'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.13878454064197143'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15059541872268056'}}}\n",
      "reward:  {'agent-0': 0.8680330974523116, 'agent-1': 0.010146365453536532, 'agent-2': -1.4163536219259143, 'agent-3': -0.5482137438319583} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19334113358069516'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.32394405825511186'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5107768457820825'}}}\n",
      "reward:  {'agent-0': -0.41997659925791453, 'agent-1': -0.028167825234664434, 'agent-2': -1.0, 'agent-3': 0.5323305373462475} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2833234532326969'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09930835398566273'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3887636708825113'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1520663972487881'}}}\n",
      "reward:  {'agent-0': -0.15002964030190924, 'agent-1': -0.7020749380430118, 'agent-2': 0.16629101264753388, 'agent-3': 2.4561991917463644} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2613453006491895'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1925125698074055'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5370411180701566'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.21596409805243155, 'agent-1': -0.4224622905777835, 'agent-2': 0.6111233542104699, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7297341280085305'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.12898348541638427'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.8798942211971479'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 1.1892023840255916, 'agent-1': -0.6130495437508472, 'agent-2': 1.6396826635914437, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.41351273732158234'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.22077211992135304'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4519036791554285'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.240538211964747, 'agent-1': -0.3376836402359409, 'agent-2': 0.3557110374662855, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0391856294505075'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.257985954851371'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22378302282494644'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5489717468448561'}}}\n",
      "reward:  {'agent-0': 2.1175568883515226, 'agent-1': -0.22604213544588703, 'agent-2': -0.32865093152516067, 'agent-3': 0.6469152405345682} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.27528496036457284'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3877731130327504'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5205630352696318'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.264646594478819'}}}\n",
      "reward:  {'agent-0': -0.17414511890628148, 'agent-1': 0.16331933909825125, 'agent-2': 0.5616891058088953, 'agent-3': 2.793939783436457} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4657789403785628'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4430040511822'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.39932956680955556'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.39733682113568847, 'agent-2': 0.32901215354659996, 'agent-3': 0.19798870042866668} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6339404222154883'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3632870030829771'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6927711163451278'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.2819699027920848'}}}\n",
      "reward:  {'agent-0': 0.9018212666464649, 'agent-1': 0.08986100924893137, 'agent-2': 1.0783133490353833, 'agent-3': 2.8459097083762543} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19850488207940487'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7545270458332141'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7518148200973869'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6122069644528096'}}}\n",
      "reward:  {'agent-0': -0.4044853537617854, 'agent-1': 1.2635811374996422, 'agent-2': 1.2554444602921606, 'agent-3': 0.8366208933584289} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9816024774575993'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3220892301852878'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.08521711826705314'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1179911237930753'}}}\n",
      "reward:  {'agent-0': 1.944807432372798, 'agent-1': -0.03373230944413663, 'agent-2': -0.7443486451988406, 'agent-3': -0.6460266286207741} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.30630491439792706'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.911567180033483'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.02190961269556624'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.32633466273647116'}}}\n",
      "reward:  {'agent-0': -0.08108525680621881, 'agent-1': 1.734701540100449, 'agent-2': -0.9342711619133013, 'agent-3': -0.020996011790586522} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7035665211915045'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.39896941702781774'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.08853774985215068'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6329503908743277'}}}\n",
      "reward:  {'agent-0': 1.1106995635745136, 'agent-1': 0.19690825108345322, 'agent-2': -0.734386750443548, 'agent-3': 0.8988511726229831} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.07270773497857874'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9809672152451583'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10523350210068827'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12634214219746553'}}}\n",
      "reward:  {'agent-0': -0.7818767950642638, 'agent-1': 1.9429016457354749, 'agent-2': -0.6842994936979352, 'agent-3': -0.6209735734076034} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.4140915024182732'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08110503226097521'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.11427404393046459'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5340918348061123'}}}\n",
      "reward:  {'agent-0': 3.2422745072548196, 'agent-1': -0.7566849032170744, 'agent-2': -0.6571778682086062, 'agent-3': 0.602275504418337} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.13401145730458097'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.13528273486652154'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.8046774936145624'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.10896028359712773'}}}\n",
      "reward:  {'agent-0': -0.5979656280862571, 'agent-1': -0.5941517954004354, 'agent-2': 1.4140324808436873, 'agent-3': -0.6731191492086168} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9225643272341486'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2599330368492154'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7443147339854619'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4219267718818145'}}}\n",
      "reward:  {'agent-0': 1.7676929817024458, 'agent-1': -0.22020088945235372, 'agent-2': 1.2329442019563857, 'agent-3': 0.26578031564544347} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.36866260009041696'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8661247965596104'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6653531130249348'}}}\n",
      "reward:  {'agent-0': 0.10598780027125088, 'agent-1': 1.5983743896788312, 'agent-2': -1.0, 'agent-3': 0.9960593390748045} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2375306459839166'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.39996625399301067'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4433675445512435'}}}\n",
      "reward:  {'agent-0': -0.2874080620482502, 'agent-1': 0.199898761979032, 'agent-2': -1.0, 'agent-3': 0.3301026336537305} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.01990933861858224'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.02913680121278972'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6093613186246642'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.21302698058976688'}}}\n",
      "reward:  {'agent-0': -0.9402719841442533, 'agent-1': -0.9125895963616308, 'agent-2': 0.8280839558739927, 'agent-3': -0.36091905823069936} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8176431732604357'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5674900054383585'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5423063569219622'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9832277457336716'}}}\n",
      "reward:  {'agent-0': 1.452929519781307, 'agent-1': 0.7024700163150754, 'agent-2': 0.6269190707658865, 'agent-3': 1.9496832372010147} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8498655756405213'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.011791624114032118'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27852214322863844'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 1.549596726921564, 'agent-1': -0.9646251276579036, 'agent-2': -0.16443357031408468, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0857975765282717'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.12709328463682468'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6382754024583335'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.3652094618057404'}}}\n",
      "reward:  {'agent-0': 2.257392729584815, 'agent-1': -0.618720146089526, 'agent-2': 0.9148262073750004, 'agent-3': 3.0956283854172213} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8689893725070732'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5090326779485679'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0021808009202608503'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.361026233405397'}}}\n",
      "reward:  {'agent-0': 1.6069681175212196, 'agent-1': 0.5270980338457036, 'agent-2': -0.9934575972392174, 'agent-3': 3.0830787002161912} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3744689550026834'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.13140194463567312'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10028322499243814'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6978695541194107'}}}\n",
      "reward:  {'agent-0': 0.1234068650080502, 'agent-1': -0.6057941660929806, 'agent-2': -0.6991503250226856, 'agent-3': 1.093608662358232} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.47475088605038707'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09819936977195809'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19978792107032461'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.48463043121775584'}}}\n",
      "reward:  {'agent-0': 0.4242526581511612, 'agent-1': -0.7054018906841257, 'agent-2': -0.40063623678902616, 'agent-3': 0.4538912936532675} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.13845204626277052'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3236674953855392'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3078426330251034'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5419950746134106'}}}\n",
      "reward:  {'agent-0': -0.5846438612116884, 'agent-1': -0.02899751384338245, 'agent-2': -0.07647210092468981, 'agent-3': 0.6259852238402317} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.019792124179488724'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3387351744493685'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.15839884195138154'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.551409543443313'}}}\n",
      "reward:  {'agent-0': -0.9406236274615338, 'agent-1': 0.016205523348105544, 'agent-2': -0.5248034741458554, 'agent-3': 0.6542286303299392} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1945998262827402'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.11863832586811185'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2167368060616539'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.06167588201396512'}}}\n",
      "reward:  {'agent-0': -0.4162005211517794, 'agent-1': -0.6440850223956645, 'agent-2': -0.3497895818150383, 'agent-3': -0.8149723539581046} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.38981576777096194'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.28976600579756706'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.39664259868163754'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9238082772669713'}}}\n",
      "reward:  {'agent-0': 0.16944730331288582, 'agent-1': -0.13070198260729882, 'agent-2': 0.1899277960449126, 'agent-3': 1.771424831800914} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.036931108921088196'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.46994022931160373'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.29393850074079353'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.05366749272312177'}}}\n",
      "reward:  {'agent-0': -0.8892066732367354, 'agent-1': 0.4098206879348112, 'agent-2': -0.11818449777761941, 'agent-3': -0.8389975218306347} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2868841417126333'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6527309425555767'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.30784933444165574'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9248030107635685'}}}\n",
      "reward:  {'agent-0': -0.13934757486210003, 'agent-1': 0.9581928276667302, 'agent-2': -0.07645199667503277, 'agent-3': 1.7744090322907056} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.26966559814315616'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3359235967400309'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09274597875510082'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1901203856045548'}}}\n",
      "reward:  {'agent-0': -0.19100320557053152, 'agent-1': 0.007770790220092749, 'agent-2': -0.7217620637346975, 'agent-3': -0.4296388431863356} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.35757887784414066'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2128345451448581'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9880550996886797'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.0026967442439592'}}}\n",
      "reward:  {'agent-0': 0.07273663353242199, 'agent-1': -0.36149636456542567, 'agent-2': 1.964165299066039, 'agent-3': 2.0080902327318775} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7171227038406585'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.640933312906153'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.42465379853399554'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.16470134175054696'}}}\n",
      "reward:  {'agent-0': 1.1513681115219754, 'agent-1': 0.9227999387184589, 'agent-2': 0.2739613956019866, 'agent-3': -0.5058959747483591} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.17930833407860547'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4777156893628245'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.8278943955396159'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.24797524165855123'}}}\n",
      "reward:  {'agent-0': -0.4620749977641836, 'agent-1': 0.4331470680884735, 'agent-2': 1.4836831866188476, 'agent-3': -0.2560742750243463} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2479500834040067'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2706757477356305'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2657936291238485'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.2561497497879799, 'agent-2': -0.18797275679310843, 'agent-3': -0.20261911262845445} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.24234394597455378'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5122796422843408'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6690666193834609'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6458647201316978'}}}\n",
      "reward:  {'agent-0': -0.27296816207633867, 'agent-1': 0.5368389268530223, 'agent-2': 1.0071998581503827, 'agent-3': 0.9375941603950935} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3311794046893777'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.47192968497163434'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.00646178593186697, 'agent-2': 0.41578905491490303, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3951940547558479'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4843608372662871'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.011897967726483216'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11449277218649456'}}}\n",
      "reward:  {'agent-0': 0.1855821642675437, 'agent-1': 0.4530825117988613, 'agent-2': -0.9643060968205504, 'agent-3': -0.6565216834405163} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.25825168999590176'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06151787450856716'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.13809888777419843'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.18740823251240712'}}}\n",
      "reward:  {'agent-0': -0.22524493001229473, 'agent-1': -0.8154463764742985, 'agent-2': -0.5857033366774047, 'agent-3': -0.4377753024627786} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.08397770385444403'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06399244999533948'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.0360095589948841'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.06225020415364213'}}}\n",
      "reward:  {'agent-0': -0.7480668884366679, 'agent-1': -0.8080226500139815, 'agent-2': 2.1080286769846523, 'agent-3': -0.8132493875390736} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5552430697842681'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1083463231633548'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5959546761277714'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0624363896266118'}}}\n",
      "reward:  {'agent-0': 0.6657292093528042, 'agent-1': -0.6749610305099356, 'agent-2': 0.7878640283833143, 'agent-3': -0.8126908311201646} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.04200503034937242'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.46215449290252053'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.24388072997729182'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19576827937547492'}}}\n",
      "reward:  {'agent-0': -0.8739849089518827, 'agent-1': 0.3864634787075616, 'agent-2': -0.26835781006812454, 'agent-3': -0.41269516187357524} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3336735195550773'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6489928492645838'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.37851940390076066'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8433082869057102'}}}\n",
      "reward:  {'agent-0': 0.0010205586652318743, 'agent-1': 0.9469785477937513, 'agent-2': 0.135558211702282, 'agent-3': 1.5299248607171307} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.09474210653131365'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4895599008298319'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27555901774934455'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4116179541518932'}}}\n",
      "reward:  {'agent-0': -0.715773680406059, 'agent-1': 0.46867970248949575, 'agent-2': -0.17332294675196636, 'agent-3': 0.23485386245567952} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.023212747704221215'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.30507574605121945'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3604278887886103'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.01879469671668943'}}}\n",
      "reward:  {'agent-0': -0.9303617568873364, 'agent-1': -0.08477276184634164, 'agent-2': 0.08128366636583095, 'agent-3': -0.9436159098499317} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.24710443280737593'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6163153169244442'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.0058969798877655'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.054367526652654874'}}}\n",
      "reward:  {'agent-0': -0.2586867015778722, 'agent-1': 0.8489459507733326, 'agent-2': 2.0176909396632965, 'agent-3': -0.8368974200420354} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8527307032173397'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4117016005210825'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5386771205236371'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.055321787233154396'}}}\n",
      "reward:  {'agent-0': 1.558192109652019, 'agent-1': 0.23510480156324753, 'agent-2': 0.6160313615709114, 'agent-3': -0.8340346383005368} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.2281942399335364'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06990417704224683'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27598530548810274'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.14833789008788045'}}}\n",
      "reward:  {'agent-0': 2.684582719800609, 'agent-1': -0.7902874688732595, 'agent-2': -0.17204408353569178, 'agent-3': -0.5549863297363586} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.4042684004161714'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.05904818447710802'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09394084478992681'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9687274879881898'}}}\n",
      "reward:  {'agent-0': 3.212805201248514, 'agent-1': -0.8228554465686759, 'agent-2': -0.7181774656302196, 'agent-3': 1.9061824639645693} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.44172696487786567'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5357328953267047'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6889972366174533'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.25676941210357995'}}}\n",
      "reward:  {'agent-0': 0.325180894633597, 'agent-1': 0.607198685980114, 'agent-2': 1.0669917098523598, 'agent-3': -0.22969176368926014} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.29529782715621167'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7469503989838078'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.31887868945432274'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1089330186582629'}}}\n",
      "reward:  {'agent-0': -0.114106518531365, 'agent-1': 1.2408511969514233, 'agent-2': -0.04336393163703178, 'agent-3': 2.3267990559747886} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4393746520544042'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4414447561869821'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.40985883483350705'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.034068599149343015'}}}\n",
      "reward:  {'agent-0': 0.31812395616321254, 'agent-1': 0.32433426856094627, 'agent-2': 0.22957650450052114, 'agent-3': -0.897794202551971} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7271060513265155'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3151460347785928'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0004516660098374814'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3992491754013727'}}}\n",
      "reward:  {'agent-0': 1.1813181539795465, 'agent-1': -0.05456189566422154, 'agent-2': -0.9986450019704876, 'agent-3': 0.19774752620411817} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.009560397715212332'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6068142304764876'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1442113236793645'}}}\n",
      "reward:  {'agent-0': -1.028681193145637, 'agent-1': 0.8204426914294629, 'agent-2': -1.0, 'agent-3': -0.5673660289619065} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.2342815202736475'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5162103082665581'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3398258506048535'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.32546260557620244'}}}\n",
      "reward:  {'agent-0': 2.7028445608209424, 'agent-1': 0.5486309247996743, 'agent-2': 0.019477551814560456, 'agent-3': -0.023612183271392695} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7548934416670647'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4892019697111536'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1760399034264033'}}}\n",
      "reward:  {'agent-0': 1.2646803250011942, 'agent-1': 0.4676059091334608, 'agent-2': -1.0, 'agent-3': -0.4718802897207901} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.08421259521921343'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1047916514559244'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.809067870659554'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4217881009221429'}}}\n",
      "reward:  {'agent-0': -0.7473622143423597, 'agent-1': -0.6856250456322268, 'agent-2': 1.427203611978662, 'agent-3': 0.26536430276642875} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.014718755517549198'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08442826374161783'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.021120658157009586'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.09779323895842396'}}}\n",
      "reward:  {'agent-0': -0.9558437334473524, 'agent-1': -0.7467152087751465, 'agent-2': -0.9366380255289712, 'agent-3': -0.7066202831247281} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7349568166543676'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2380745543849443'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.37826787663157546'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2436186858903966'}}}\n",
      "reward:  {'agent-0': 1.2048704499631029, 'agent-1': -0.2857763368451671, 'agent-2': 0.13480362989472638, 'agent-3': -0.2691439423288102} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.143456485583215'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.319614549853636'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1782645178113711'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5338327840261528'}}}\n",
      "reward:  {'agent-0': -0.569630543250355, 'agent-1': -0.04115635043909194, 'agent-2': -0.4652064465658867, 'agent-3': 0.6014983520784583} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7490843665745572'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.15024099411336067'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.09854770391001466'}}}\n",
      "reward:  {'agent-0': 1.2472530997236717, 'agent-1': -0.549277017659918, 'agent-2': -1.0, 'agent-3': -0.704356888269956} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.06035091427207817'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2524161481160778'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7673903508630708'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4110863463687551'}}}\n",
      "reward:  {'agent-0': -0.8189472571837655, 'agent-1': -0.24275155565176654, 'agent-2': 1.3021710525892125, 'agent-3': 0.23325903910626522} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4399673554367922'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3362896983918269'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.004632012636115235'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.21588956371880386'}}}\n",
      "reward:  {'agent-0': 0.31990206631037665, 'agent-1': 0.008869095175480624, 'agent-2': -0.9861039620916543, 'agent-3': -0.35233130884358843} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.1060936390156897'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.40335362746674974'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.08179993697451948'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.39060211811359835'}}}\n",
      "reward:  {'agent-0': 2.318280917047069, 'agent-1': 0.21006088240024923, 'agent-2': -0.7546001890764416, 'agent-3': 0.17180635434079505} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4135844067851764'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5771060765152072'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.0, 'agent-2': 0.24075322035552915, 'agent-3': 0.7313182295456215} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6989521543153572'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7367538967209128'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.07832879803939363'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4608719351155699'}}}\n",
      "reward:  {'agent-0': 1.0968564629460715, 'agent-1': 1.2102616901627385, 'agent-2': -0.7650136058818191, 'agent-3': 0.3826158053467097} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.33431809486621944'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5735732327410688'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09040650566952024'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9302793402543621'}}}\n",
      "reward:  {'agent-0': 0.002954284598658319, 'agent-1': 0.7207196982232063, 'agent-2': -0.7287804829914393, 'agent-3': 1.7908380207630863} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2782792678268251'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2961607126786916'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4993807333014999'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2707368802100767'}}}\n",
      "reward:  {'agent-0': -0.16516219651952468, 'agent-1': -0.11151786196392521, 'agent-2': 0.4981421999044997, 'agent-3': -0.18778935936976993} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.21285480737441276'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.20783252225480453'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.03701773794621488'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1638523485506198'}}}\n",
      "reward:  {'agent-0': -0.3614355778767617, 'agent-1': -0.3765024332355864, 'agent-2': -0.8889467861613554, 'agent-3': -0.5084429543481406} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.048625026590727316'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7361811811537251'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.16535097920016995'}}}\n",
      "reward:  {'agent-0': -1.145875079772182, 'agent-1': 1.2085435434611753, 'agent-2': -1.0, 'agent-3': -0.5039470623994902} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5872099446913523'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4417396033829988'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.05916128668457432'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.46039472003336'}}}\n",
      "reward:  {'agent-0': 0.761629834074057, 'agent-1': 0.32521881014899634, 'agent-2': -0.822516139946277, 'agent-3': 0.38118416010008005} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.01027060782683975'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.36814954265366495'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3016795748095902'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.008010183764657341'}}}\n",
      "reward:  {'agent-0': -0.9691881765194807, 'agent-1': 0.10444862796099486, 'agent-2': -0.09496127557122946, 'agent-3': -0.975969448706028} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.45325855879315213'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2769974534197619'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2892761294607915'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.09190465657454183'}}}\n",
      "reward:  {'agent-0': 0.3597756763794564, 'agent-1': -0.1690076397407143, 'agent-2': -0.13217161161762547, 'agent-3': -0.7242860302763745} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8718422002639059'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4280667822451818'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7464299226122577'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4755894290754199'}}}\n",
      "reward:  {'agent-0': 1.6155266007917177, 'agent-1': 0.2842003467355454, 'agent-2': 1.2392897678367731, 'agent-3': 0.4267682872262597} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9446101983143578'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.117817790501423'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7653539999103387'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.36959866084963267'}}}\n",
      "reward:  {'agent-0': 1.8338305949430733, 'agent-1': 2.353453371504269, 'agent-2': 1.296061999731016, 'agent-3': 0.108795982548898} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.07342472323530558'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.537919371762797'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4107803636461327'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.937850845163986'}}}\n",
      "reward:  {'agent-0': -0.7797258302940833, 'agent-1': 0.6137581152883911, 'agent-2': 0.23234109093839805, 'agent-3': 1.813552535491958} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8785019581861988'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.198188323374195'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4780532760883638'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 1.6355058745585964, 'agent-1': -0.405435029877415, 'agent-2': 0.43415982826509136, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9448964774820467'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6675899164020542'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.01598311119027329'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 1.8346894324461402, 'agent-1': 1.0027697492061627, 'agent-2': -0.9520506664291801, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6830621607557177'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.17095064985588238'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.28520115918363587'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.036196444065417666'}}}\n",
      "reward:  {'agent-0': 1.049186482267153, 'agent-1': -0.4871480504323529, 'agent-2': -0.1443965224490924, 'agent-3': -0.891410667803747} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8202359288512611'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.024648412703854206'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.059393345735152536'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.17980963254435522'}}}\n",
      "reward:  {'agent-0': 1.4607077865537832, 'agent-1': -0.9260547618884374, 'agent-2': -0.8218199627945424, 'agent-3': -0.4605711023669343} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5135475400868117'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0916394857884626'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.5406426202604351, 'agent-1': -1.0, 'agent-2': -0.7250815426346122, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.15756895531859527'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08953520955931538'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.24237452967127382'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2998797898072354'}}}\n",
      "reward:  {'agent-0': -0.5272931340442142, 'agent-1': -0.7313943713220539, 'agent-2': -0.27287641098617854, 'agent-3': -0.10036063057829381} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6283910808675941'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1549466302526099'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9480127112313728'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6879493671209111'}}}\n",
      "reward:  {'agent-0': 0.8851732426027823, 'agent-1': -0.5351601092421703, 'agent-2': 1.8440381336941183, 'agent-3': 1.0638481013627334} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.992907266168757'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09694709589495609'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6998177918608661'}}}\n",
      "reward:  {'agent-0': 1.978721798506271, 'agent-1': -0.7091587123151317, 'agent-2': -1.0, 'agent-3': 1.0994533755825984} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.004293783820926933'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.23962188138597362'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7152360785490117'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1274368698458126'}}}\n",
      "reward:  {'agent-0': -0.9871186485372192, 'agent-1': -0.28113435584207913, 'agent-2': 1.1457082356470352, 'agent-3': -0.6176893904625622} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.03135621020128099'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.31983726773518306'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0062848397987096405'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.07265782004457222'}}}\n",
      "reward:  {'agent-0': -1.094068630603843, 'agent-1': -0.040488196794450815, 'agent-2': -0.9811454806038711, 'agent-3': -0.7820265398662833} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.33255196841692936'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3166025985216976'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.2581352201997476'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11160866715299278'}}}\n",
      "reward:  {'agent-0': -0.0023440947492119335, 'agent-1': -0.05019220443490724, 'agent-2': 2.7744056605992427, 'agent-3': -0.6651739985410217} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.47898721910903674'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5659578392536151'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3358997570015596'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.43491908466384643'}}}\n",
      "reward:  {'agent-0': 0.43696165732711023, 'agent-1': 0.6978735177608453, 'agent-2': 0.00769927100467882, 'agent-3': 0.3047572539915393} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4292033596810896'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8884297081690651'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27294245424512553'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3235698086856438'}}}\n",
      "reward:  {'agent-0': 0.28761007904326874, 'agent-1': 1.6652891245071952, 'agent-2': -0.1811726372646234, 'agent-3': -0.029290573943068665} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6022108281056688'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.028212271679976197'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4963494357356577'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2504796512347198'}}}\n",
      "reward:  {'agent-0': 0.8066324843170065, 'agent-1': -0.9153631849600714, 'agent-2': 0.4890483072069731, 'agent-3': -0.24856104629584053} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.12580117657521583'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.045017909908924736'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.07338155725253159'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2273499159354344'}}}\n",
      "reward:  {'agent-0': -0.6225964702743525, 'agent-1': -0.8649462702732258, 'agent-2': -0.7798553282424052, 'agent-3': -0.31795025219369677} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.061959239197982185'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1765148021855083'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.8141222824060534, 'agent-1': -0.4704555934434751, 'agent-2': -1.0, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.30255923755175473'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6007542797826115'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22904288006050422'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8934928665145812'}}}\n",
      "reward:  {'agent-0': -0.0923222873447358, 'agent-1': 0.8022628393478346, 'agent-2': -0.31287135981848735, 'agent-3': 1.6804785995437435} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2095936483819969'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.0590329541865486'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3390018661212366'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.3712190548540093, 'agent-2': 2.177098862559646, 'agent-3': 0.01700559836370985} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7044760059631372'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.15356641731501952'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4408726699706733'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7302034261128973'}}}\n",
      "reward:  {'agent-0': 1.1134280178894116, 'agent-1': -0.5393007480549414, 'agent-2': 0.32261800991201994, 'agent-3': 1.190610278338692} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.189682321709256'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.45439447211757944'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.334674175855028'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.28602998983715366'}}}\n",
      "reward:  {'agent-0': 2.569046965127768, 'agent-1': 0.3631834163527383, 'agent-2': 0.004022527565084033, 'agent-3': -0.141910030488539} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.1642277548305628'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06953315614711642'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4029773789904425'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.24299177508344982'}}}\n",
      "reward:  {'agent-0': 2.4926832644916885, 'agent-1': -0.7914005315586508, 'agent-2': 0.2089321369713275, 'agent-3': -0.27102467474965053} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.49175843042621636'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.03101242392365755'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2524047430150915'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.4752752912786491, 'agent-1': -0.9069627282290273, 'agent-2': -0.24278577095472542, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.22425853902667825'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.16955690216949115'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.36566119899536886'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7583658214640074'}}}\n",
      "reward:  {'agent-0': -0.32722438291996525, 'agent-1': -0.49132929349152654, 'agent-2': 0.09698359698610659, 'agent-3': 1.2750974643920223} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9466977487599308'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.009490742632792148'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.47471922359124363'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.2121940076252287'}}}\n",
      "reward:  {'agent-0': 1.8400932462797925, 'agent-1': -0.9715277721016236, 'agent-2': 0.4241576707737309, 'agent-3': 2.636582022875686} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5525056632065812'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.11802488756472229'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.019106976149771526'}}}\n",
      "reward:  {'agent-0': 0.6575169896197437, 'agent-1': -0.6459253373058331, 'agent-2': -1.0, 'agent-3': -0.9426790715506854} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5243694961382417'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.34896210401260674'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6325178105073359'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.07777493040352113'}}}\n",
      "reward:  {'agent-0': 0.5731084884147251, 'agent-1': 0.04688631203782023, 'agent-2': 0.8975534315220077, 'agent-3': -0.7666752087894366} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.26913079185649735'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5006923707247095'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3852862334523266'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.08026013605824645'}}}\n",
      "reward:  {'agent-0': -0.19260762443050794, 'agent-1': 0.5020771121741285, 'agent-2': 0.1558587003569798, 'agent-3': -0.7592195918252607} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9271691694750572'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.04073166493499514'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.25475340504348054'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.039354649435822'}}}\n",
      "reward:  {'agent-0': 1.7815075084251717, 'agent-1': -0.8778050051950146, 'agent-2': -0.23573978486955838, 'agent-3': 2.1180639483074657} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.004551992838052854'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6117819611464697'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3716455480670007'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.17939005676582553'}}}\n",
      "reward:  {'agent-0': -0.9863440214858414, 'agent-1': 0.835345883439409, 'agent-2': 0.11493664420100203, 'agent-3': -0.4618298297025234} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.029333232042993984'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.35084072933511834'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21213976708924065'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7557907203738949'}}}\n",
      "reward:  {'agent-0': -0.912000303871018, 'agent-1': 0.05252218800535502, 'agent-2': -0.36358069873227805, 'agent-3': 1.2673721611216848} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.086300149808153'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8565386506611148'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11959581746644332'}}}\n",
      "reward:  {'agent-0': 2.258900449424459, 'agent-1': 1.5696159519833444, 'agent-2': -1.0, 'agent-3': -0.64121254760067} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2614143115464884'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.27629952942474745'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21176223612370393'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.400920617312174'}}}\n",
      "reward:  {'agent-0': -0.21575706536053474, 'agent-1': -0.17110141172575766, 'agent-2': -0.3647132916288882, 'agent-3': 3.202761851936522} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4053929898576243'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.25671039115911753'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4927139297164196'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.21617896957287286, 'agent-2': -0.2298688265226474, 'agent-3': 0.47814178914925876} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1720550373714147'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10606424866628927'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.054767944573860916'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.26348940779277186'}}}\n",
      "reward:  {'agent-0': -0.4838348878857559, 'agent-1': -0.6818072540011322, 'agent-2': -0.8356961662784173, 'agent-3': -0.20953177662168443} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5595000670876829'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09849210913158402'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.920420465020328'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.14926224487455286'}}}\n",
      "reward:  {'agent-0': 0.6785002012630486, 'agent-1': -0.704523672605248, 'agent-2': 1.7612613950609841, 'agent-3': -0.5522132653763414} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.12549470874057533'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.018029979863861456'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.81759551083187'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2591201317696594'}}}\n",
      "reward:  {'agent-0': -0.623515873778274, 'agent-1': -0.9459100604084156, 'agent-2': 1.45278653249561, 'agent-3': -0.22263960469102173} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9794235997806666'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10977830956539947'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1131278197301846'}}}\n",
      "reward:  {'agent-0': 1.9382707993419999, 'agent-1': -1.0, 'agent-2': -0.6706650713038016, 'agent-3': 2.339383459190554} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.29676581524952184'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6641072359730211'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5708870480514356'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.10970255425143449, 'agent-1': 0.9923217079190634, 'agent-2': 0.7126611441543069, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.2840724772222742'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2938628119333515'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7433407243064352'}}}\n",
      "reward:  {'agent-0': 2.8522174316668227, 'agent-1': -1.0, 'agent-2': -0.11841156419994547, 'agent-3': 1.2300221729193055} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.20759910858478037'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1712414985059354'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3010670818670036'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1423794522289228'}}}\n",
      "reward:  {'agent-0': -0.3772026742456589, 'agent-1': -0.4862755044821938, 'agent-2': -0.09679875439898922, 'agent-3': -0.5728616433132316} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0017667228499558263'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22555982198507962'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7009047640648021'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.9946998314501325, 'agent-2': -0.32332053404476113, 'agent-3': 1.1027142921944062} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8839864349853244'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.11938035573739114'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5556526210852866'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7456078813323757'}}}\n",
      "reward:  {'agent-0': 1.651959304955973, 'agent-1': -0.6418589327878266, 'agent-2': 0.6669578632558597, 'agent-3': 1.236823643997127} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5853491422599006'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.17734555842943678'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.7560474267797019, 'agent-1': -1.0, 'agent-2': -0.46796332471168967, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4169959630011064'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09444681474309391'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.004195240465534766'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.41441822621554536'}}}\n",
      "reward:  {'agent-0': 0.25098788900331925, 'agent-1': -0.7166595557707183, 'agent-2': -0.9874142786033957, 'agent-3': 0.24325467864663608} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9809671343106956'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0008892187088918035'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.18773610770927007'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.9536884914894159'}}}\n",
      "reward:  {'agent-0': 1.9429014029320868, 'agent-1': -0.9973323438733246, 'agent-2': -0.4367916768721898, 'agent-3': 1.8610654744682478} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2627489957821183'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7782036954465212'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1992321592765265'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2596923891763723'}}}\n",
      "reward:  {'agent-0': -0.2117530126536451, 'agent-1': 1.3346110863395637, 'agent-2': -0.40230352217042054, 'agent-3': -0.22092283247088318} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19532043543287614'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.01817474439762634'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.8838965214212191'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.48986668177129644'}}}\n",
      "reward:  {'agent-0': -0.4140386937013716, 'agent-1': -0.945475766807121, 'agent-2': 1.6516895642636573, 'agent-3': 0.4696000453138893} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3662541300375892'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3110536265786834'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.23796536413639302'}}}\n",
      "reward:  {'agent-0': 0.09876239011276766, 'agent-1': -1.0, 'agent-2': -0.06683912026394978, 'agent-3': -0.28610390759082094} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5811923136844825'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7084753711424909'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.43219904786853647'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19821249821259812'}}}\n",
      "reward:  {'agent-0': 0.7435769410534476, 'agent-1': 1.1254261134274728, 'agent-2': 0.2965971436056094, 'agent-3': -0.40536250536220564} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.3690566878476176'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06021110763859383'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1980996374395545'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.35918302800230606'}}}\n",
      "reward:  {'agent-0': 3.1071700635428527, 'agent-1': -0.8193666770842185, 'agent-2': -0.4057010876813365, 'agent-3': 0.07754908400691818} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3367812963322834'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0813267651754046'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.36880382529160016'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.010343888996850126, 'agent-1': -0.7560197044737862, 'agent-2': 0.10641147587480049, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.21179640317705406'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6910940028242223'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.13552918589090268'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.02318285487409355'}}}\n",
      "reward:  {'agent-0': -0.3646107904688378, 'agent-1': 1.0732820084726669, 'agent-2': -0.593412442327292, 'agent-3': -1.0695485646222807} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3334827320886333'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6515089924585178'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.035013255940057775'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6070865481378327'}}}\n",
      "reward:  {'agent-0': 0.0004481962658999805, 'agent-1': 0.9545269773755534, 'agent-2': -0.8949602321798267, 'agent-3': 0.8212596444134981} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.05367473831674374'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07676437845345507'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10932907166808548'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.41761724120840427'}}}\n",
      "reward:  {'agent-0': -1.1610242149502312, 'agent-1': -0.7697068646396348, 'agent-2': -0.6720127849957436, 'agent-3': 0.2528517236252128} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.04245583712075529'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06619688848652139'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6515001585247688'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.02684527149679994'}}}\n",
      "reward:  {'agent-0': -0.8726324886377341, 'agent-1': -0.8014093345404358, 'agent-2': 0.9545004755743065, 'agent-3': -0.9194641855096002} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6501257245871344'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3113209621199431'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0825807123203326'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.9503771737614031, 'agent-2': -0.06603711364017073, 'agent-3': -0.7522578630390022} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.25409238938748757'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.18220982161493993'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0019204195315811745'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.23648034554598496'}}}\n",
      "reward:  {'agent-0': -0.23772283183753729, 'agent-1': -0.4533705351551802, 'agent-2': -0.9942387414052565, 'agent-3': -0.2905589633620451} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.04710341493058934'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06356551327281323'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5864099903954667'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.3633896472520348'}}}\n",
      "reward:  {'agent-0': -0.858689755208232, 'agent-1': -0.8093034601815603, 'agent-2': 0.7592299711864001, 'agent-3': 3.0901689417561045} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7253742021815022'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.12806048756951327'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8907832962734545'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 1.1761226065445065, 'agent-2': -0.6158185372914602, 'agent-3': 1.6723498888203636} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.0021049526853076372'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.42774142684927696'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6331087053888922'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.05036582643938914'}}}\n",
      "reward:  {'agent-0': -1.006314858055923, 'agent-1': 0.2832242805478309, 'agent-2': 0.8993261161666766, 'agent-3': -0.8489025206818326} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.1941720214934506'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.683369313693424'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4380077072620736'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.27130114310871534'}}}\n",
      "reward:  {'agent-0': 2.5825160644803518, 'agent-1': 1.050107941080272, 'agent-2': 0.3140231217862208, 'agent-3': -0.186096570673854} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.208081477752323'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5330816944982555'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.08639039195354314'}}}\n",
      "reward:  {'agent-0': -0.375755566743031, 'agent-1': -1.0, 'agent-2': 0.5992450834947665, 'agent-3': -0.7408288241393706} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.03703088438899016'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5078753358090609'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4253947792033017'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.663879591978457'}}}\n",
      "reward:  {'agent-0': -0.8889073468330295, 'agent-1': 0.5236260074271826, 'agent-2': 0.27618433760990513, 'agent-3': 0.9916387759353711} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.06548190312644664'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2161441989714774'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2729371179089952'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.8035542906206601, 'agent-1': -0.3515674030855678, 'agent-2': -0.18118864627301434, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.37036754548173434'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3167357982229513'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2580613401077443'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.036225654154570464'}}}\n",
      "reward:  {'agent-0': 0.11110263644520302, 'agent-1': -0.049792605331146156, 'agent-2': -0.22581597967676714, 'agent-3': -1.1086769624637114} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7744475418707495'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.49121372571272026'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2543066652905992'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.08393511526068664'}}}\n",
      "reward:  {'agent-0': 1.3233426256122485, 'agent-1': 0.4736411771381608, 'agent-2': -0.2370800041282024, 'agent-3': -0.7481946542179401} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.48313900296262347'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.03797531533449927'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5058279130866374'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6925668663964935'}}}\n",
      "reward:  {'agent-0': 0.4494170088878704, 'agent-1': -0.8860740539965022, 'agent-2': 0.5174837392599123, 'agent-3': 1.0777005991894804} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7426607072667792'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.16751517127034177'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3167627117220988'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.18550284643590587'}}}\n",
      "reward:  {'agent-0': 1.2279821218003377, 'agent-1': -0.4974544861889747, 'agent-2': -0.0497118648337036, 'agent-3': -0.4434914606922824} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.42496557849042205'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0035899849771112713'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.14801616592651357'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1861185263816765'}}}\n",
      "reward:  {'agent-0': 0.27489673547126614, 'agent-1': -0.9892300450686662, 'agent-2': -0.5559515022204593, 'agent-3': 2.5583555791450294} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.04362874228954894'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.004712579741237732'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2091619543241876'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.8691137731313532, 'agent-1': -1.0141377392237132, 'agent-2': -0.3725141370274372, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.38660514128001466'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.26625140400807634'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.20681022009546268'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.2446373173919483'}}}\n",
      "reward:  {'agent-0': 0.159815423840044, 'agent-1': -0.20124578797577097, 'agent-2': -0.37956933971361195, 'agent-3': 2.733911952175845} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3274619509617622'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09224580328004173'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9229878077885161'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.01254207869392232'}}}\n",
      "reward:  {'agent-0': -0.01761414711471332, 'agent-1': -0.7232625901598748, 'agent-2': 1.7689634233655482, 'agent-3': -0.962373763918233} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1085294466341935'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.0026445272071526915'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4057013128339122'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19678808383538993'}}}\n",
      "reward:  {'agent-0': -0.6744116600974195, 'agent-1': -1.007933581621458, 'agent-2': 0.2171039385017366, 'agent-3': -0.4096357484938302} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.043228015260289965'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2789918686321755'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09770544053171193'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6355444623252673'}}}\n",
      "reward:  {'agent-0': -0.8703159542191301, 'agent-1': -0.16302439410347347, 'agent-2': -0.7068836784048642, 'agent-3': 0.9066333869758019} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5030222668775437'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7479016340707219'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.11144269640885796'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.35040665459485965'}}}\n",
      "reward:  {'agent-0': 0.5090668006326311, 'agent-1': 1.2437049022121656, 'agent-2': -0.6656719107734261, 'agent-3': 0.05121996378457894} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.923875940751735'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.02179064714158585'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.181136864434702'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1291911935232406'}}}\n",
      "reward:  {'agent-0': 1.7716278222552049, 'agent-1': -0.9346280585752424, 'agent-2': -0.456589406695894, 'agent-3': -0.6124264194302782} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3165124165464448'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.16669582353467405'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.380601011890338'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.0316055389498082'}}}\n",
      "reward:  {'agent-0': 99.94953724963933, 'agent-1': 98.49991252939597, 'agent-2': 100.14180303567102, 'agent-3': 102.09481661684943} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2905070090440489'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5714468539668047'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.13560479629736477'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.12847897286785326, 'agent-2': 0.7143405619004142, 'agent-3': -0.5931856111079057} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5980965733793298'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.13028047869464388'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.37460255393006037'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2696605688465681'}}}\n",
      "reward:  {'agent-0': 0.7942897201379893, 'agent-1': -0.6091585639160684, 'agent-2': 0.1238076617901811, 'agent-3': -0.19101829346029575} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21571609677614845'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1472600664433408'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.0, 'agent-2': -0.35285170967155466, 'agent-3': 2.4417801993300223} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.2090223653798802'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.903240163329528'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.05078537020106921'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.04774605823828537'}}}\n",
      "reward:  {'agent-0': 2.6270670961396405, 'agent-1': 1.7097204899885838, 'agent-2': -0.8476438893967924, 'agent-3': -0.8567618252851439} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.881339739979687'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.33131149775456237'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.09641142681921266'}}}\n",
      "reward:  {'agent-0': 1.6440192199390609, 'agent-1': -0.006065506736312898, 'agent-2': -1.0, 'agent-3': -0.710765719542362} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.17511904484662466'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.031138279225757515'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.05954444843955997'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4380901225709053'}}}\n",
      "reward:  {'agent-0': -0.474642865460126, 'agent-1': -1.0934148376772725, 'agent-2': -0.8213666546813201, 'agent-3': 0.3142703677127159} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.15871229737496861'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.49751952099251184'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.11411537184731912'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.04471332605344713'}}}\n",
      "reward:  {'agent-0': -0.5238631078750942, 'agent-1': -2.4925585629775355, 'agent-2': -1.3423461155419574, 'agent-3': -0.8658600218396586} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.10648706975626965'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1405915590516429'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6399686867004775'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.17734548155024754'}}}\n",
      "reward:  {'agent-0': -1.319461209268809, 'agent-1': -0.5782253228450713, 'agent-2': 0.9199060601014324, 'agent-3': -0.4679635553492574} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.30448299442828386'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5484446662413234'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.15450624649069766'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.08655101671514842, 'agent-2': 0.6453339987239701, 'agent-3': -1.463518739472093} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.09850952309611927'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.3799041750670753'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3277357650287911'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -4.8943740740270414e-05'}}}\n",
      "reward:  {'agent-0': -0.7044714307116422, 'agent-1': -2.139712525201226, 'agent-2': -0.01679270491362672, 'agent-3': -1.0001468312222208} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.019554933495570026'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.33784149051907164'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.46704062699704707'}}}\n",
      "reward:  {'agent-0': -0.9413351995132899, 'agent-1': -1.0, 'agent-2': 0.013524471557214923, 'agent-3': 0.4011218809911412} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1823664314773481'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.12658158348578752'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.06115593235428207'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.4529007055679557, 'agent-1': -0.6202552495426374, 'agent-2': -1.1834677970628462, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4508718328185495'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2671096302842173'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.24381342947079787'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6876149295484097'}}}\n",
      "reward:  {'agent-0': 0.35261549845564844, 'agent-1': -0.1986711091473481, 'agent-2': -0.2685597115876064, 'agent-3': 1.0628447886452292} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.12721931615214288'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.08293176903353583'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.11413200891527708'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11745208274592045'}}}\n",
      "reward:  {'agent-0': -0.6183420515435714, 'agent-1': -1.2487953071006075, 'agent-2': -1.3423960267458313, 'agent-3': -0.6476437517622387} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.14449130459651371'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7943989124349713'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5327343966175704'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.26793131000074766'}}}\n",
      "reward:  {'agent-0': -0.5665260862104589, 'agent-1': 1.3831967373049139, 'agent-2': 0.5982031898527111, 'agent-3': -0.19620606999775703} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2341413186838821'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.07480218318987397'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.26510900979580754'}}}\n",
      "reward:  {'agent-0': -0.2975760439483537, 'agent-1': -1.224406549569622, 'agent-2': -1.0, 'agent-3': -0.2046729706125774} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0684279139466355'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22299531578208587'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.16265099121051207'}}}\n",
      "reward:  {'agent-0': -0.7947162581600935, 'agent-1': -1.0, 'agent-2': -0.3310140526537424, 'agent-3': -0.5120470263684638} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.16636115972708865'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5507361906041126'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.27971865334578894'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.5009165208187341, 'agent-2': 0.6522085718123378, 'agent-3': -0.1608440399626332} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9710007025935852'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19721915491521713'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5597725426193136'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 1.9130021077807555, 'agent-2': -0.4083425352543486, 'agent-3': 0.6793176278579409} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.40009880976673884'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5128213998173834'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19723947268134978'}}}\n",
      "reward:  {'agent-0': 0.20029642930021652, 'agent-1': 0.5384641994521502, 'agent-2': -1.0, 'agent-3': -0.40828158195595066} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.38364382107073425'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.45377414357852786'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.05969851574481311'}}}\n",
      "reward:  {'agent-0': 0.15093146321220274, 'agent-1': 0.36132243073558357, 'agent-2': -1.0, 'agent-3': -1.1790955472344393} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.07992611041643727'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19160722124155427'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.03519090652035217'}}}\n",
      "reward:  {'agent-0': -0.7602216687506882, 'agent-1': -1.0, 'agent-2': -0.4251783362753372, 'agent-3': -1.1055727195610565} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.019297180504523226'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5795363451443052'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19226766007126628'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2062825997133899'}}}\n",
      "reward:  {'agent-0': -1.0578915415135697, 'agent-1': 0.7386090354329156, 'agent-2': -0.42319701978620117, 'agent-3': -0.38115220085983026} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5411411074431101'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.04058959464127554'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.71117858587494'}}}\n",
      "reward:  {'agent-0': 0.6234233223293302, 'agent-1': -0.8782312160761734, 'agent-2': -1.0, 'agent-3': 1.13353575762482} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5642163405306633'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.770317031986977'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.02732148579301'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3564255240313621'}}}\n",
      "reward:  {'agent-0': 0.6926490215919898, 'agent-1': 1.310951095960931, 'agent-2': 2.08196445737903, 'agent-3': 0.06927657209408622} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.17264106298594584'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2173950867871497'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2927026946842801'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.034485908177781965'}}}\n",
      "reward:  {'agent-0': -1.5179231889578375, 'agent-1': -0.3478147396385509, 'agent-2': -0.12189191594715965, 'agent-3': -0.8965422754666541} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.027439458148194262'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7521000610105943'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.013461613103530112'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3617342245915225'}}}\n",
      "reward:  {'agent-0': -0.9176816255554172, 'agent-1': 1.256300183031783, 'agent-2': -1.0403848393105903, 'agent-3': 0.08520267377456747} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.03675026667652048'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.22549976953247608'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10652686696266755'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5528381808463187'}}}\n",
      "reward:  {'agent-0': -0.8897491999704386, 'agent-1': -0.32350069140257176, 'agent-2': -0.6804193991119973, 'agent-3': 0.6585145425389562} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9435545137932735'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5262689147703341'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.14978972687904957'}}}\n",
      "reward:  {'agent-0': 1.8306635413798205, 'agent-1': -1.0, 'agent-2': 0.5788067443110023, 'agent-3': -0.5506308193628513} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.03474998678751007'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.10916073732369114'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.567256934118376'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.05871985169921956'}}}\n",
      "reward:  {'agent-0': -0.8957500396374698, 'agent-1': -1.3274822119710734, 'agent-2': 0.7017708023551279, 'agent-3': -0.8238404449023413} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.07570895807789668'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.08149084124275419'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2171771193292642'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.18815790932398713'}}}\n",
      "reward:  {'agent-0': -1.22712687423369, 'agent-1': -1.2444725237282626, 'agent-2': -0.3484686420122074, 'agent-3': -0.4355262720280386} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4606150134281819'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07440004362295127'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.377938400596193'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7135971187337162'}}}\n",
      "reward:  {'agent-0': 0.3818450402845457, 'agent-1': -0.7767998691311462, 'agent-2': 0.13381520178857897, 'agent-3': 1.1407913562011487} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.29153515433724664'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10600132200021761'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4753298027041808'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.21561914876988197'}}}\n",
      "reward:  {'agent-0': -0.12539453698826009, 'agent-1': -0.6819960339993472, 'agent-2': 0.4259894081125424, 'agent-3': -0.3531425536903541} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.119044842809572'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7227342951267559'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3637888100821485'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 2.357134528428716, 'agent-2': 1.1682028853802677, 'agent-3': 0.09136643024644542} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1036221399794286'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.19453962905471656'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09694559234710098'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.07709734591410466'}}}\n",
      "reward:  {'agent-0': -0.6891335800617142, 'agent-1': -0.41638111283585033, 'agent-2': -0.709163222958697, 'agent-3': -0.768707962257686} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.35121479975285297'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9525802967330037'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4891255735161728'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6446008990730121'}}}\n",
      "reward:  {'agent-0': 0.053644399258558906, 'agent-1': 1.8577408901990111, 'agent-2': 0.4673767205485184, 'agent-3': 0.9338026972190363} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9144957473834978'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.1238523412128103'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.14317166548715932'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8694700493046525'}}}\n",
      "reward:  {'agent-0': 1.7434872421504934, 'agent-1': -1.371557023638431, 'agent-2': -0.570485003538522, 'agent-3': 1.6084101479139576} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.1792221065332598'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.03277185048868603'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19630241826539319'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8319172930059935'}}}\n",
      "reward:  {'agent-0': 2.5376663195997793, 'agent-1': -0.9016844485339419, 'agent-2': -0.41109274520382044, 'agent-3': 1.4957518790179805} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3662122407510324'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2802775334380243'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.009784315995322146'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.038873803559884124'}}}\n",
      "reward:  {'agent-0': 0.09863672225309728, 'agent-1': -0.15916739968592708, 'agent-2': -1.0293529479859664, 'agent-3': -0.8833785893203476} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6425983721952022'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.15206553440972925'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 1.286775440023277'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3861288099179774'}}}\n",
      "reward:  {'agent-0': 0.9277951165856066, 'agent-1': -1.4561966032291878, 'agent-2': 2.860326320069831, 'agent-3': 0.15838642975393213} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.31319029544204113'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.3126910558542022'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3302022524181609'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15763747286834473'}}}\n",
      "reward:  {'agent-0': -0.0604291136738766, 'agent-1': 2.9380731675626066, 'agent-2': -0.009393242745517227, 'agent-3': -0.5270875813949658} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.23626746017154687'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.17679691263831643'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.314374269970493'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.137999106441562'}}}\n",
      "reward:  {'agent-0': -0.2911976194853594, 'agent-1': -0.4696092620850507, 'agent-2': -0.05687719008852099, 'agent-3': -0.586002680675314} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9931089670534092'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.5861464268316041'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.42618038063456964'}}}\n",
      "reward:  {'agent-0': 1.9793269011602277, 'agent-1': -2.7584392804948124, 'agent-2': -1.0, 'agent-3': 0.27854114190370893} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5865850333588511'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6821390619282894'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.00010100573617677355'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.09789653434842194'}}}\n",
      "reward:  {'agent-0': 0.7597551000765534, 'agent-1': 1.0464171857848683, 'agent-2': -1.0003030172085303, 'agent-3': -0.7063103969547342} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.39971219096238286'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.2132011664884743'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.24139652294799419'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12081545365223789'}}}\n",
      "reward:  {'agent-0': 0.1991365728871486, 'agent-1': 2.639603499465423, 'agent-2': -0.27581043115601744, 'agent-3': -0.6375536390432863} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0039499352690768'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.24001900121778874'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.059739189869887355'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.23717875913741437'}}}\n",
      "reward:  {'agent-0': 2.0118498058072305, 'agent-1': -0.2799429963466338, 'agent-2': -0.8207824303903379, 'agent-3': -0.2884637225877569} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.4055496035563877'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.006601982334984768'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09999999672152171'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.34204396916105395'}}}\n",
      "reward:  {'agent-0': 3.216648810669163, 'agent-1': -1.0198059470049543, 'agent-2': -0.7000000098354349, 'agent-3': 0.026131907483161854} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3754986983471724'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2831961635208664'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.016437070921099917'}}}\n",
      "reward:  {'agent-0': 0.12649609504151726, 'agent-1': -1.0, 'agent-2': -0.15041150943740078, 'agent-3': -0.9506887872367003} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0875172710524623'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9146974753701329'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4492976308397374'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.46045023937640295'}}}\n",
      "reward:  {'agent-0': 2.262551813157387, 'agent-1': 1.7440924261103987, 'agent-2': 0.3478928925192122, 'agent-3': 0.38135071812920884} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3212129761096847'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6050523157307026'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.06504341815001169'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.002652048548760888'}}}\n",
      "reward:  {'agent-0': -0.03636107167094593, 'agent-1': 0.8151569471921079, 'agent-2': -1.195130254450035, 'agent-3': -0.9920438543537173} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.26774316861101255'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06744928710602949'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.574790855042707'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8407738010978996'}}}\n",
      "reward:  {'agent-0': -0.19677049416696235, 'agent-1': -0.7976521386819115, 'agent-2': 0.724372565128121, 'agent-3': 1.5223214032936987} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.012039051722595673'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6194693118580687'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.19474852505989304'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.16989929026549078'}}}\n",
      "reward:  {'agent-0': -1.036117155167787, 'agent-1': 0.8584079355742062, 'agent-2': -0.4157544248203209, 'agent-3': -0.49030212920352767} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.32887783687922223'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08428576285668044'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4097617182001443'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11501906281540641'}}}\n",
      "reward:  {'agent-0': -0.013366489362333311, 'agent-1': -0.7471427114299587, 'agent-2': 0.22928515460043286, 'agent-3': -0.6549428115537808} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1343541441795182'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.20597458848659755'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.09119257503698108'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12321620569916547'}}}\n",
      "reward:  {'agent-0': -0.5969375674614454, 'agent-1': -0.38207623454020734, 'agent-2': -0.7264222748890568, 'agent-3': -0.6303513829025036} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.01882411300911002'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1727889730111727'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.07325449422455677'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.05647233902733, 'agent-2': -0.48163308096648194, 'agent-3': -0.7802365173263297} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.012410503558847097'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1578098776791066'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.34701948942708327'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11303491490737017'}}}\n",
      "reward:  {'agent-0': -1.0372315106765413, 'agent-1': -0.5265703669626802, 'agent-2': 0.041058468281249816, 'agent-3': -0.6608952552778895} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.34378376968179936'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2598219653121525'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.14102624073319703'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.10162996465044749'}}}\n",
      "reward:  {'agent-0': 0.03135130904539807, 'agent-1': -0.22053410406354246, 'agent-2': -0.5769212778004089, 'agent-3': -1.3048898939513425} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.37727727625999563'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07997892606269019'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6671590328843209'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 0.1318318287799869, 'agent-1': -0.7600632218119294, 'agent-2': 1.0014770986529626, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2417874495607606'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10560932160322523'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6736314853463661'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4901608395571362'}}}\n",
      "reward:  {'agent-0': -0.2746376513177182, 'agent-1': -0.6831720351903243, 'agent-2': 1.0208944560390982, 'agent-3': 0.47048251867140856} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6606203706114968'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1357055866073722'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5191744546320507'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2570526592010225'}}}\n",
      "reward:  {'agent-0': 0.9818611118344904, 'agent-1': -0.5928832401778834, 'agent-2': 0.5575233638961521, 'agent-3': -0.22884202239693252} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.13639826774979014'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07942636105296685'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.23500062582343162'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.04737229348179106'}}}\n",
      "reward:  {'agent-0': -0.5908051967506296, 'agent-1': -0.7617209168410994, 'agent-2': -0.29499812252970514, 'agent-3': -1.1421168804453732} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.004351710577253698'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8830997275662398'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5506818329051839'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1359360907740221'}}}\n",
      "reward:  {'agent-0': -0.9869448682682389, 'agent-1': 1.6492991826987193, 'agent-2': 0.6520454987155517, 'agent-3': 2.4078082723220664} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.07562099391790866'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.899310195047434'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.18090856342280404'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3183573799263435'}}}\n",
      "reward:  {'agent-0': -1.226862981753726, 'agent-1': 1.697930585142302, 'agent-2': -0.4572743097315879, 'agent-3': -0.04492786022096951} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.008777173046397024'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.0245933673147967'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.398682427143374'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.08684104764580525'}}}\n",
      "reward:  {'agent-0': -0.9736684808608089, 'agent-1': 2.07378010194439, 'agent-2': 0.19604728143012196, 'agent-3': -1.2605231429374157} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.14325351236084316'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.19332974236223777'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6135811210256747'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.5702394629174705, 'agent-1': -0.4200107729132867, 'agent-2': 0.8407433630770242, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.20185023263451285'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.23983995594542762'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3949939257810158'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4177764093622045'}}}\n",
      "reward:  {'agent-0': -0.39444930209646145, 'agent-1': -0.28048013216371714, 'agent-2': 0.18498177734304733, 'agent-3': 0.2533292280866135} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.21916838595440424'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4995692394960116'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.36575146597509445'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6029610083838737'}}}\n",
      "reward:  {'agent-0': -1.6575051578632127, 'agent-1': 0.49870771848803486, 'agent-2': 0.09725439792528334, 'agent-3': 0.808883025151621} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.21343445190762722'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.15674762854379765'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.35969664427711834, 'agent-2': -0.5297571143686071, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.35714818078804456'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.37015491590336325'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6993507945430402'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.07144454236413367, 'agent-2': 0.11046474771008974, 'agent-3': 1.0980523836291205} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.29825809982780527'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5738711683856224'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5210882205673926'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.1052257005165842, 'agent-1': 0.7216135051568671, 'agent-2': 0.5632646617021777, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0351797472510853'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.48261446574892375'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.0838721789638015'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 2.105539241753256, 'agent-1': 0.44784339724677125, 'agent-2': -0.7483834631085955, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.13643134073065966'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.11256356231611875'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.04526194561038466'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.001859890406215925'}}}\n",
      "reward:  {'agent-0': -0.590705977808021, 'agent-1': -1.3376906869483562, 'agent-2': -0.864214163168846, 'agent-3': -0.9944203287813522} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.12703398550592482'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.014080760508889512'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2526943391978733'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7026845390791951'}}}\n",
      "reward:  {'agent-0': -0.6188980434822255, 'agent-1': -1.0422422815266685, 'agent-2': -0.24191698240638004, 'agent-3': 1.1080536172375854} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.1621143140879582'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7731102083244217'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.011262422330531763'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.29048834969353265'}}}\n",
      "reward:  {'agent-0': 2.4863429422638745, 'agent-1': 1.319330624973265, 'agent-2': -0.9662127330084047, 'agent-3': -0.12853495091940204} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.029177846489353954'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2584224972539033'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.12124427504252822'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1503948791393945'}}}\n",
      "reward:  {'agent-0': -1.0875335394680619, 'agent-1': -0.22473250823829005, 'agent-2': -0.6362671748724154, 'agent-3': 2.4511846374181836} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.10483550559179378'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.32527029458358925'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.10993591692632876'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.11936172325084726'}}}\n",
      "reward:  {'agent-0': -0.6854934832246187, 'agent-1': -0.024189116249232256, 'agent-2': -0.6701922492210137, 'agent-3': -1.3580851697525418} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.9106137641648786'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.09757624199841075'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.892542742067505'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.755456704823354'}}}\n",
      "reward:  {'agent-0': 1.7318412924946358, 'agent-1': -1.2927287259952323, 'agent-2': 1.6776282262025148, 'agent-3': 1.266370114470062} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.21728936733701687'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.20879614056840978'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.042827099177404904'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.481048119513245'}}}\n",
      "reward:  {'agent-0': -0.3481318979889494, 'agent-1': -1.6263884217052293, 'agent-2': -0.8715187024677853, 'agent-3': 0.443144358539735} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.032249534360538235'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.03358990433022768'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.22151098496919985'}}}\n",
      "reward:  {'agent-0': -0.9032513969183853, 'agent-1': -1.0, 'agent-2': -0.899230287009317, 'agent-3': -0.33546704509240044} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.09829366006091789'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3755096471122812'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.56066344364916'}}}\n",
      "reward:  {'agent-0': -1.2948809801827537, 'agent-1': -1.0, 'agent-2': 0.12652894133684356, 'agent-3': 0.68199033094748} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.10033548608435439'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.020310910779286928'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5268249623214025'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6644750089554972'}}}\n",
      "reward:  {'agent-0': -0.6989935417469368, 'agent-1': -1.0609327323378608, 'agent-2': 0.5804748869642076, 'agent-3': 0.9934250268664915} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.47092071278041914'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.24896375155313422'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5122549651950834'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3917222260401072'}}}\n",
      "reward:  {'agent-0': 0.4127621383412574, 'agent-1': -1.7468912546594026, 'agent-2': 0.5367648955852502, 'agent-3': 0.1751666781203216} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5148351777658036'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.04017097188084051'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.35293833513375716'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.37090838417532623'}}}\n",
      "reward:  {'agent-0': 0.5445055332974107, 'agent-1': -0.8794870843574785, 'agent-2': 0.05881500540127149, 'agent-3': 0.1127251525259787} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.06744735338841679'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.14735849534127965'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19578247035647678'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.2023420601652504, 'agent-2': -0.557924513976161, 'agent-3': -0.41265258893056966} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.31296560367838566'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.682794472761671'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.26515322775092187'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.566843493803475'}}}\n",
      "reward:  {'agent-0': -0.061103188964843014, 'agent-1': 1.0483834182850131, 'agent-2': -0.20454031674723439, 'agent-3': 0.700530481410425} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5277369110596055'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.022728129653614815'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2934886973004467'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8917458805308689'}}}\n",
      "reward:  {'agent-0': 0.5832107331788166, 'agent-1': -0.9318156110391556, 'agent-2': -0.11953390809865994, 'agent-3': 1.6752376415926067} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4702119794983659'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0035458176077654002'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6141142277053255'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.07611262676818242'}}}\n",
      "reward:  {'agent-0': 0.4106359384950977, 'agent-1': -0.9893625471767038, 'agent-2': 0.8423426831159766, 'agent-3': -0.7716621196954527} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.18973297298878578'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.14666508827903257'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.4308010810336427, 'agent-1': -1.0, 'agent-2': -0.5600047351629023, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.13737888954499766'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.02094383042691561'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9071253606042369'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3518162421234283'}}}\n",
      "reward:  {'agent-0': -0.587863331365007, 'agent-1': -0.9371685087192532, 'agent-2': 1.7213760818127106, 'agent-3': 0.05544872637028497} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.017412181218695366'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.016226903569414475'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.38448989686901935'}}}\n",
      "reward:  {'agent-0': -0.9477634563439139, 'agent-1': -1.0, 'agent-2': -0.9513192892917566, 'agent-3': 0.15346969060705806} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.24570720017347725'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.06191447064725253'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.8562776956420741'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12073835932258703'}}}\n",
      "reward:  {'agent-0': -0.26287839947956826, 'agent-1': -0.8142565880582424, 'agent-2': 1.5688330869262224, 'agent-3': -0.6377849220322389} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19104011493677575'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.31721548384717835'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27476576414719034'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.015044138184459932'}}}\n",
      "reward:  {'agent-0': -0.42687965518967275, 'agent-1': -1.951646451541535, 'agent-2': -0.17570270755842898, 'agent-3': -0.9548675854466202} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6471669838057963'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.39715183893967776'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.46768096397546444'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6601350470420648'}}}\n",
      "reward:  {'agent-0': 0.9415009514173889, 'agent-1': -2.1914555168190333, 'agent-2': 0.4030428919263933, 'agent-3': 0.9804051411261945} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8080686907478736'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.060262234886828026'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.015123225194557222'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': 1.4242060722436207, 'agent-1': -1.180786704660484, 'agent-2': -0.9546303244163283, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5225729518297229'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.05036697546422886'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.14088217335338982'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4618513648576492'}}}\n",
      "reward:  {'agent-0': 0.5677188554891686, 'agent-1': -0.8488990736073134, 'agent-2': -0.5773534799398305, 'agent-3': 0.38555409457294765} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.11132846617181258'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7133897280441346'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.22828750756116278'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.25947790895815714'}}}\n",
      "reward:  {'agent-0': -0.6660146014845623, 'agent-1': 1.1401691841324038, 'agent-2': -0.31513747731651165, 'agent-3': -0.22156627312552857} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2847419911310993'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.2662199030623569'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.07747729609447873'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.20068033046810285'}}}\n",
      "reward:  {'agent-0': 99.8542259733933, 'agent-1': 98.20134029081294, 'agent-2': 98.76756811171657, 'agent-3': 98.39795900859569} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3813041073982504'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8456900448136011'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.10336020750004948'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3847131335158167'}}}\n",
      "reward:  {'agent-0': 0.14391232219475114, 'agent-1': 1.5370701344408033, 'agent-2': -1.3100806225001485, 'agent-3': 0.15413940054745012} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.40518775870293666'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.7504660009476396'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.1716333835073307'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.368882949263579'}}}\n",
      "reward:  {'agent-0': -2.21556327610881, 'agent-1': -3.251398002842919, 'agent-2': -1.5149001505219921, 'agent-3': -2.106648847790737} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.8552282105713331'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.3585551423972362'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.18926751502847594'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7374309454182821'}}}\n",
      "reward:  {'agent-0': -3.5656846317139994, 'agent-1': -2.0756654271917085, 'agent-2': -0.4321974549145722, 'agent-3': 1.2122928362548464} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.0176987591043698'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6513941158758314'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.06862119500005193'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.01861376944765425'}}}\n",
      "reward:  {'agent-0': -1.0530962773131094, 'agent-1': 0.9541823476274942, 'agent-2': -1.2058635850001558, 'agent-3': -0.9441586916570373} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.23051755022755316'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5368135355168064'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.19088038462466983'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.22423700905517308'}}}\n",
      "reward:  {'agent-0': -0.3084473493173405, 'agent-1': 0.6104406065504193, 'agent-2': -1.5726411538740095, 'agent-3': -1.6727110271655192} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.9797743752472385'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1528905038506565'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5564136447889894'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5031969724989835'}}}\n",
      "reward:  {'agent-0': -3.9393231257417156, 'agent-1': -0.5413284884480305, 'agent-2': 0.6692409343669681, 'agent-3': 0.5095909174969506} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5030496872890495'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5183271668641396'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1715668102892458'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.09888740251945194'}}}\n",
      "reward:  {'agent-0': 0.5091490618671486, 'agent-1': 0.5549815005924188, 'agent-2': -0.4852995691322626, 'agent-3': -1.2966622075583558} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3035268317484352'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.043134272222239645'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.11358000225479259'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.29286174499353024'}}}\n",
      "reward:  {'agent-0': -0.0894195047546944, 'agent-1': -0.8705971833332811, 'agent-2': -0.6592599932356222, 'agent-3': -1.8785852349805907} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -1.006798274988597'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.0960102584769622'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.5175452772397726'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.4223819210580899'}}}\n",
      "reward:  {'agent-0': -4.020394824965791, 'agent-1': 2.2880307754308866, 'agent-2': -2.552635831719318, 'agent-3': 0.26714576317426975} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.8510220787368397'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.07590045438541182'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7841477458697668'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.24924284926180462'}}}\n",
      "reward:  {'agent-0': -3.553066236210519, 'agent-1': -1.2277013631562355, 'agent-2': 1.3524432376093003, 'agent-3': -0.25227145221458613} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.05146500833424028'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.2989244198609242'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.625582860168322'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.77858764842901'}}}\n",
      "reward:  {'agent-0': -1.1543950250027208, 'agent-1': 2.8967732595827727, 'agent-2': 0.876748580504966, 'agent-3': 1.3357629452870299} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8816866112066322'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.18800267569045914'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4766663212937168'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.6330726997766192'}}}\n",
      "reward:  {'agent-0': 1.6450598336198965, 'agent-1': -0.4359919729286226, 'agent-2': 0.42999896388115033, 'agent-3': -2.8992180993298575} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.3802925599798286'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.6832594462247847'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.1361786566014267'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.26216453336540724'}}}\n",
      "reward:  {'agent-0': -2.1408776799394857, 'agent-1': -3.049778338674354, 'agent-2': -1.40853596980428, 'agent-3': -0.2135063999037783} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.8685808719855004'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8907675786415048'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3687882459575462'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.011470703733266419'}}}\n",
      "reward:  {'agent-0': -3.605742615956501, 'agent-1': 1.6723027359245144, 'agent-2': 0.10636473787263867, 'agent-3': -1.0344121111997993} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6707625346489365'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.1780182818895923'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.45858696919190756'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.2041400727510876'}}}\n",
      "reward:  {'agent-0': 1.0122876039468096, 'agent-1': 2.534054845668777, 'agent-2': 0.37576090757572267, 'agent-3': -1.6124202182532628} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6204535054786149'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.5711496902645088'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1787101103785549'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.59178137123385'}}}\n",
      "reward:  {'agent-0': 0.8613605164358447, 'agent-1': -2.7134490707935264, 'agent-2': -0.46386966886433534, 'agent-3': -2.77534411370155} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.36587595936551054'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.09695498288744986'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6943659940494022'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.7898765967077708'}}}\n",
      "reward:  {'agent-0': -2.0976278780965316, 'agent-1': -0.7091350513376504, 'agent-2': 1.0830979821482067, 'agent-3': -3.3696297901233123} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4047945486630766'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5927967554027305'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6603516064016226'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.11549639018389257'}}}\n",
      "reward:  {'agent-0': 0.21438364598922988, 'agent-1': 0.7783902662081914, 'agent-2': 0.9810548192048678, 'agent-3': -0.6535108294483223} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0051066531123140635'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.1071173568789874'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.04372815401836583'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.38399525155220715'}}}\n",
      "reward:  {'agent-0': -0.9846800406630578, 'agent-1': 2.321352070636962, 'agent-2': -1.1311844620550975, 'agent-3': 0.15198575465662145} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.10022009016250877'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.40512254465382824'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.046043490474913185'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15349068149026834'}}}\n",
      "reward:  {'agent-0': -1.3006602704875263, 'agent-1': 0.21536763396148473, 'agent-2': -0.8618695285752604, 'agent-3': -0.539527955529195} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.4266107796356593'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.272056898689808'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.06984425281410012'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -1.2396781598577888'}}}\n",
      "reward:  {'agent-0': -2.279832338906978, 'agent-1': -0.18382930393057606, 'agent-2': -0.7904672415576997, 'agent-3': -4.7190344795733665} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.1089142596834662'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.7513492503944725'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2804034792639509'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.01103584186853368'}}}\n",
      "reward:  {'agent-0': 2.3267427790503987, 'agent-1': -3.2540477511834176, 'agent-2': -0.15878956220814722, 'agent-3': -1.033107525605601} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.28624133106608696'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.37678483929312634'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.01923136320523433'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.551830113678875'}}}\n",
      "reward:  {'agent-0': -0.14127600680173913, 'agent-1': -2.130354517879379, 'agent-2': -1.057694089615703, 'agent-3': -2.655490341036625} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.38277720976700635'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.45383351945409345'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.5400716190208144'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2752186205429439'}}}\n",
      "reward:  {'agent-0': 0.14833162930101906, 'agent-1': 0.36150055836228034, 'agent-2': -2.620214857062443, 'agent-3': -0.17434413837116836} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.29302372165398083'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.14796358860255943'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.27241130509860056'}}}\n",
      "reward:  {'agent-0': -0.12092883503805751, 'agent-1': -1.0, 'agent-2': -1.4438907658076783, 'agent-3': -0.1827660847041983} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5587501492118605'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.4199122615729074'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.18327990343235356'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.008520962210667449'}}}\n",
      "reward:  {'agent-0': 0.6762504476355815, 'agent-1': 0.2597367847187222, 'agent-2': -1.5498397102970607, 'agent-3': -1.0255628866320023} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.6933961458885918'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.26309901806044067'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.13282113747647095'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19520358540397353'}}}\n",
      "reward:  {'agent-0': -3.0801884376657753, 'agent-1': -1.789297054181322, 'agent-2': -1.3984634124294129, 'agent-3': -0.4143892437880794} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.0766315613812623'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.2662605730211638'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3682622290482449'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.12766902143427217'}}}\n",
      "reward:  {'agent-0': 2.2298946841437868, 'agent-1': -1.7987817190634914, 'agent-2': 0.10478668714473471, 'agent-3': -0.6169929356971835} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.26724916934642096'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.02247370415127392'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.8040617602906224'}}}\n",
      "reward:  {'agent-0': -0.19825249196073713, 'agent-1': -1.0, 'agent-2': -0.9325788875461782, 'agent-3': -3.412185280871867} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.7126403886733499'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.07310136743878104'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.4517168206265225'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1094507932718045'}}}\n",
      "reward:  {'agent-0': -3.1379211660200497, 'agent-1': -0.7806958976836569, 'agent-2': -2.3551504618795676, 'agent-3': 2.3283523798154135} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.14802073023099638'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.07387570141433741'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.07602111103620679'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.46680051148115353'}}}\n",
      "reward:  {'agent-0': -0.5559378093070109, 'agent-1': -1.2216271042430122, 'agent-2': -1.2280633331086204, 'agent-3': 0.4004015344434606} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.10316030981397262'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.040583350967136056'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.17452525102865302'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.460580395501637'}}}\n",
      "reward:  {'agent-0': -0.6905190705580821, 'agent-1': -0.8782499470985918, 'agent-2': -1.523575753085959, 'agent-3': 0.38174118650491096} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.05997896149998638'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -1.1542186255507048'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9256241960615483'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.04794912388899775'}}}\n",
      "reward:  {'agent-0': -0.8200631155000409, 'agent-1': -4.462655876652114, 'agent-2': 1.776872588184645, 'agent-3': -0.8561526283330068} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.32759386905003396'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.11349718181990553'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.012102133892220479'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.49278402819182077'}}}\n",
      "reward:  {'agent-0': -0.017218392849898123, 'agent-1': -1.3404915454597166, 'agent-2': -1.0363064016766614, 'agent-3': -2.4783520845754623} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2134439062594211'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.20105085368151165'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6562853430427538'}}}\n",
      "reward:  {'agent-0': -0.35966828122173666, 'agent-1': -1.0, 'agent-2': -1.603152561044535, 'agent-3': 0.9688560291282613} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.6802681679710005'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8351776628426464'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21442659960369248'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -3.0408045039130016, 'agent-1': 1.5055329885279392, 'agent-2': -0.35672020118892256, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.12638196520054024'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.9671597191846146'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.2820179259852438'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.6208541043983793, 'agent-2': 1.901479157553844, 'agent-3': -1.8460537779557313} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0530021680248538'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6053049935956452'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.39312171390800366'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.46977878703535225'}}}\n",
      "reward:  {'agent-0': -0.8409934959254386, 'agent-1': 0.8159149807869355, 'agent-2': 0.17936514172401097, 'agent-3': -2.4093363611060568} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.60164676581892'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7587630006911219'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.4924975924345443'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.21031025241796897'}}}\n",
      "reward:  {'agent-0': -2.80494029745676, 'agent-1': 1.2762890020733657, 'agent-2': -2.477492777303633, 'agent-3': -1.630930757253907} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5274883257211584'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.026684476597505835'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.006017535354226666'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7727179708843863'}}}\n",
      "reward:  {'agent-0': 0.5824649771634753, 'agent-1': -0.9199465702074825, 'agent-2': -1.01805260606268, 'agent-3': 1.318153912653159} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.25477295026750824'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.5137023752921692'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.01991140398333968'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6276185742153615'}}}\n",
      "reward:  {'agent-0': -0.2356811491974753, 'agent-1': -2.5411071258765077, 'agent-2': -0.940265788049981, 'agent-3': 0.8828557226460845} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.09584779276588762'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8370984444209029'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.37919901859721605'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.28026492211327536'}}}\n",
      "reward:  {'agent-0': -0.7124566217023371, 'agent-1': 1.5112953332627086, 'agent-2': 0.13759705579164816, 'agent-3': -0.15920523366017392} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.20347199462526078'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.9805429901334755'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.39964323291338744'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -1.6104159838757823, 'agent-1': -3.9416289704004264, 'agent-2': -2.1989296987401623, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.08252089721039368'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.34152100743504477'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.0998844055698811'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.3359565008971117'}}}\n",
      "reward:  {'agent-0': -0.752437308368819, 'agent-1': -2.0245630223051343, 'agent-2': -1.2996532167096433, 'agent-3': -2.007869502691335} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.33665329296747615'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3050516479679146'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6267018330307401'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.3279558109481684'}}}\n",
      "reward:  {'agent-0': -2.0099598789024284, 'agent-1': -0.08484505609625614, 'agent-2': 0.8801054990922204, 'agent-3': -1.9838674328445052} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7631738713090996'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.327955313626223'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.05451647670917481'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.6571096013123565'}}}\n",
      "reward:  {'agent-0': 1.289521613927299, 'agent-1': -0.016134059121331035, 'agent-2': -1.1635494301275244, 'agent-3': -2.9713288039370696} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0703786482276243'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.21359899690478557'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.7284092248869865'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5007180086416696'}}}\n",
      "reward:  {'agent-0': -0.7888640553171271, 'agent-1': -0.3592030092856433, 'agent-2': -3.1852276746609594, 'agent-3': 0.5021540259250088} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.39496053068510406'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.5004010329351907'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.16217131455607792'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.37198137239653306'}}}\n",
      "reward:  {'agent-0': -2.184881592055312, 'agent-1': -2.501203098805572, 'agent-2': -1.4865139436682338, 'agent-3': -2.115944117189599} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.32915494290445224'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.27128586148672795'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6388295494142149'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1599401011065993'}}}\n",
      "reward:  {'agent-0': -1.9874648287133567, 'agent-1': -1.8138575844601839, 'agent-2': 0.9164886482426446, 'agent-3': -0.5201796966802021} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.21815957447051204'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.37486525812756355'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.5397734461333972'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.25349004821060817'}}}\n",
      "reward:  {'agent-0': -0.3455212765884639, 'agent-1': -2.1245957743826906, 'agent-2': -2.6193203384001915, 'agent-3': -0.2395298553681755} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5647730206653989'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.5233165236606041'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.06425778105289837'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.5236022896101389'}}}\n",
      "reward:  {'agent-0': 0.6943190619961968, 'agent-1': -2.5699495709818123, 'agent-2': -0.8072266568413049, 'agent-3': -2.5708068688304166} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.004535001024237317'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.571596343571958'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.012853172607018237'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7714454091577068'}}}\n",
      "reward:  {'agent-0': -0.986394996927288, 'agent-1': -2.714789030715874, 'agent-2': -0.9614404821789453, 'agent-3': 1.3143362274731203} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.10036811379429622'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.051498120354423804'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.36866277352789645'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15633702804075256'}}}\n",
      "reward:  {'agent-0': -1.3011043413828887, 'agent-1': -1.1544943610632714, 'agent-2': 0.10598832058368934, 'agent-3': -0.5309889158777423} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.49996108466757505'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8930459886704512'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.3239725753222924'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.16906865773928814'}}}\n",
      "reward:  {'agent-0': -2.499883254002725, 'agent-1': 1.6791379660113535, 'agent-2': -1.9719177259668772, 'agent-3': -1.5072059732178644} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2730771940817931'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.32480236565115206'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.22319058295521899'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.2225424205358877'}}}\n",
      "reward:  {'agent-0': -0.1807684177546207, 'agent-1': -0.025592903046543825, 'agent-2': -1.669571748865657, 'agent-3': -1.667627261607663} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.14278765288204198'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.20476785288092003'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.30733402879717175'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.1966488481594837'}}}\n",
      "reward:  {'agent-0': -1.428362958646126, 'agent-1': -0.3856964413572399, 'agent-2': -0.07799791360848474, 'agent-3': -1.589946544478451} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2653615889470089'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.4613353704684684'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.28591819227119863'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.12154231062076803'}}}\n",
      "reward:  {'agent-0': -0.2039152331589733, 'agent-1': -2.384006111405405, 'agent-2': -0.1422454231864041, 'agent-3': -1.364626931862304} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.5511653186929806'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5431323820527858'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.03695043848880175'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5416979257640406'}}}\n",
      "reward:  {'agent-0': -2.6534959560789417, 'agent-1': 0.6293971461583574, 'agent-2': -0.8891486845335947, 'agent-3': 0.6250937772921219} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.37295699378044844'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3738117936220604'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.03853712291030398'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.039603236706753364'}}}\n",
      "reward:  {'agent-0': -2.1188709813413453, 'agent-1': 0.12143538086618122, 'agent-2': -1.115611368730912, 'agent-3': -1.11880971012026} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 1.00069683228962'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5692660641737035'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.1894865316298393'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.019270456668650127'}}}\n",
      "reward:  {'agent-0': 2.0020904968688598, 'agent-1': 0.7077981925211105, 'agent-2': -0.4315404051104821, 'agent-3': -0.9421886299940496} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.046704367729333285'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.8086190390211847'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.45882778694100956'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6298028159644389'}}}\n",
      "reward:  {'agent-0': -1.1401131031879999, 'agent-1': -3.425857117063554, 'agent-2': 0.3764833608230287, 'agent-3': 0.8894084478933166} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8684398400283442'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.21437715965659265'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.00535862598403547'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.11462977185800582'}}}\n",
      "reward:  {'agent-0': 1.6053195200850325, 'agent-1': -0.35686852103022204, 'agent-2': -1.0160758779521064, 'agent-3': -1.3438893155740175} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.42402656425831964'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.7048178714484763'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.02711535837146606'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.15864707053385985'}}}\n",
      "reward:  {'agent-0': -2.272079692774959, 'agent-1': -3.114453614345429, 'agent-2': -1.0813460751143982, 'agent-3': -0.5240587883984205} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.4904846598002379'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.28827076455999645'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4904323901169825'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.07865491501955546'}}}\n",
      "reward:  {'agent-0': -2.4714539794007138, 'agent-1': -0.13518770632001065, 'agent-2': 0.4712971703509474, 'agent-3': -0.7640352549413336} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2890430117821978'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.17668017079211396'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.07466250270401353'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.47030769634061187'}}}\n",
      "reward:  {'agent-0': -0.13287096465340653, 'agent-1': -0.46995948762365813, 'agent-2': -0.7760124918879594, 'agent-3': -2.4109230890218356} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.2970806760332465'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.3507015217391682'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.41302841264038825'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.7171307036172436'}}}\n",
      "reward:  {'agent-0': -0.10875797190026049, 'agent-1': 3.0521045652175047, 'agent-2': -2.2390852379211648, 'agent-3': -3.151392110851731} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.021270035555644995'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.17841387696140032'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.3432356057612562'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.003795104872622801'}}}\n",
      "reward:  {'agent-0': -1.063810106666935, 'agent-1': -0.46475836911579904, 'agent-2': -2.0297068172837687, 'agent-3': -0.9886146853821316} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4706447957351685'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08473973850100691'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.27466224975149167'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3087954060442115'}}}\n",
      "reward:  {'agent-0': 0.41193438720550546, 'agent-1': -0.7457807844969793, 'agent-2': -0.17601325074552499, 'agent-3': -0.07361378186736545} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5859569866652663'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.23586638677666372'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5068308358096107'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.33238642836033705'}}}\n",
      "reward:  {'agent-0': 0.7578709599957989, 'agent-1': -0.29240083967000885, 'agent-2': 0.5204925074288322, 'agent-3': -1.9971592850810111} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3296605594593771'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.0936499026488349'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -1.3484955046508666'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3199013144734266'}}}\n",
      "reward:  {'agent-0': -0.011018321621868665, 'agent-1': 2.2809497079465046, 'agent-2': -5.0454865139526, 'agent-3': -0.04029605657972013} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.41367098514579226'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8648458727870079'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.17944554348407138'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3271067003481818'}}}\n",
      "reward:  {'agent-0': -2.2410129554373768, 'agent-1': 1.5945376183610236, 'agent-2': -1.5383366304522141, 'agent-3': -0.018679898955454632} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.45240709864432205'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.4187462565417235'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4588428946819363'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5308518751391915'}}}\n",
      "reward:  {'agent-0': -2.357221295932966, 'agent-1': -2.2562387696251704, 'agent-2': 0.37652868404580886, 'agent-3': 0.5925556254175746} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.4783985611527086'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.08369113330818934'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.18340601404876367'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.44500607337118936'}}}\n",
      "reward:  {'agent-0': 0.43519568345812587, 'agent-1': -0.748926600075432, 'agent-2': -0.449781957853709, 'agent-3': -2.335018220113568} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.39046415804963175'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.13743597536178243'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.15604152783961034'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.04784847322181918'}}}\n",
      "reward:  {'agent-0': -2.1713924741488952, 'agent-1': -1.4123079260853473, 'agent-2': -0.531875416481169, 'agent-3': -0.8564545803345425} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.7248989552644289'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.20604025258235126'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.6047693486208345'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.13163543292637314'}}}\n",
      "reward:  {'agent-0': -3.174696865793287, 'agent-1': -1.6181207577470538, 'agent-2': -2.8143080458625036, 'agent-3': -0.6050937012208806} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.046650445452542044'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.008006823186349266'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.21321368543378405'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.3224871186523899'}}}\n",
      "reward:  {'agent-0': -0.8600486636423739, 'agent-1': -1.0240204695590478, 'agent-2': -0.36035894369864785, 'agent-3': -1.9674613559571696} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.10503942414297995'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.760986578160395'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.8160609073946006'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.3151182724289399, 'agent-2': -3.282959734481185, 'agent-3': -3.4481827221838017} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5309579334232737'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.34654451159453714'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.09291108117777824'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6285400773423504'}}}\n",
      "reward:  {'agent-0': 0.5928738002698211, 'agent-1': -2.0396335347836114, 'agent-2': -1.2787332435333347, 'agent-3': 0.8856202320270512} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3519951078529182'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.5217560680552182'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.10167259518301819'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.05598532355875463, 'agent-2': -2.5652682041656547, 'agent-3': -0.6949822144509454} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.9493064887302936'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.3405032886519628'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.1364769208852774'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1095203553398818'}}}\n",
      "reward:  {'agent-0': -3.8479194661908807, 'agent-1': -2.0215098659558883, 'agent-2': -1.4094307626558322, 'agent-3': -0.6714389339803546} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.40697453806426154'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.9220975088607659'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6791751755036533'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.20460780063069706'}}}\n",
      "reward:  {'agent-0': -2.2209236141927846, 'agent-1': 1.7662925265822977, 'agent-2': 1.0375255265109598, 'agent-3': -0.38617659810790883} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.25506749302827103'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.02694276057909306'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4453615105373103'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.9196334919897282'}}}\n",
      "reward:  {'agent-0': -0.2347975209151869, 'agent-1': -1.0808282817372792, 'agent-2': 0.33608453161193097, 'agent-3': -3.7589004759691846} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.01874789391492726'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.815954958669046'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.02445786728260302'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.33796167590143966'}}}\n",
      "reward:  {'agent-0': -0.9437563182552182, 'agent-1': -3.447864876007138, 'agent-2': -0.9266263981521909, 'agent-3': -2.013885027704319} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.29211642892546763'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6244751858687003'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.18913108384616706'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -0.12365071322359711, 'agent-1': 0.873425557606101, 'agent-2': -1.5673932515385012, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.32380475896466265'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3007282496868484'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 1.1597457787677712'}}}\n",
      "reward:  {'agent-0': -1.971414276893988, 'agent-1': -1.0, 'agent-2': -0.09781525093945476, 'agent-3': 2.4792373363033136} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5135965833179483'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.499538370744645'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.15023096713727213'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3156792918666014'}}}\n",
      "reward:  {'agent-0': 0.540789749953845, 'agent-1': 0.49861511223393506, 'agent-2': -0.5493070985881836, 'agent-3': -0.052962124400195876} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.1358739516672145'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.6260946737159294'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.26433210453117617'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.3081618992331556'}}}\n",
      "reward:  {'agent-0': -1.4076218550016435, 'agent-1': -2.8782840211477883, 'agent-2': -0.2070036864064715, 'agent-3': -1.9244856976994669} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.26414097495235467'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.04503235650564008'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5867109320977555'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.16812233413057243'}}}\n",
      "reward:  {'agent-0': -0.207577075142936, 'agent-1': -1.1350970695169202, 'agent-2': 0.7601327962932665, 'agent-3': -0.4956329976082827} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.302408091586571'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.41897474077274666'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.04419546588674805'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8391435495369848'}}}\n",
      "reward:  {'agent-0': -1.907224274759713, 'agent-1': -2.25692422231824, 'agent-2': -1.1325863976602442, 'agent-3': 1.5174306486109543} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.7166454742743653'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10869053926231942'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4645308409076012'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.016480885503924014'}}}\n",
      "reward:  {'agent-0': -3.149936422823096, 'agent-1': -0.6739283822130417, 'agent-2': 0.39359252272280365, 'agent-3': -0.950557343488228} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8510338312335293'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.138561515315903'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.07615077605779241'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.047497008859693324'}}}\n",
      "reward:  {'agent-0': 1.5531014937005878, 'agent-1': -1.415684545947709, 'agent-2': -0.7715476718266228, 'agent-3': -1.14249102657908} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.9477730264235618'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1970158564019897'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.10627009267486187'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.08293410422209035'}}}\n",
      "reward:  {'agent-0': -3.8433190792706853, 'agent-1': -0.4089524307940309, 'agent-2': -1.3188102780245856, 'agent-3': -1.248802312666271} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.22291658901741584'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.15510337179702205'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3833705108899146'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.04489382653470386'}}}\n",
      "reward:  {'agent-0': -1.6687497670522475, 'agent-1': -1.4653101153910661, 'agent-2': 0.15011153266974375, 'agent-3': -0.8653185203958884} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.17741178891743203'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.17471194371554688'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.0399634306017127'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.4311816506218662'}}}\n",
      "reward:  {'agent-0': -0.4677646332477039, 'agent-1': -1.5241358311466406, 'agent-2': -1.119890291805138, 'agent-3': -2.2935449518655986} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.010812317100892699'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5687418864652543'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.38900419840228295'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6053787723173087'}}}\n",
      "reward:  {'agent-0': -0.9675630486973219, 'agent-1': 0.7062256593957628, 'agent-2': -2.167012595206849, 'agent-3': 0.8161363169519262} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.4505453682755842'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.40298003513871805'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.2131904783436518'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.5039324880422384'}}}\n",
      "reward:  {'agent-0': -2.3516361048267527, 'agent-1': -2.208940105416154, 'agent-2': -1.6395714350309554, 'agent-3': -2.5117974641267153} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.1029164291469371'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.03264782914370912'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.14181292831061754'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.24088509416682768'}}}\n",
      "reward:  {'agent-0': -0.6912507125591887, 'agent-1': -0.9020565125688726, 'agent-2': -1.4254387849318526, 'agent-3': -0.27734471749951695} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7044266639850321'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.026362010621603815'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.1546498594846586'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.03597822995280353'}}}\n",
      "reward:  {'agent-0': 1.1132799919550962, 'agent-1': -1.0790860318648114, 'agent-2': -1.4639495784539758, 'agent-3': -0.8920653101415894} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8438000022445848'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.16619991897774966'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6860234168680499'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2777675324655604'}}}\n",
      "reward:  {'agent-0': 1.5314000067337545, 'agent-1': -0.501400243066751, 'agent-2': 1.0580702506041497, 'agent-3': -0.16669740260331878} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.383429171057287'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.021153557833379466'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.16080853394018035'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -2.150287513171861, 'agent-1': -0.9365393264998616, 'agent-2': -0.5175743981794589, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7970854197729338'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.15686852199682022'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.30974378414863146'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.7763581610629302'}}}\n",
      "reward:  {'agent-0': 1.3912562593188014, 'agent-1': -0.5293944340095393, 'agent-2': -0.07076864755410561, 'agent-3': 1.3290744831887906} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.018511050805905427'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.23957222135137357'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.7040637186956467'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.9687883361920768'}}}\n",
      "reward:  {'agent-0': -1.0555331524177163, 'agent-1': -1.7187166640541207, 'agent-2': -3.11219115608694, 'agent-3': -3.9063650085762305} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.15545180178828844'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.9588585300273582'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.14481609037336796'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.4663554053648653, 'agent-2': -3.8765755900820746, 'agent-3': -0.5655517288798961} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.008107090970938202'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -1.3254548556490668'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.539893925641163'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19077605444795154'}}}\n",
      "reward:  {'agent-0': -0.9756787270871854, 'agent-1': -4.9763645669472005, 'agent-2': -2.619681776923489, 'agent-3': -0.4276718366561454} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.6206704535147054'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7485344259585105'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.017024357438453208'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2132193511492062'}}}\n",
      "reward:  {'agent-0': -2.862011360544116, 'agent-1': 1.2456032778755315, 'agent-2': -0.9489269276846404, 'agent-3': -0.3603419465523814} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.2495160860435064'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.04505985260441747'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.07245475225719211'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.37805969113721005'}}}\n",
      "reward:  {'agent-0': -1.7485482581305192, 'agent-1': -0.8648204421867476, 'agent-2': -0.7826357432284237, 'agent-3': -2.13417907341163} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.5216930436955138'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.07551647360298475'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.7638252264486578'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.06583124887706049'}}}\n",
      "reward:  {'agent-0': 0.5650791310865415, 'agent-1': -1.2265494208089542, 'agent-2': 1.2914756793459734, 'agent-3': -1.1974937466311815} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8880915052725697'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.19102362670195205'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.0629465755664036'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.31896142101712144'}}}\n",
      "reward:  {'agent-0': 1.6642745158177092, 'agent-1': -0.42692911989414384, 'agent-2': -1.1888397266992108, 'agent-3': -0.043115736948635686} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.11210274919731233'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.320894966710803'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.797594365987722'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.13076857119388308'}}}\n",
      "reward:  {'agent-0': -0.663691752408063, 'agent-1': 2.962684900132409, 'agent-2': -3.392783097963166, 'agent-3': -1.3923057135816492} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.02276502714984474'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3891334164854108'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.5430888142798498'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.19054518443697077'}}}\n",
      "reward:  {'agent-0': -0.9317049185504658, 'agent-1': 0.16740024945623233, 'agent-2': 0.6292664428395494, 'agent-3': -0.4283644466890877} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.14123365134194898'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.24018090766860212'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.25265359622233063'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.576299045974153, 'agent-2': -1.7205427230058064, 'agent-3': -1.757960788666992} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.6478853985973032'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.024734572076251737'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.2753598671412476'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.4048161636681442'}}}\n",
      "reward:  {'agent-0': 0.9436561957919096, 'agent-1': -1.0742037162287552, 'agent-2': -0.17392039857625718, 'agent-3': -2.2144484910044326} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.34151154492542446'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2380104203087292'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.043097582455335015'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.13721877421676254'}}}\n",
      "reward:  {'agent-0': 0.02453463477627338, 'agent-1': -0.2859687390738124, 'agent-2': -0.870707252633995, 'agent-3': -1.4116563226502876} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.6652699603739833'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.004193859881645778'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.13341410864138226'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.29687194211491885'}}}\n",
      "reward:  {'agent-0': -2.99580988112195, 'agent-1': -0.9874184203550627, 'agent-2': -0.5997576740758532, 'agent-3': -0.10938417365524344} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.31810361862903846'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.8367395500228643'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.5313413984947175'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.9543108558871154, 'agent-2': -3.510218650068593, 'agent-3': 0.5940241954841525} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.25698068809111163'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3767657878185098'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.1607787238937135'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.053669163913625084'}}}\n",
      "reward:  {'agent-0': -1.770942064273335, 'agent-1': 0.13029736345552934, 'agent-2': -1.4823361716811405, 'agent-3': -1.1610074917408753} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.24814837178455917'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.02666449068660981'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.30464267376159526'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.36853651438542556'}}}\n",
      "reward:  {'agent-0': -0.2555548846463225, 'agent-1': -1.0799934720598294, 'agent-2': -0.08607197871521421, 'agent-3': 0.10560954315627669} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.29276084014131243'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8038511193286126'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.04007243918965031'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1363262845021751'}}}\n",
      "reward:  {'agent-0': -1.8782825204239373, 'agent-1': 1.411553357985838, 'agent-2': -0.8797826824310491, 'agent-3': -0.5910211464934747} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.20559546172320609'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7702632954847957'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.11200017881099456'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.23828592448673191'}}}\n",
      "reward:  {'agent-0': -1.6167863851696183, 'agent-1': 1.310789886454387, 'agent-2': -1.3360005364329837, 'agent-3': -1.7148577734601957} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.41467805355186016'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.3166028560148604'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.5322178849221935'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.05426419416272665'}}}\n",
      "reward:  {'agent-0': -2.2440341606555805, 'agent-1': -0.050191431955418864, 'agent-2': -2.5966536547665804, 'agent-3': -0.83720741751182} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -1.0204705110865078'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.2901390001210622'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.0745596336478993'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0'}}}\n",
      "reward:  {'agent-0': -4.061411533259523, 'agent-1': -1.8704170003631866, 'agent-2': -1.223678900943698, 'agent-3': -1.0} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.8151298924304768'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.18271391304034168'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.4705317661911437'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.3158230791624277'}}}\n",
      "reward:  {'agent-0': -3.4453896772914305, 'agent-1': -1.548141739121025, 'agent-2': -2.411595298573431, 'agent-3': -0.05253076251271693} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.5180421619953819'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.2344360756500059'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.4053832748611921'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.6652776641663962'}}}\n",
      "reward:  {'agent-0': -2.5541264859861457, 'agent-1': -1.7033082269500177, 'agent-2': -2.2161498245835762, 'agent-3': 0.9958329924991887} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.014356790931209673'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10166648873051187'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.8399238747679121'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.22155474288243227'}}}\n",
      "reward:  {'agent-0': -1.043070372793629, 'agent-1': -0.6950005338084644, 'agent-2': -3.5197716243037362, 'agent-3': -0.3353357713527032} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2610020192376581'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6861613057372953'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.21777243273507452'}}}\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.21699394228702573, 'agent-2': 1.0584839172118858, 'agent-3': -0.34668270179477645} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.0009048622451928168'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.36476034006917857'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.4585072671924486'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.23068673635546588'}}}\n",
      "reward:  {'agent-0': -1.0027145867355785, 'agent-1': -2.0942810202075357, 'agent-2': -2.375521801577346, 'agent-3': -0.30793979093360235} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.20468523335391353'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6626182514899455'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.24451228655877877'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.9368624049832874'}}}\n",
      "reward:  {'agent-0': -0.3859442999382594, 'agent-1': 0.9878547544698364, 'agent-2': -0.2664631403236637, 'agent-3': -3.8105872149498623} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.020209800065657646'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.2453827067618306'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.6216074205110171'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.08421258969957535'}}}\n",
      "reward:  {'agent-0': -1.060629400196973, 'agent-1': -0.2638518797145082, 'agent-2': 0.8648222615330514, 'agent-3': -0.747362230901274} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.029548031041507272'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -1.213439141284514'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.9125933818139522'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.0451921274501359'}}}\n",
      "reward:  {'agent-0': -0.9113559068754782, 'agent-1': -4.640317423853542, 'agent-2': -3.7377801454418567, 'agent-3': -0.8644236176495923} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.19259905410239497'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.47995585077005387'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.06561405434278988'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.1387574986613629'}}}\n",
      "reward:  {'agent-0': -0.4222028376928151, 'agent-1': -2.4398675523101616, 'agent-2': -0.8031578369716303, 'agent-3': -0.5837275040159113} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8498653537191743'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.6701264077372535'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.9054623164009712'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.21357517206462262'}}}\n",
      "reward:  {'agent-0': 1.5495960611575228, 'agent-1': -3.0103792232117605, 'agent-2': -3.7163869492029136, 'agent-3': -0.35927448380613214} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.0722724818984588'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.10920352848156156'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.7529018885941241'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.12533894121332878'}}}\n",
      "reward:  {'agent-0': -0.7831825543046236, 'agent-1': -0.6723894145553153, 'agent-2': -3.2587056657823723, 'agent-3': -1.3760168236399863} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.18766391741890942'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.11763463290655096'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.056652016086417234'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.24068877508477726'}}}\n",
      "reward:  {'agent-0': -0.43700824774327174, 'agent-1': -1.3529038987196529, 'agent-2': -1.1699560482592517, 'agent-3': -1.7220663252543318} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.09701358957275374'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.7666871680537994'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.4841228332076426'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.24464246334093787'}}}\n",
      "reward:  {'agent-0': -0.7089592312817388, 'agent-1': 1.3000615041613983, 'agent-2': 0.4523684996229278, 'agent-3': -1.7339273900228136} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.3271258635534551'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.6361379919153833'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.10053384662204579'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.29339931965756705'}}}\n",
      "reward:  {'agent-0': -1.9813775906603652, 'agent-1': -2.90841397574615, 'agent-2': -1.3016015398661374, 'agent-3': -1.8801979589727011} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.01686320635825922'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.1248865601406699'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.23132527264556657'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.24258886601134577'}}}\n",
      "reward:  {'agent-0': -0.9494103809252223, 'agent-1': -0.6253403195779903, 'agent-2': -0.3060241820633003, 'agent-3': -1.7277665980340373} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.12947109858652084'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.6596818483820464'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.19489250362120458'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.6740620887405839'}}}\n",
      "reward:  {'agent-0': -1.3884132957595625, 'agent-1': 0.9790455451461391, 'agent-2': -1.5846775108636137, 'agent-3': -3.022186266221752} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.13018919212687052'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.6358596227897415'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.12773346431048438'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.18505133668151075'}}}\n",
      "reward:  {'agent-0': -0.6094324236193884, 'agent-1': -2.9075788683692245, 'agent-2': -0.6167996070685469, 'agent-3': -0.44484598995546776} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7291278467362048'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.01995928514543266'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.6414249568444212'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.0007921284451271049'}}}\n",
      "reward:  {'agent-0': 1.1873835402086144, 'agent-1': -0.940122144563702, 'agent-2': -2.9242748705332637, 'agent-3': -1.0023763853353813} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.8611866262502446'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 1.0267874393789214'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.625997368632234'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.06555663892000041'}}}\n",
      "reward:  {'agent-0': 1.5835598787507337, 'agent-1': 2.080362318136764, 'agent-2': -2.877992105896702, 'agent-3': -0.8033300832399988} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.3952716026992391'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.5916857487007476'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: -0.29340243345005845'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.2468163802578971'}}}\n",
      "reward:  {'agent-0': 0.18581480809771733, 'agent-1': 0.7750572461022429, 'agent-2': -1.8802073003501754, 'agent-3': -0.2595508592263087} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: -0.0477293998185786'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: 0.8702256122607679'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.815107817051441'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: -0.036988427017732306'}}}\n",
      "reward:  {'agent-0': -1.1431881994557358, 'agent-1': 1.6106768367823037, 'agent-2': 1.445323451154323, 'agent-3': -1.110965281053197} \n",
      "\n",
      "info:  {'agent-0': {'info': {'r2: 0, r3: -1, r4: 0.7809973331979876'}}, 'agent-1': {'info': {'r2: 0, r3: -1, r4: -0.27706829898654206'}}, 'agent-2': {'info': {'r2: 0, r3: -1, r4: 0.3783887591776214'}}, 'agent-3': {'info': {'r2: 0, r3: -1, r4: 0.8421520811378684'}}}\n",
      "reward:  {'agent-0': 1.3429919995939628, 'agent-1': -1.8312048969596262, 'agent-2': 0.13516627753286414, 'agent-3': 1.5264562434136053} \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainin_steps):\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     clear_output()\n\u001b[1;32m     28\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ppo_result_format(result) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:328\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:873\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    863\u001b[0m     (\n\u001b[1;32m    864\u001b[0m         train_results,\n\u001b[1;32m    865\u001b[0m         eval_results,\n\u001b[1;32m    866\u001b[0m         train_iter_ctx,\n\u001b[1;32m    867\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 873\u001b[0m     train_results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:3156\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_STEP_TIMER]:\n\u001b[0;32m-> 3156\u001b[0m                 results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:428\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_step_new_api_stack()\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# Old and hybrid API stacks (Policy, RolloutWorker, Connector, maybe RLModule,\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# maybe Learner).\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training_step_old_and_hybrid_api_stacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:562\u001b[0m, in \u001b[0;36mPPO._training_step_old_and_hybrid_api_stacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    558\u001b[0m         worker_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers,\n\u001b[1;32m    559\u001b[0m         max_agent_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtotal_train_batch_size,\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mas_multi_agent()\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39magent_steps()\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/execution/rollout_ops.py:97\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat, sample_timeout_s, _uses_new_env_runners, _return_metrics)\u001b[0m\n\u001b[1;32m     94\u001b[0m         stats_dicts \u001b[38;5;241m=\u001b[39m [worker_set\u001b[38;5;241m.\u001b[39mlocal_worker()\u001b[38;5;241m.\u001b[39mget_metrics()]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m \u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_return_metrics\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Nothing was returned (maybe all workers are stalling) or no healthy\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# remote workers left: Break.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampled_data \u001b[38;5;129;01mor\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mnum_healthy_remote_workers() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:840\u001b[0m, in \u001b[0;36mEnvRunnerGroup.foreach_worker\u001b[0;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_manager\u001b[38;5;241m.\u001b[39mactor_ids():\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m local_result\n\u001b[0;32m--> 840\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m _handle_remote_call_result_errors(\n\u001b[1;32m    850\u001b[0m     remote_results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_env_runner_failures\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:622\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    616\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[1;32m    617\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    618\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    619\u001b[0m )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:476\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[0;32m--> 476\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/_private/worker.py:2854\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2852\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2853\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2854\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3812\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:571\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gymnasium.wrappers.time_limit import TimeLimit\n",
    "\n",
    "trainin_steps = 60\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "     .training(gamma = 0.925, \n",
    "              lr = 0.001,\n",
    "              train_batch_size = 4096, \n",
    "              sgd_minibatch_size = 256, \n",
    "              num_sgd_iter = 30,\n",
    "              #entropy_coeff=0.005,\n",
    "              )\n",
    "    .env_runners(num_env_runners=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"collect_the_items?visible_nbrs=3&visible_targets=3\")\n",
    "    .build()\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "out = \"\"\n",
    "for i in range(trainin_steps):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += ppo_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    simulate_episode(RenderableKeepTheDistance(env_config), algo, 500, sleep_between_frames=0.01, print_reward=True, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c4b68aa60748589da3eebe02450b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config_2 = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 10,\n",
    "    spawn_area = 200,\n",
    "    max_steps=300,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3)\n",
    "simulate_episode(RenderableKeepTheDistance(env_config_2), algo, 300, sleep_between_frames=0.01, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Algorithm checkpoint has been created inside directory: 'TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/c/Users/nicol/Desktop/Università/tesi/experiments/RL_experiments/algos/collect_the_items?visible_nbrs=3&visible_targets=3), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 54.611373374362785, 'cur_kl_coeff': 38.9239013671875, 'cur_lr': 0.0010000000000000005, 'total_loss': 8.893688325832288, 'policy_loss': 0.003270520373916952, 'vf_loss': 8.343666425719857, 'vf_explained_var': 0.10399388348062834, 'kl': 0.01404667480073843, 'entropy': 4.994146442164977, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 256.0, 'num_grad_updates_lifetime': 114240.5, 'diff_num_grad_updates_vs_sampler_policy': 959.5}}, 'num_env_steps_sampled': 245760, 'num_env_steps_trained': 245760, 'num_agent_steps_sampled': 983040, 'num_agent_steps_trained': 983040}, 'sampler_results': {'episode_reward_max': 4400.050410411874, 'episode_reward_min': 1833.0820945094215, 'episode_reward_mean': 3300.8381551636785, 'episode_len_mean': 300.0, 'episode_media': {}, 'episodes_this_iter': 14, 'episodes_timesteps_total': 30000, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3379.8986169526097, 3707.5953575499893, 3541.7332851770398, 3106.3848810473714, 3459.3402914405815, 3805.169756468618, 2126.004977811175, 3529.9589918187617, 3816.542342375313, 2793.965460360503, 1833.0820945094215, 3514.0462533865234, 3622.86003700441, 2996.6305349041104, 2711.69802778388, 3571.8211766473964, 4400.050410411874, 3603.3262396653636, 3089.9573358702764, 3607.298228115678, 3422.388169315279, 3694.552356831392, 3920.5928428568177, 3323.802164714253, 2656.357989927578, 2995.039060184011, 3748.745146664939, 3375.4826247817437, 2971.7612889051943, 3386.2496214651105, 3925.7254186772184, 2994.1432107560872, 3469.398495938791, 2830.210647176783, 2196.5228880678646, 3145.156374333817, 3923.5817924701623, 3548.687819739138, 3407.071675984192, 3411.9569936603907, 3666.9644275908113, 3449.7781298536943, 3624.3884104425365, 3272.403105924799, 3233.531187201045, 3514.6822056633528, 3588.288404116125, 3615.4762857213595, 3767.5814082646716, 3391.8833033014907, 3700.5830073819584, 3044.8581989530057, 3196.926761670113, 3425.3023664147113, 3628.325322182815, 3409.1012738652016, 4052.734444404746, 2759.7972382048833, 3870.2130547066768, 1893.7346601712136, 3358.712970411206, 3869.7048742352863, 2068.298085932484, 3761.875766999291, 3204.6996017978263, 2400.9608753146235, 3039.821149473443, 3270.001376409787, 2774.311080997865, 3575.9543612515504, 2764.494641927446, 3875.851499760447, 3766.412548797839, 3341.2961293035905, 3268.6274819575797, 3590.0018794541857, 3248.235766116433, 2858.8976527675527, 3747.10029566332, 3485.067806110543, 3307.2860053235854, 3862.1602950094734, 2570.130639088262, 3470.915397488631, 3579.479125991671, 2225.6003883341937, 3559.6355635363157, 3734.794235899656, 3406.239897566686, 3103.887303104498, 3500.5202437768467, 2037.5684167630823, 2850.15809179647, 3650.5906669697665, 3385.0813451533336, 3512.197747205305, 2645.445106147085, 3312.684307157806, 3253.013352460232, 3174.7574651257414], 'episode_lengths': [300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.647751253006095, 'mean_inference_ms': 1.0029457364034695, 'mean_action_processing_ms': 0.40128866470085484, 'mean_env_wait_ms': 1.1572634214374407, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.007913351058959961, 'StateBufferConnector_ms': 0.006781816482543945, 'ViewRequirementAgentConnector_ms': 0.24051380157470703}, 'num_episodes': 14, 'episode_return_max': 4400.050410411874, 'episode_return_min': 1833.0820945094215, 'episode_return_mean': 3300.8381551636785}, 'env_runner_results': {'episode_reward_max': 4400.050410411874, 'episode_reward_min': 1833.0820945094215, 'episode_reward_mean': 3300.8381551636785, 'episode_len_mean': 300.0, 'episode_media': {}, 'episodes_this_iter': 14, 'episodes_timesteps_total': 30000, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3379.8986169526097, 3707.5953575499893, 3541.7332851770398, 3106.3848810473714, 3459.3402914405815, 3805.169756468618, 2126.004977811175, 3529.9589918187617, 3816.542342375313, 2793.965460360503, 1833.0820945094215, 3514.0462533865234, 3622.86003700441, 2996.6305349041104, 2711.69802778388, 3571.8211766473964, 4400.050410411874, 3603.3262396653636, 3089.9573358702764, 3607.298228115678, 3422.388169315279, 3694.552356831392, 3920.5928428568177, 3323.802164714253, 2656.357989927578, 2995.039060184011, 3748.745146664939, 3375.4826247817437, 2971.7612889051943, 3386.2496214651105, 3925.7254186772184, 2994.1432107560872, 3469.398495938791, 2830.210647176783, 2196.5228880678646, 3145.156374333817, 3923.5817924701623, 3548.687819739138, 3407.071675984192, 3411.9569936603907, 3666.9644275908113, 3449.7781298536943, 3624.3884104425365, 3272.403105924799, 3233.531187201045, 3514.6822056633528, 3588.288404116125, 3615.4762857213595, 3767.5814082646716, 3391.8833033014907, 3700.5830073819584, 3044.8581989530057, 3196.926761670113, 3425.3023664147113, 3628.325322182815, 3409.1012738652016, 4052.734444404746, 2759.7972382048833, 3870.2130547066768, 1893.7346601712136, 3358.712970411206, 3869.7048742352863, 2068.298085932484, 3761.875766999291, 3204.6996017978263, 2400.9608753146235, 3039.821149473443, 3270.001376409787, 2774.311080997865, 3575.9543612515504, 2764.494641927446, 3875.851499760447, 3766.412548797839, 3341.2961293035905, 3268.6274819575797, 3590.0018794541857, 3248.235766116433, 2858.8976527675527, 3747.10029566332, 3485.067806110543, 3307.2860053235854, 3862.1602950094734, 2570.130639088262, 3470.915397488631, 3579.479125991671, 2225.6003883341937, 3559.6355635363157, 3734.794235899656, 3406.239897566686, 3103.887303104498, 3500.5202437768467, 2037.5684167630823, 2850.15809179647, 3650.5906669697665, 3385.0813451533336, 3512.197747205305, 2645.445106147085, 3312.684307157806, 3253.013352460232, 3174.7574651257414], 'episode_lengths': [300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.647751253006095, 'mean_inference_ms': 1.0029457364034695, 'mean_action_processing_ms': 0.40128866470085484, 'mean_env_wait_ms': 1.1572634214374407, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.007913351058959961, 'StateBufferConnector_ms': 0.006781816482543945, 'ViewRequirementAgentConnector_ms': 0.24051380157470703}, 'num_episodes': 14, 'episode_return_max': 4400.050410411874, 'episode_return_min': 1833.0820945094215, 'episode_return_mean': 3300.8381551636785}, 'episode_reward_max': 4400.050410411874, 'episode_reward_min': 1833.0820945094215, 'episode_reward_mean': 3300.8381551636785, 'episode_len_mean': 300.0, 'episodes_this_iter': 14, 'episodes_timesteps_total': 30000, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3379.8986169526097, 3707.5953575499893, 3541.7332851770398, 3106.3848810473714, 3459.3402914405815, 3805.169756468618, 2126.004977811175, 3529.9589918187617, 3816.542342375313, 2793.965460360503, 1833.0820945094215, 3514.0462533865234, 3622.86003700441, 2996.6305349041104, 2711.69802778388, 3571.8211766473964, 4400.050410411874, 3603.3262396653636, 3089.9573358702764, 3607.298228115678, 3422.388169315279, 3694.552356831392, 3920.5928428568177, 3323.802164714253, 2656.357989927578, 2995.039060184011, 3748.745146664939, 3375.4826247817437, 2971.7612889051943, 3386.2496214651105, 3925.7254186772184, 2994.1432107560872, 3469.398495938791, 2830.210647176783, 2196.5228880678646, 3145.156374333817, 3923.5817924701623, 3548.687819739138, 3407.071675984192, 3411.9569936603907, 3666.9644275908113, 3449.7781298536943, 3624.3884104425365, 3272.403105924799, 3233.531187201045, 3514.6822056633528, 3588.288404116125, 3615.4762857213595, 3767.5814082646716, 3391.8833033014907, 3700.5830073819584, 3044.8581989530057, 3196.926761670113, 3425.3023664147113, 3628.325322182815, 3409.1012738652016, 4052.734444404746, 2759.7972382048833, 3870.2130547066768, 1893.7346601712136, 3358.712970411206, 3869.7048742352863, 2068.298085932484, 3761.875766999291, 3204.6996017978263, 2400.9608753146235, 3039.821149473443, 3270.001376409787, 2774.311080997865, 3575.9543612515504, 2764.494641927446, 3875.851499760447, 3766.412548797839, 3341.2961293035905, 3268.6274819575797, 3590.0018794541857, 3248.235766116433, 2858.8976527675527, 3747.10029566332, 3485.067806110543, 3307.2860053235854, 3862.1602950094734, 2570.130639088262, 3470.915397488631, 3579.479125991671, 2225.6003883341937, 3559.6355635363157, 3734.794235899656, 3406.239897566686, 3103.887303104498, 3500.5202437768467, 2037.5684167630823, 2850.15809179647, 3650.5906669697665, 3385.0813451533336, 3512.197747205305, 2645.445106147085, 3312.684307157806, 3253.013352460232, 3174.7574651257414], 'episode_lengths': [300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.647751253006095, 'mean_inference_ms': 1.0029457364034695, 'mean_action_processing_ms': 0.40128866470085484, 'mean_env_wait_ms': 1.1572634214374407, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.007913351058959961, 'StateBufferConnector_ms': 0.006781816482543945, 'ViewRequirementAgentConnector_ms': 0.24051380157470703}, 'num_episodes': 14, 'episode_return_max': 4400.050410411874, 'episode_return_min': 1833.0820945094215, 'episode_return_mean': 3300.8381551636785, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 983040, 'num_agent_steps_trained': 983040, 'num_env_steps_sampled': 245760, 'num_env_steps_trained': 245760, 'num_env_steps_sampled_this_iter': 4096, 'num_env_steps_trained_this_iter': 4096, 'num_env_steps_sampled_throughput_per_sec': 168.93328432591915, 'num_env_steps_trained_throughput_per_sec': 168.93328432591915, 'timesteps_total': 245760, 'num_env_steps_sampled_lifetime': 245760, 'num_agent_steps_sampled_lifetime': 983040, 'num_steps_trained_this_iter': 4096, 'agent_timesteps_total': 983040, 'timers': {'training_iteration_time_ms': 25302.016, 'restore_workers_time_ms': 0.017, 'training_step_time_ms': 25301.969, 'sample_time_ms': 12940.977, 'load_time_ms': 2.018, 'load_throughput': 2029398.049, 'learn_time_ms': 12353.987, 'learn_throughput': 331.553, 'synch_weights_time_ms': 4.073}, 'counters': {'num_env_steps_sampled': 245760, 'num_env_steps_trained': 245760, 'num_agent_steps_sampled': 983040, 'num_agent_steps_trained': 983040}, 'done': False, 'episodes_total': 819, 'training_iteration': 60, 'trial_id': 'default', 'date': '2024-06-04_10-50-17', 'timestamp': 1717491017, 'time_this_iter_s': 24.251665592193604, 'time_total_s': 1555.166481256485, 'pid': 7060, 'hostname': 'LAPTOP-9AD2MD1C', 'node_ip': '172.23.85.106', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'collect_the_items?visible_nbrs=3&visible_targets=3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.95, 'lr': 0.001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4096, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f4654d616c0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 1555.166481256485, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 37.67209302325581, 'ram_util_percent': 81.63023255813954}})'.\n"
     ]
    }
   ],
   "source": [
    "save_algo(algo, \"collect_the_items?visible_nbrs=3&visible_targets=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 5,\n",
    "    spawn_area = 100,\n",
    "    max_steps=500,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=2)\n",
    "register_env(\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3\", lambda _: KeepTheDistance(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 15:43:08,569\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:43:23,964 E 10380 10380] (raylet) node_manager.cc:3002: 52 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:44:23,970 E 10380 10380] (raylet) node_manager.cc:3002: 65 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:45:23,980 E 10380 10380] (raylet) node_manager.cc:3002: 72 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:46:23,984 E 10380 10380] (raylet) node_manager.cc:3002: 64 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:47:23,987 E 10380 10380] (raylet) node_manager.cc:3002: 70 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:48:23,994 E 10380 10380] (raylet) node_manager.cc:3002: 66 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-06-24 15:49:24,002 E 10380 10380] (raylet) node_manager.cc:3002: 62 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c92a8fad4295ef41314bbcec7c6772303d655a7756275352327cf6dd, IP: 172.22.114.234) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.114.234`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[43mload_algo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/nicol/Desktop/Università/tesi/experiments/RL_experiments/utils/algo_utils.py:17\u001b[0m, in \u001b[0;36mload_algo\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(subfolder_path):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified subfolder \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubfolder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:363\u001b[0m, in \u001b[0;36mAlgorithm.from_checkpoint\u001b[0;34m(checkpoint, policy_ids, policy_mapping_fn, policies_to_train)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    346\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to restore a multi-agent algorithm from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`msgpack` formatted checkpoint, which do NOT store the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou would like to train all policies anyways.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    356\u001b[0m state \u001b[38;5;241m=\u001b[39m Algorithm\u001b[38;5;241m.\u001b[39m_checkpoint_info_to_algorithm_state(\n\u001b[1;32m    357\u001b[0m     checkpoint_info\u001b[38;5;241m=\u001b[39mcheckpoint_info,\n\u001b[1;32m    358\u001b[0m     policy_ids\u001b[38;5;241m=\u001b[39mpolicy_ids,\n\u001b[1;32m    359\u001b[0m     policy_mapping_fn\u001b[38;5;241m=\u001b[39mpolicy_mapping_fn,\n\u001b[1;32m    360\u001b[0m     policies_to_train\u001b[38;5;241m=\u001b[39mpolicies_to_train,\n\u001b[1;32m    361\u001b[0m )\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:391\u001b[0m, in \u001b[0;36mAlgorithm.from_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo `config` found in given Algorithm state!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 391\u001b[0m new_algo \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Set the new algo's state.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m new_algo\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:554\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# TODO: Don't dump sampler results into top-level.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     },\n\u001b[1;32m    552\u001b[0m }\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:158\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, storage)\u001b[0m\n\u001b[1;32m    154\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStorageContext on the TRAINABLE:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstorage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_logfiles(stdout_file, stderr_file)\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:640\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moff_policy_estimation_methods \u001b[38;5;241m=\u001b[39m ope_dict\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# Create a set of env runner actors via a EnvRunnerGroup.\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mEnvRunnerGroup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_env_runners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39msync_weights(inference_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:169\u001b[0m, in \u001b[0;36mEnvRunnerGroup.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_env_runners, local_env_runner, logdir, _setup, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _setup:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_env_runners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_env_runners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_env_runner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_env_runner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# EnvRunnerGroup creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# be initialized properly (due to some errors in the EnvRunners's\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# constructor).\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# errors.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:239\u001b[0m, in \u001b[0;36mEnvRunnerGroup._setup\u001b[0;34m(self, validate_env, config, num_env_runners, local_env_runner)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds_shards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_env_runners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env_runners_after_construction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    248\u001b[0m     local_env_runner\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_manager\u001b[38;5;241m.\u001b[39mnum_actors() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39maction_space)\n\u001b[1;32m    253\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:748\u001b[0m, in \u001b[0;36mEnvRunnerGroup.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Validate here, whether all remote workers have been constructed properly\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# and are \"up and running\". Establish initial states.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m--> 748\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_healthy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;66;03m# Simiply raise the error, which will get handled by the try-except\u001b[39;00m\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;66;03m# clause around the _setup().\u001b[39;00m\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m    754\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:622\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    616\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[1;32m    617\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    618\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    619\u001b[0m )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:476\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[0;32m--> 476\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/worker.py:2854\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2852\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2853\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2854\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3812\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:571\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algo = load_algo(\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [1] => episode_reward_mean: -739.5492273316224, episode_len_mean: 500.0, agent_steps_trained: 16384, env_steps_trained: 4096, entropy: 4.246371173237761, learning_rate: 0.0010000000000000005\n",
      "iteration [2] => episode_reward_mean: -477.55517091648153, episode_len_mean: 500.0, agent_steps_trained: 32768, env_steps_trained: 8192, entropy: 4.225632384916147, learning_rate: 0.0010000000000000005\n",
      "iteration [3] => episode_reward_mean: -300.4690354731436, episode_len_mean: 500.0, agent_steps_trained: 49152, env_steps_trained: 12288, entropy: 4.202773099889358, learning_rate: 0.0010000000000000005\n",
      "iteration [4] => episode_reward_mean: -91.2652442908371, episode_len_mean: 500.0, agent_steps_trained: 65536, env_steps_trained: 16384, entropy: 4.21546970034639, learning_rate: 0.0010000000000000005\n",
      "iteration [5] => episode_reward_mean: 99.83375406704977, episode_len_mean: 494.1219512195122, agent_steps_trained: 81920, env_steps_trained: 20480, entropy: 4.237968141088883, learning_rate: 0.0010000000000000005\n",
      "iteration [6] => episode_reward_mean: 220.7210115534981, episode_len_mean: 488.02, agent_steps_trained: 98304, env_steps_trained: 24576, entropy: 4.191457904751102, learning_rate: 0.0010000000000000005\n",
      "iteration [7] => episode_reward_mean: 339.7160287845038, episode_len_mean: 485.8813559322034, agent_steps_trained: 114688, env_steps_trained: 28672, entropy: 4.174908780803283, learning_rate: 0.0010000000000000005\n",
      "iteration [8] => episode_reward_mean: 439.70171857475947, episode_len_mean: 483.089552238806, agent_steps_trained: 131072, env_steps_trained: 32768, entropy: 4.110121568168203, learning_rate: 0.0010000000000000005\n",
      "iteration [9] => episode_reward_mean: 519.5266354101844, episode_len_mean: 475.68831168831167, agent_steps_trained: 147456, env_steps_trained: 36864, entropy: 4.086693909267584, learning_rate: 0.0010000000000000005\n",
      "iteration [10] => episode_reward_mean: 587.2341835734392, episode_len_mean: 469.7241379310345, agent_steps_trained: 163840, env_steps_trained: 40960, entropy: 4.130501513803998, learning_rate: 0.0010000000000000005\n",
      "iteration [11] => episode_reward_mean: 673.7205596519076, episode_len_mean: 464.7395833333333, agent_steps_trained: 180224, env_steps_trained: 45056, entropy: 4.0161507617682215, learning_rate: 0.0010000000000000005\n",
      "iteration [12] => episode_reward_mean: 847.8793284952562, episode_len_mean: 455.35, agent_steps_trained: 196608, env_steps_trained: 49152, entropy: 4.135394638776779, learning_rate: 0.0010000000000000005\n",
      "iteration [13] => episode_reward_mean: 982.7801550746861, episode_len_mean: 443.96, agent_steps_trained: 212992, env_steps_trained: 53248, entropy: 4.103148384143909, learning_rate: 0.0010000000000000005\n",
      "iteration [14] => episode_reward_mean: 1141.4909511599099, episode_len_mean: 423.34, agent_steps_trained: 229376, env_steps_trained: 57344, entropy: 4.041870366657774, learning_rate: 0.0010000000000000005\n",
      "iteration [15] => episode_reward_mean: 1192.5962439057776, episode_len_mean: 413.4, agent_steps_trained: 245760, env_steps_trained: 61440, entropy: 4.0775674341867365, learning_rate: 0.0010000000000000005\n",
      "iteration [16] => episode_reward_mean: 1271.191506675942, episode_len_mean: 400.81, agent_steps_trained: 262144, env_steps_trained: 65536, entropy: 4.155605650196473, learning_rate: 0.0010000000000000005\n",
      "iteration [17] => episode_reward_mean: 1344.5683672739435, episode_len_mean: 376.19, agent_steps_trained: 278528, env_steps_trained: 69632, entropy: 4.01299328332146, learning_rate: 0.0010000000000000005\n",
      "iteration [18] => episode_reward_mean: 1444.0831367396743, episode_len_mean: 360.84, agent_steps_trained: 294912, env_steps_trained: 73728, entropy: 4.079047802959879, learning_rate: 0.0010000000000000005\n",
      "iteration [19] => episode_reward_mean: 1486.1685602148336, episode_len_mean: 344.54, agent_steps_trained: 311296, env_steps_trained: 77824, entropy: 4.049826584508022, learning_rate: 0.0010000000000000005\n",
      "iteration [20] => episode_reward_mean: 1560.938214485724, episode_len_mean: 315.69, agent_steps_trained: 327680, env_steps_trained: 81920, entropy: 3.925365198776126, learning_rate: 0.0010000000000000005\n",
      "iteration [21] => episode_reward_mean: 1646.4785770811673, episode_len_mean: 297.48, agent_steps_trained: 344064, env_steps_trained: 86016, entropy: 3.9980939734727143, learning_rate: 0.0010000000000000005\n",
      "iteration [22] => episode_reward_mean: 1702.0313868657186, episode_len_mean: 280.99, agent_steps_trained: 360448, env_steps_trained: 90112, entropy: 4.019426688676079, learning_rate: 0.0010000000000000005\n",
      "iteration [23] => episode_reward_mean: 1774.4004866478417, episode_len_mean: 262.76, agent_steps_trained: 376832, env_steps_trained: 94208, entropy: 3.9918701679756246, learning_rate: 0.0010000000000000005\n",
      "iteration [24] => episode_reward_mean: 1831.7719254312633, episode_len_mean: 244.07, agent_steps_trained: 393216, env_steps_trained: 98304, entropy: 3.874996575216452, learning_rate: 0.0010000000000000005\n",
      "iteration [25] => episode_reward_mean: 1851.3341272891987, episode_len_mean: 235.47, agent_steps_trained: 409600, env_steps_trained: 102400, entropy: 4.0245235876490675, learning_rate: 0.0010000000000000005\n",
      "iteration [26] => episode_reward_mean: 1867.2857153542957, episode_len_mean: 232.24, agent_steps_trained: 425984, env_steps_trained: 106496, entropy: 3.9845165599137546, learning_rate: 0.0010000000000000005\n",
      "iteration [27] => episode_reward_mean: 1924.188533815042, episode_len_mean: 217.07, agent_steps_trained: 442368, env_steps_trained: 110592, entropy: 3.973825510094563, learning_rate: 0.0010000000000000005\n",
      "iteration [28] => episode_reward_mean: 1928.4285964296944, episode_len_mean: 210.48, agent_steps_trained: 458752, env_steps_trained: 114688, entropy: 4.054729554802179, learning_rate: 0.0010000000000000005\n",
      "iteration [29] => episode_reward_mean: 1932.522087264994, episode_len_mean: 215.63, agent_steps_trained: 475136, env_steps_trained: 118784, entropy: 3.9608129665255545, learning_rate: 0.0010000000000000005\n",
      "iteration [30] => episode_reward_mean: 1975.785617996903, episode_len_mean: 212.27, agent_steps_trained: 491520, env_steps_trained: 122880, entropy: 3.7819670400271814, learning_rate: 0.0010000000000000005\n",
      "iteration [31] => episode_reward_mean: 1998.347536252772, episode_len_mean: 204.48, agent_steps_trained: 507904, env_steps_trained: 126976, entropy: 3.9091527085751294, learning_rate: 0.0010000000000000005\n",
      "iteration [32] => episode_reward_mean: 2030.9571115864765, episode_len_mean: 196.08, agent_steps_trained: 524288, env_steps_trained: 131072, entropy: 3.823804545029998, learning_rate: 0.0010000000000000005\n",
      "iteration [33] => episode_reward_mean: 2056.4619574715352, episode_len_mean: 184.45, agent_steps_trained: 540672, env_steps_trained: 135168, entropy: 3.8910863316307465, learning_rate: 0.0010000000000000005\n",
      "iteration [34] => episode_reward_mean: 2044.6305670463519, episode_len_mean: 178.97, agent_steps_trained: 557056, env_steps_trained: 139264, entropy: 4.011586319282651, learning_rate: 0.0010000000000000005\n",
      "iteration [35] => episode_reward_mean: 2052.5187837555764, episode_len_mean: 173.57, agent_steps_trained: 573440, env_steps_trained: 143360, entropy: 3.972048371906082, learning_rate: 0.0010000000000000005\n",
      "iteration [36] => episode_reward_mean: 2063.5981154186943, episode_len_mean: 167.1, agent_steps_trained: 589824, env_steps_trained: 147456, entropy: 3.857100075359146, learning_rate: 0.0010000000000000005\n",
      "iteration [37] => episode_reward_mean: 2070.298439090843, episode_len_mean: 162.48, agent_steps_trained: 606208, env_steps_trained: 151552, entropy: 3.950949097548922, learning_rate: 0.0010000000000000005\n",
      "iteration [38] => episode_reward_mean: 2090.7144164747124, episode_len_mean: 152.62, agent_steps_trained: 622592, env_steps_trained: 155648, entropy: 3.9940364712228376, learning_rate: 0.0010000000000000005\n",
      "iteration [39] => episode_reward_mean: 2081.880786468766, episode_len_mean: 158.32, agent_steps_trained: 638976, env_steps_trained: 159744, entropy: 4.001378374795119, learning_rate: 0.0010000000000000005\n",
      "iteration [40] => episode_reward_mean: 2098.8419981991683, episode_len_mean: 159.26, agent_steps_trained: 655360, env_steps_trained: 163840, entropy: 3.815357765989999, learning_rate: 0.0010000000000000005\n",
      "iteration [41] => episode_reward_mean: 2088.480662827797, episode_len_mean: 166.89, agent_steps_trained: 671744, env_steps_trained: 167936, entropy: 4.082358454912901, learning_rate: 0.0010000000000000005\n",
      "iteration [42] => episode_reward_mean: 2084.1296139170136, episode_len_mean: 180.72, agent_steps_trained: 688128, env_steps_trained: 172032, entropy: 3.9689666592826445, learning_rate: 0.0010000000000000005\n",
      "iteration [43] => episode_reward_mean: 2057.5061449204163, episode_len_mean: 182.34, agent_steps_trained: 704512, env_steps_trained: 176128, entropy: 4.181626391286652, learning_rate: 0.0010000000000000005\n",
      "iteration [44] => episode_reward_mean: 2016.3723683521455, episode_len_mean: 187.64, agent_steps_trained: 720896, env_steps_trained: 180224, entropy: 4.030358869209886, learning_rate: 0.0010000000000000005\n",
      "iteration [45] => episode_reward_mean: 2014.9861397364666, episode_len_mean: 180.79, agent_steps_trained: 737280, env_steps_trained: 184320, entropy: 3.912688947468996, learning_rate: 0.0010000000000000005\n",
      "iteration [46] => episode_reward_mean: 2030.5703080966073, episode_len_mean: 164.88, agent_steps_trained: 753664, env_steps_trained: 188416, entropy: 4.021864931161205, learning_rate: 0.0010000000000000005\n",
      "iteration [47] => episode_reward_mean: 2088.556763434121, episode_len_mean: 150.0, agent_steps_trained: 770048, env_steps_trained: 192512, entropy: 3.9850140417615574, learning_rate: 0.0010000000000000005\n",
      "iteration [48] => episode_reward_mean: 2086.85287075865, episode_len_mean: 147.88, agent_steps_trained: 786432, env_steps_trained: 196608, entropy: 4.120251746475697, learning_rate: 0.0010000000000000005\n",
      "iteration [49] => episode_reward_mean: 2078.5479647607835, episode_len_mean: 154.05, agent_steps_trained: 802816, env_steps_trained: 200704, entropy: 4.135100481410821, learning_rate: 0.0010000000000000005\n",
      "iteration [50] => episode_reward_mean: 2063.0354172575667, episode_len_mean: 161.48, agent_steps_trained: 819200, env_steps_trained: 204800, entropy: 4.127779018382231, learning_rate: 0.0010000000000000005\n",
      "iteration [51] => episode_reward_mean: 2063.6154117293877, episode_len_mean: 167.28, agent_steps_trained: 835584, env_steps_trained: 208896, entropy: 4.1421986609697345, learning_rate: 0.0010000000000000005\n",
      "iteration [52] => episode_reward_mean: 2075.1848014847506, episode_len_mean: 170.65, agent_steps_trained: 851968, env_steps_trained: 212992, entropy: 4.10955415815115, learning_rate: 0.0010000000000000005\n",
      "iteration [53] => episode_reward_mean: 2100.2440817748206, episode_len_mean: 163.24, agent_steps_trained: 868352, env_steps_trained: 217088, entropy: 3.802015837157766, learning_rate: 0.0010000000000000005\n",
      "iteration [54] => episode_reward_mean: 2117.7796985118953, episode_len_mean: 156.26, agent_steps_trained: 884736, env_steps_trained: 221184, entropy: 3.9112009299298127, learning_rate: 0.0010000000000000005\n",
      "iteration [55] => episode_reward_mean: 2106.3469277511144, episode_len_mean: 154.85, agent_steps_trained: 901120, env_steps_trained: 225280, entropy: 4.203709264596303, learning_rate: 0.0010000000000000005\n",
      "iteration [56] => episode_reward_mean: 2089.9291518224277, episode_len_mean: 157.11, agent_steps_trained: 917504, env_steps_trained: 229376, entropy: 4.2213744706163805, learning_rate: 0.0010000000000000005\n",
      "iteration [57] => episode_reward_mean: 2080.779038264583, episode_len_mean: 158.84, agent_steps_trained: 933888, env_steps_trained: 233472, entropy: 3.869718695928653, learning_rate: 0.0010000000000000005\n",
      "iteration [58] => episode_reward_mean: 2087.7830425427815, episode_len_mean: 150.36, agent_steps_trained: 950272, env_steps_trained: 237568, entropy: 3.926369447261095, learning_rate: 0.0010000000000000005\n",
      "iteration [59] => episode_reward_mean: 2116.4666520515034, episode_len_mean: 142.85, agent_steps_trained: 966656, env_steps_trained: 241664, entropy: 3.9161810825268426, learning_rate: 0.0010000000000000005\n",
      "iteration [60] => episode_reward_mean: 2105.5878031370885, episode_len_mean: 146.24, agent_steps_trained: 983040, env_steps_trained: 245760, entropy: 4.168454428389668, learning_rate: 0.0010000000000000005\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4991a69ca0d5435d90303c493f91b295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  {'agent-0': 0.5441133493377883, 'agent-1': 0.7009293577975981, 'agent-2': 1.8477870083621806, 'agent-3': 0.18192650056783322} \n",
      "\n",
      "reward:  {'agent-0': 2.4200859007911326, 'agent-1': 1.0657918038671532, 'agent-2': 1.1947469470405192, 'agent-3': 1.118971699641527} \n",
      "\n",
      "reward:  {'agent-0': 1.1699873206680458, 'agent-1': 1.7480914526410931, 'agent-2': 2.402047571515384, 'agent-3': 1.4576047010449464} \n",
      "\n",
      "reward:  {'agent-0': 2.5854738273930344, 'agent-1': 0.5565722765386099, 'agent-2': 0.6277600938064269, 'agent-3': 0.6702206649803948} \n",
      "\n",
      "reward:  {'agent-0': 101.00752632274484, 'agent-1': 100.94431586187355, 'agent-2': 102.5464559200949, 'agent-3': 100.33231318203542} \n",
      "\n",
      "reward:  {'agent-0': 1.986451927807245, 'agent-1': 3.21175423045279, 'agent-2': 2.0132276415023895, 'agent-3': 1.0006724383594303} \n",
      "\n",
      "reward:  {'agent-0': 1.5188484804766276, 'agent-1': 3.208671366142397, 'agent-2': 2.967948464109533, 'agent-3': -0.4555973011817791} \n",
      "\n",
      "reward:  {'agent-0': -0.014024658909931986, 'agent-1': 2.2869625429354343, 'agent-2': 1.8566158797785306, 'agent-3': 0.30553168038638034} \n",
      "\n",
      "reward:  {'agent-0': 1.9431856057236914, 'agent-1': 3.1768012289757195, 'agent-2': 0.9348595704569007, 'agent-3': 3.101337467458034} \n",
      "\n",
      "reward:  {'agent-0': 2.9292551407414678, 'agent-1': -0.6254022114105879, 'agent-2': -1.4894880750169257, 'agent-3': 2.3523453800649143} \n",
      "\n",
      "reward:  {'agent-0': 1.928425109050231, 'agent-1': 3.02344712584771, 'agent-2': -1.0975862904914848, 'agent-3': 0.07017506769813764} \n",
      "\n",
      "reward:  {'agent-0': 1.9461928308794647, 'agent-1': 2.584061725025986, 'agent-2': 2.744770285326993, 'agent-3': 2.6354875563067814} \n",
      "\n",
      "reward:  {'agent-0': 1.7395697973563173, 'agent-1': 1.5831087952094833, 'agent-2': -0.6675552155735573, 'agent-3': 3.2258799265837403} \n",
      "\n",
      "reward:  {'agent-0': 0.38110856930671133, 'agent-1': 2.372930675284131, 'agent-2': -2.554077450701918, 'agent-3': 2.4494150488409865} \n",
      "\n",
      "reward:  {'agent-0': 2.8267316644352434, 'agent-1': 0.6118316909643404, 'agent-2': -1.031075987456994, 'agent-3': 2.5762289831859118} \n",
      "\n",
      "reward:  {'agent-0': 1.547220519037154, 'agent-1': 0.7562239184574224, 'agent-2': 0.026715680334085334, 'agent-3': 1.4877374494527373} \n",
      "\n",
      "reward:  {'agent-0': 1.8745694822559926, 'agent-1': 1.7535248636122915, 'agent-2': -0.29581797047390523, 'agent-3': 1.718532321192189} \n",
      "\n",
      "reward:  {'agent-0': 1.385528652876168, 'agent-1': 3.1222459090699353, 'agent-2': 2.4880856073084416, 'agent-3': 1.8856746236218918} \n",
      "\n",
      "reward:  {'agent-0': 2.0348628319268016, 'agent-1': 1.3916070300464227, 'agent-2': -2.278391395718508, 'agent-3': 0.9880488052659828} \n",
      "\n",
      "reward:  {'agent-0': 2.4268105487465093, 'agent-1': 0.3882041392270281, 'agent-2': -2.316131102442416, 'agent-3': 0.7703450272453978} \n",
      "\n",
      "reward:  {'agent-0': 0.6504201789803581, 'agent-1': -0.23323626394493147, 'agent-2': 2.627170062604371, 'agent-3': 0.9921450787435777} \n",
      "\n",
      "reward:  {'agent-0': 0.46808813034558483, 'agent-1': 0.032621047090515276, 'agent-2': 2.662118736471321, 'agent-3': 0.05054779649169738} \n",
      "\n",
      "reward:  {'agent-0': 1.9347528846847446, 'agent-1': 1.1640631651028563, 'agent-2': 0.351690051782402, 'agent-3': 0.020903602892722972} \n",
      "\n",
      "reward:  {'agent-0': 2.262711233380111, 'agent-1': 2.8611157459981484, 'agent-2': 1.237148383192043, 'agent-3': 1.2378702555572758} \n",
      "\n",
      "reward:  {'agent-0': 2.4636260619969708, 'agent-1': 1.859401385923217, 'agent-2': 1.7985184324644443, 'agent-3': 2.109340062232544} \n",
      "\n",
      "reward:  {'agent-0': 1.3764310809904075, 'agent-1': 2.4143801808095056, 'agent-2': -1.6639333653118982, 'agent-3': 2.635227925841191} \n",
      "\n",
      "reward:  {'agent-0': 1.9202802003505042, 'agent-1': 0.5717007958082228, 'agent-2': 1.9014568143916861, 'agent-3': 1.206247365730416} \n",
      "\n",
      "reward:  {'agent-0': 2.025239649660648, 'agent-1': 2.2659333449974, 'agent-2': -0.017823093413174007, 'agent-3': 1.318108573840572} \n",
      "\n",
      "reward:  {'agent-0': 0.11898992406336895, 'agent-1': 1.2087675822407888, 'agent-2': 1.7181921530316586, 'agent-3': 1.1429332495690545} \n",
      "\n",
      "reward:  {'agent-0': 1.2477749120132335, 'agent-1': 1.413813965581035, 'agent-2': 0.399729826165256, 'agent-3': 2.321775389426941} \n",
      "\n",
      "reward:  {'agent-0': 100.8683839621196, 'agent-1': 100.71127003111252, 'agent-2': 101.9221993105734, 'agent-3': 102.03963987848337} \n",
      "\n",
      "reward:  {'agent-0': 0.6953364879479196, 'agent-1': 1.9817207177033715, 'agent-2': -1.4021763309914306, 'agent-3': 2.854243785770919} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.2743739882725329, 'agent-2': 1.8564740663128134, 'agent-3': 1.429835604053327} \n",
      "\n",
      "reward:  {'agent-0': 2.1367154594464886, 'agent-1': -1.243880679141526, 'agent-2': 0.2104068493891731, 'agent-3': -0.9458759761593285} \n",
      "\n",
      "reward:  {'agent-0': -1.5928066791096427, 'agent-1': 0.5594495553931864, 'agent-2': 1.7087174257829574, 'agent-3': 1.0843534242490023} \n",
      "\n",
      "reward:  {'agent-0': 0.8052672324255639, 'agent-1': 0.49515720779990247, 'agent-2': 0.47160262196128855, 'agent-3': 0.42350383502954436} \n",
      "\n",
      "reward:  {'agent-0': -1.6052539509581862, 'agent-1': 2.8168691713980074, 'agent-2': 0.9651444343622018, 'agent-3': 0.8021616330885841} \n",
      "\n",
      "reward:  {'agent-0': 0.0001315908014305478, 'agent-1': 1.8589289959918425, 'agent-2': 0.9366334296701666, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -0.28777601061087665, 'agent-1': -1.3628308301676135, 'agent-2': 1.2756195800097814, 'agent-3': -0.9543918232327684} \n",
      "\n",
      "reward:  {'agent-0': 0.14554234206629957, 'agent-1': 0.729453312517979, 'agent-2': 2.6327398015286505, 'agent-3': 1.6977580253512858} \n",
      "\n",
      "reward:  {'agent-0': 1.152629728393471, 'agent-1': 1.2005159449399798, 'agent-2': -0.12534391305181458, 'agent-3': 0.015343806582722053} \n",
      "\n",
      "reward:  {'agent-0': 2.279920621740409, 'agent-1': 3.1859756102074037, 'agent-2': 0.8879929472081187, 'agent-3': 0.5837992721039527} \n",
      "\n",
      "reward:  {'agent-0': 1.6090817884774111, 'agent-1': -0.6688189898906778, 'agent-2': 1.7758171772269122, 'agent-3': 0.8461143733397449} \n",
      "\n",
      "reward:  {'agent-0': 1.5731397063422499, 'agent-1': 2.4107301939780825, 'agent-2': 1.4916903638829737, 'agent-3': 0.04407942975893242} \n",
      "\n",
      "reward:  {'agent-0': 0.8475493402943073, 'agent-1': 0.5369906636284014, 'agent-2': 2.4841479832800033, 'agent-3': 0.4936385287198899} \n",
      "\n",
      "reward:  {'agent-0': 1.72270435454055, 'agent-1': 2.318326475288707, 'agent-2': 3.023221799519085, 'agent-3': 2.017912813446914} \n",
      "\n",
      "reward:  {'agent-0': 1.2108414159261756, 'agent-1': -0.10452682160168436, 'agent-2': 2.022324545306134, 'agent-3': -0.4307536430483907} \n",
      "\n",
      "reward:  {'agent-0': 2.0513869957589037, 'agent-1': -1.647048553997422, 'agent-2': 1.4805429751340853, 'agent-3': -0.7064718014553364} \n",
      "\n",
      "reward:  {'agent-0': 2.996983353975594, 'agent-1': 0.24671354050664718, 'agent-2': 2.6385590870088294, 'agent-3': -0.23994377035779202} \n",
      "\n",
      "reward:  {'agent-0': 1.593181435248919, 'agent-1': -0.3386469941236001, 'agent-2': 0.9683418787898717, 'agent-3': 3.10498144962114} \n",
      "\n",
      "reward:  {'agent-0': 0.8341952482027395, 'agent-1': 1.8692310890740096, 'agent-2': 0.778725092215069, 'agent-3': 1.4797767596633902} \n",
      "\n",
      "reward:  {'agent-0': 0.7171180153087562, 'agent-1': 0.45323815270605294, 'agent-2': -0.7404076601162473, 'agent-3': 0.8135651296113622} \n",
      "\n",
      "reward:  {'agent-0': 0.9763752277611992, 'agent-1': -0.708324408122813, 'agent-2': 1.9854287689988368, 'agent-3': -0.13973689559922597} \n",
      "\n",
      "reward:  {'agent-0': 101.99629595411996, 'agent-1': 99.27857535293757, 'agent-2': 100.80993008436629, 'agent-3': 99.94112743500145} \n",
      "\n",
      "reward:  {'agent-0': 0.801151266473795, 'agent-1': 1.553047001142719, 'agent-2': 0.607796493515977, 'agent-3': -0.8524158009090428} \n",
      "\n",
      "reward:  {'agent-0': 0.8062735909626113, 'agent-1': 0.09306732802281914, 'agent-2': -0.1973019043805877, 'agent-3': 0.2458787972162959} \n",
      "\n",
      "reward:  {'agent-0': -0.08057921639905175, 'agent-1': 1.9241398294112528, 'agent-2': 1.383815760121898, 'agent-3': -0.09475685562082248} \n",
      "\n",
      "reward:  {'agent-0': -0.3775272360714368, 'agent-1': -1.3282636572480726, 'agent-2': 3.2221596132425816, 'agent-3': 0.04519281720515522} \n",
      "\n",
      "reward:  {'agent-0': 0.8391925983852602, 'agent-1': 1.3218594061214048, 'agent-2': 1.3482442678449402, 'agent-3': -0.07925539381499647} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 0.21799453492280563, 'agent-2': 0.7212444705154084, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 1.7095933223755466, 'agent-1': -0.8352285825398731, 'agent-2': 1.3625363528474779, 'agent-3': 1.7719262343949076} \n",
      "\n",
      "reward:  {'agent-0': 2.5839941497518097, 'agent-1': 0.5080108434432304, 'agent-2': 1.2895712962939143, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 1.317618339101422, 'agent-1': 1.7137089074395142, 'agent-2': -0.12102683723592378, 'agent-3': 2.009625844775865} \n",
      "\n",
      "reward:  {'agent-0': 1.3226664393793328, 'agent-1': -1.0, 'agent-2': 1.213455581302675, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 2.7572242298720653, 'agent-1': -1.2049741938589094, 'agent-2': -0.7394816802690585, 'agent-3': 0.04568560449690651} \n",
      "\n",
      "reward:  {'agent-0': 0.27248588571143983, 'agent-1': -0.586475600405592, 'agent-2': 0.6727753599434152, 'agent-3': 1.8901603598421026} \n",
      "\n",
      "reward:  {'agent-0': 1.2294833103800542, 'agent-1': 1.524766977756201, 'agent-2': 2.9127929485218047, 'agent-3': -0.3586811374397243} \n",
      "\n",
      "reward:  {'agent-0': 2.7531703586686262, 'agent-1': 0.02576912073025639, 'agent-2': 2.3483784237153174, 'agent-3': -1.1769371178367933} \n",
      "\n",
      "reward:  {'agent-0': 0.3088144191739559, 'agent-1': -1.0547465855870612, 'agent-2': -2.250129777254216, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 0.8510516591330273, 'agent-1': -0.052498258057184444, 'agent-2': -1.1823697751294588, 'agent-3': 1.3662585763309956} \n",
      "\n",
      "reward:  {'agent-0': -0.43416772518527225, 'agent-1': 1.9834405036661735, 'agent-2': -0.3216532737139417, 'agent-3': -0.918492910099431} \n",
      "\n",
      "reward:  {'agent-0': -1.076663388379746, 'agent-1': -1.0655312298222697, 'agent-2': 3.2344076460240885, 'agent-3': 1.869537403124177} \n",
      "\n",
      "reward:  {'agent-0': 2.841961240707569, 'agent-1': 0.3662977025398426, 'agent-2': 0.7791141499109315, 'agent-3': 0.1268754906819467} \n",
      "\n",
      "reward:  {'agent-0': -0.8847585918083638, 'agent-1': -0.9977181047857009, 'agent-2': -0.12326363360527637, 'agent-3': -0.663833237737137} \n",
      "\n",
      "reward:  {'agent-0': 0.4527275616067854, 'agent-1': 1.9565744478784808, 'agent-2': 1.5500222507051546, 'agent-3': 0.5479149713872573} \n",
      "\n",
      "reward:  {'agent-0': 0.45564303747800494, 'agent-1': 1.749740518526533, 'agent-2': -1.5655889391904694, 'agent-3': -0.9821928542729239} \n",
      "\n",
      "reward:  {'agent-0': 1.146141886542452, 'agent-1': 1.0582487162789533, 'agent-2': 2.28091053594871, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -0.5688664074526883, 'agent-1': -1.5209760001887709, 'agent-2': -0.23983685755437634, 'agent-3': 1.9443342959639942} \n",
      "\n",
      "reward:  {'agent-0': -1.0261689267006702, 'agent-1': -1.0055941521447274, 'agent-2': -1.0, 'agent-3': -0.209050702124145} \n",
      "\n",
      "reward:  {'agent-0': 1.6758631278629608, 'agent-1': -0.35390701652274004, 'agent-2': 0.6893706185293027, 'agent-3': -0.08443539781116982} \n",
      "\n",
      "reward:  {'agent-0': 1.6831302221469393, 'agent-1': -0.2137034978201129, 'agent-2': -1.2594126015343434, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 2.7202728887519427, 'agent-1': 0.7791718105307837, 'agent-2': -0.40589985534533923, 'agent-3': -1.0541249321138295} \n",
      "\n",
      "reward:  {'agent-0': 0.4784367322682641, 'agent-1': 1.733253779560826, 'agent-2': 3.239223557672556, 'agent-3': 1.8933140553667123} \n",
      "\n",
      "reward:  {'agent-0': 2.6395874342316716, 'agent-1': -0.07978202023974745, 'agent-2': 0.9037389124570154, 'agent-3': 1.6671831217372386} \n",
      "\n",
      "reward:  {'agent-0': -1.0462168865296348, 'agent-1': 0.5047737575257685, 'agent-2': -0.44985026566123665, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 0.0600119175424787, 'agent-1': 0.8047252251881893, 'agent-2': 1.3814546498248816, 'agent-3': 1.884199969112295} \n",
      "\n",
      "reward:  {'agent-0': 0.03128661355116691, 'agent-1': -0.6400837132140644, 'agent-2': 1.045203335573781, 'agent-3': 1.4701622601155862} \n",
      "\n",
      "reward:  {'agent-0': 2.736040907065984, 'agent-1': 2.6528575158989263, 'agent-2': 1.0004555953414567, 'agent-3': 2.1543901465991997} \n",
      "\n",
      "reward:  {'agent-0': -0.8995153796700492, 'agent-1': -0.4773757099211213, 'agent-2': -0.8825241421081422, 'agent-3': -0.7326394590519474} \n",
      "\n",
      "reward:  {'agent-0': -0.3980568983864927, 'agent-1': -0.21207813691738586, 'agent-2': 2.6720059359791968, 'agent-3': 2.644958160617108} \n",
      "\n",
      "reward:  {'agent-0': 0.4398078202279905, 'agent-1': 1.284310868669051, 'agent-2': 0.5435363044022097, 'agent-3': 0.5935157463074283} \n",
      "\n",
      "reward:  {'agent-0': 1.9850486851525844, 'agent-1': 2.251633671387472, 'agent-2': 0.20393206331918634, 'agent-3': 0.48376337569517425} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 1.7738238711139171, 'agent-2': 1.4480909539241544, 'agent-3': -0.9804175763109235} \n",
      "\n",
      "reward:  {'agent-0': 0.5407656537850727, 'agent-1': 0.9809755639532796, 'agent-2': 1.4103542212338525, 'agent-3': -0.4301505695818335} \n",
      "\n",
      "reward:  {'agent-0': 1.6177651607581787, 'agent-1': 2.601056432628212, 'agent-2': -0.2042537507038702, 'agent-3': 1.0879318247052083} \n",
      "\n",
      "reward:  {'agent-0': -0.459492548556085, 'agent-1': 1.7181947416744894, 'agent-2': 2.4605539487753383, 'agent-3': -1.0657280947604022} \n",
      "\n",
      "reward:  {'agent-0': 1.035314459690035, 'agent-1': -0.14719767847462606, 'agent-2': 2.079410803572408, 'agent-3': 2.415971806803441} \n",
      "\n",
      "reward:  {'agent-0': 0.6040574408032597, 'agent-1': -0.10655852487919404, 'agent-2': 0.6616531327041386, 'agent-3': 1.014502417995974} \n",
      "\n",
      "reward:  {'agent-0': -0.13743960145166767, 'agent-1': 2.4320949836975636, 'agent-2': 2.687186021294515, 'agent-3': 2.180402374263334} \n",
      "\n",
      "reward:  {'agent-0': 2.444614332500805, 'agent-1': 2.3001001430188257, 'agent-2': 1.5806277476531108, 'agent-3': 0.2045967880062456} \n",
      "\n",
      "reward:  {'agent-0': 1.6261684337189841, 'agent-1': -0.07370777960112207, 'agent-2': 0.9911010215395528, 'agent-3': 1.5920441943503842} \n",
      "\n",
      "reward:  {'agent-0': 0.5367186551664815, 'agent-1': 2.1463892890129053, 'agent-2': -0.33380932631967397, 'agent-3': 2.0441299054012205} \n",
      "\n",
      "reward:  {'agent-0': -1.0334079885552896, 'agent-1': 0.9989452376335848, 'agent-2': 1.997759503817818, 'agent-3': -0.3861166888475829} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 1.0529135245315198, 'agent-2': -1.0869752089158595, 'agent-3': 0.3796590555788484} \n",
      "\n",
      "reward:  {'agent-0': 0.9549892938672109, 'agent-1': -2.0119317203647364, 'agent-2': 2.0998358545496956, 'agent-3': -0.20414883166901987} \n",
      "\n",
      "reward:  {'agent-0': 1.512018988153045, 'agent-1': -1.5044082221894675, 'agent-2': 1.2791788055591091, 'agent-3': -1.4858732537449049} \n",
      "\n",
      "reward:  {'agent-0': 2.1999918250675137, 'agent-1': -1.4792951940126509, 'agent-2': -1.0358460226210262, 'agent-3': -0.25388373947111464} \n",
      "\n",
      "reward:  {'agent-0': 1.266641254140879, 'agent-1': -2.848746723907026, 'agent-2': 1.6261601000775272, 'agent-3': -1.5756205690256744} \n",
      "\n",
      "reward:  {'agent-0': 2.41433834094331, 'agent-1': -3.1795538573098714, 'agent-2': -1.2172279573414286, 'agent-3': -1.3666922535707293} \n",
      "\n",
      "reward:  {'agent-0': 0.8831754676335954, 'agent-1': -2.96118794142739, 'agent-2': 0.2546349877897285, 'agent-3': -0.274635025692457} \n",
      "\n",
      "reward:  {'agent-0': -0.9331582239567666, 'agent-1': 0.8152871225810054, 'agent-2': -0.12397234332198082, 'agent-3': -0.04452426644172469} \n",
      "\n",
      "reward:  {'agent-0': 99.0, 'agent-1': 96.30012346226262, 'agent-2': 97.4007973893878, 'agent-3': 95.57177916430881} \n",
      "\n",
      "reward:  {'agent-0': 0.5071796058932065, 'agent-1': -3.0, 'agent-2': 1.8809120262109928, 'agent-3': -4.239439496412842} \n",
      "\n",
      "reward:  {'agent-0': -1.139231925681976, 'agent-1': 0.34091380998826537, 'agent-2': 1.9351128878464579, 'agent-3': -3.186901091159527} \n",
      "\n",
      "reward:  {'agent-0': 1.8066719518064076, 'agent-1': -3.6543277091469264, 'agent-2': -1.0, 'agent-3': -0.16144618017963808} \n",
      "\n",
      "reward:  {'agent-0': 0.4218518729468599, 'agent-1': -2.750304855592148, 'agent-2': 0.035101523640307164, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 1.4916514284595124, 'agent-1': 2.255022567168936, 'agent-2': -3.6478394520246553, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -3.597579417835, 'agent-1': -0.405523415169327, 'agent-2': -1.3963371982486876, 'agent-3': 0.9708902232094516} \n",
      "\n",
      "reward:  {'agent-0': 1.023952581835971, 'agent-1': 1.933465968335355, 'agent-2': -2.280754783723296, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -0.7981531151326138, 'agent-1': 1.743862713748797, 'agent-2': -4.062414777044509, 'agent-3': 1.6454400596053347} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.9776100575495263, 'agent-2': 1.9071522353443555, 'agent-3': 0.9655289619006737} \n",
      "\n",
      "reward:  {'agent-0': -0.2868916381499602, 'agent-1': -2.7861897433272134, 'agent-2': -0.8975099497726404, 'agent-3': 2.316342375341222} \n",
      "\n",
      "reward:  {'agent-0': -0.405548764879029, 'agent-1': 1.3874238544009074, 'agent-2': 2.1102769700034827, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -3.5838807497115113, 'agent-1': 2.22112644222625, 'agent-2': 0.5284560083181162, 'agent-3': -1.6936204419193075} \n",
      "\n",
      "reward:  {'agent-0': 2.2559526138231973, 'agent-1': 1.8865154176179715, 'agent-2': -1.0, 'agent-3': -1.1933852584989921} \n",
      "\n",
      "reward:  {'agent-0': 1.4429356523040724, 'agent-1': 0.8947931815696535, 'agent-2': -1.0, 'agent-3': -0.736583207476528} \n",
      "\n",
      "reward:  {'agent-0': 1.6793889281547294, 'agent-1': 1.7441270455181126, 'agent-2': 1.8583411535231562, 'agent-3': -1.064406558519579} \n",
      "\n",
      "reward:  {'agent-0': 2.2942401896343014, 'agent-1': 0.4943244969015552, 'agent-2': -0.012770146339242672, 'agent-3': -3.923530999891824} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -2.0332872762371608, 'agent-2': 0.7100452070982044, 'agent-3': 1.1556186495673302} \n",
      "\n",
      "reward:  {'agent-0': 2.2496244870572824, 'agent-1': 2.2228989973363866, 'agent-2': -2.5028292017130127, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -2.5274395386388733, 'agent-1': 2.18928100098654, 'agent-2': 1.8638220586784016, 'agent-3': 1.3399048935295497} \n",
      "\n",
      "reward:  {'agent-0': 1.8846804469275682, 'agent-1': 0.7881285733058689, 'agent-2': -0.397621175842346, 'agent-3': -2.140430415397134} \n",
      "\n",
      "reward:  {'agent-0': 2.063334947166325, 'agent-1': -1.0, 'agent-2': 0.3488398353283273, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -5.441945434402243, 'agent-1': 0.017256107147218813, 'agent-2': -0.2201376262761272, 'agent-3': 0.2988092254475134} \n",
      "\n",
      "reward:  {'agent-0': -4.5138415088239725, 'agent-1': 1.5885743188258061, 'agent-2': -0.20248326545409867, 'agent-3': -0.053545248936330836} \n",
      "\n",
      "reward:  {'agent-0': -1.1630667013630713, 'agent-1': -0.8920679139041283, 'agent-2': -0.648495301761038, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 0.0049936587953354206, 'agent-1': -1.2243351219667602, 'agent-2': -2.4682173876978695, 'agent-3': 0.3633553270112202} \n",
      "\n",
      "reward:  {'agent-0': -1.866951540449783, 'agent-1': 1.9131619254445411, 'agent-2': 0.15562148827369526, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 1.1112765111603267, 'agent-1': -6.053998236664839, 'agent-2': -4.140046441663294, 'agent-3': 0.5098431468367153} \n",
      "\n",
      "reward:  {'agent-0': 1.5115239445556554, 'agent-1': -2.980400992212381, 'agent-2': 2.285045474762896, 'agent-3': 0.5397819680096916} \n",
      "\n",
      "reward:  {'agent-0': -2.877670511896426, 'agent-1': 0.9568395688998663, 'agent-2': 0.24272027922352635, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 1.8427880660947054, 'agent-1': -1.9037250664109706, 'agent-2': 1.5274419907597547, 'agent-3': 0.7329258414037838} \n",
      "\n",
      "reward:  {'agent-0': 1.7693965174927015, 'agent-1': -3.376898864194686, 'agent-2': -4.290628660431011, 'agent-3': -0.9764685073029824} \n",
      "\n",
      "reward:  {'agent-0': -2.807535470816852, 'agent-1': -1.1809914150487941, 'agent-2': -4.331749446878582, 'agent-3': -0.5278580902709962} \n",
      "\n",
      "reward:  {'agent-0': -0.9904758107943366, 'agent-1': 2.1370540811133765, 'agent-2': -1.9152398448062016, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 0.30085733042582063, 'agent-1': -1.0, 'agent-2': -1.221865897953812, 'agent-3': -0.8376735921541751} \n",
      "\n",
      "reward:  {'agent-0': -1.6199987411782502, 'agent-1': -2.9786808623486962, 'agent-2': -1.5973539900354226, 'agent-3': -1.1856064875255043} \n",
      "\n",
      "reward:  {'agent-0': 0.6839361956507517, 'agent-1': 1.0753065196302742, 'agent-2': 0.728655745223243, 'agent-3': -2.079533559382199} \n",
      "\n",
      "reward:  {'agent-0': 2.02567555534295, 'agent-1': -1.0, 'agent-2': 0.6426401043853289, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -1.671903401290031, 'agent-1': 2.0526150435042325, 'agent-2': -2.9755715665094655, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -3.966083243692964, 'agent-1': -0.3315288040368074, 'agent-2': -0.8960853333189505, 'agent-3': -3.121691642847594} \n",
      "\n",
      "reward:  {'agent-0': -1.4761896383101814, 'agent-1': -1.513806705108621, 'agent-2': 1.1954140445857817, 'agent-3': -3.0845745296534517} \n",
      "\n",
      "reward:  {'agent-0': -1.562941268957374, 'agent-1': -0.034195909791591816, 'agent-2': 2.0035342897376935, 'agent-3': -1.8956909890956553} \n",
      "\n",
      "reward:  {'agent-0': -5.267023016558888, 'agent-1': -2.332236865485953, 'agent-2': -0.5279734212251341, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -0.12898963969144006, 'agent-1': 1.903092377721535, 'agent-2': -1.000804543617079, 'agent-3': -1.0593229436086204} \n",
      "\n",
      "reward:  {'agent-0': -3.0, 'agent-1': 2.0191246700388916, 'agent-2': 0.2559751474959171, 'agent-3': -0.3275580781401146} \n",
      "\n",
      "reward:  {'agent-0': -1.356880121341689, 'agent-1': 1.3934370879815674, 'agent-2': -3.0, 'agent-3': 2.2541786758601035} \n",
      "\n",
      "reward:  {'agent-0': -1.9589681562027224, 'agent-1': -0.6740269480023642, 'agent-2': -3.0, 'agent-3': 0.11775754940013883} \n",
      "\n",
      "reward:  {'agent-0': -0.2794171442960547, 'agent-1': -1.0, 'agent-2': -4.706638526642564, 'agent-3': 0.6940568651386485} \n",
      "\n",
      "reward:  {'agent-0': -0.06543885232481017, 'agent-1': 0.8358771547461004, 'agent-2': -0.42641702823070915, 'agent-3': 2.3103608844738943} \n",
      "\n",
      "reward:  {'agent-0': 2.275593921810554, 'agent-1': 0.13983061002453212, 'agent-2': -0.8953670770595323, 'agent-3': 0.44854797165697846} \n",
      "\n",
      "reward:  {'agent-0': 2.2192579557252827, 'agent-1': 2.0092906691187267, 'agent-2': -1.3868816524936065, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 2.0279776862652596, 'agent-2': 1.2704796768729238, 'agent-3': 0.6674153788117962} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -1.0, 'agent-2': -4.594388164803512, 'agent-3': -1.1631990818141134} \n",
      "\n",
      "reward:  {'agent-0': 0.719015109031254, 'agent-1': 1.949662712743617, 'agent-2': 1.132119038010238, 'agent-3': 2.052032282876425} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -5.936027853346175, 'agent-2': 0.8084459842240719, 'agent-3': -0.7739424303333209} \n",
      "\n",
      "reward:  {'agent-0': -4.1888551005850445, 'agent-1': 0.01754747615559893, 'agent-2': -2.2982887909256036, 'agent-3': -0.8049040288525475} \n",
      "\n",
      "reward:  {'agent-0': -1.5453363362665442, 'agent-1': -0.7712187615525892, 'agent-2': -3.058211358872377, 'agent-3': -0.1535733549620204} \n",
      "\n",
      "reward:  {'agent-0': 1.2973814843046512, 'agent-1': -5.449776481118462, 'agent-2': 1.768338676091581, 'agent-3': -2.983385578594749} \n",
      "\n",
      "reward:  {'agent-0': 1.6783117524029336, 'agent-1': -0.20981028719404549, 'agent-2': 1.5428139661528846, 'agent-3': -1.5868100917915768} \n",
      "\n",
      "reward:  {'agent-0': 1.9762941493577912, 'agent-1': 1.7366320701631182, 'agent-2': 1.1817601202119477, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -4.0296154991250575, 'agent-1': -1.0, 'agent-2': 1.0948043524550428, 'agent-3': 1.9205473442569456} \n",
      "\n",
      "reward:  {'agent-0': 2.3548025318330588, 'agent-1': -1.2751149253109801, 'agent-2': -1.0, 'agent-3': 1.1692268525455347} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -4.999720483988099, 'agent-2': 2.3713178946540197, 'agent-3': 0.14157116382163792} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.3399602660768295, 'agent-2': 0.15646212130172188, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 0.2862725383574869, 'agent-1': -4.174187344875747, 'agent-2': 0.9975065840949071, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 2.2835821271272323, 'agent-1': 0.7214028362708831, 'agent-2': -1.8260746007832225, 'agent-3': -0.6153344073456424} \n",
      "\n",
      "reward:  {'agent-0': 1.224803910119583, 'agent-1': -4.847951623908109, 'agent-2': -0.45745528398562385, 'agent-3': -4.097455999057061} \n",
      "\n",
      "reward:  {'agent-0': 0.05234878936379772, 'agent-1': -3.0, 'agent-2': 2.5764271056489605, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': -3.9384793178935027, 'agent-1': -0.277582964812197, 'agent-2': -0.8615506266320665, 'agent-3': -2.4286228811579633} \n",
      "\n",
      "reward:  {'agent-0': -3.8957694056670604, 'agent-1': -0.19887730550125582, 'agent-2': -1.1591622692363117, 'agent-3': -0.6677682673781362} \n",
      "\n",
      "reward:  {'agent-0': -1.2773002258225574, 'agent-1': 0.3530692050773112, 'agent-2': 0.7162848255700069, 'agent-3': -3.187538940338058} \n",
      "\n",
      "reward:  {'agent-0': 1.1539016934449222, 'agent-1': -0.30093826605939, 'agent-2': 1.869374013429443, 'agent-3': -0.6093186522277279} \n",
      "\n",
      "reward:  {'agent-0': 1.9350426039337947, 'agent-1': -0.3709762627234241, 'agent-2': -2.1382278163932114, 'agent-3': -3.838309509945482} \n",
      "\n",
      "reward:  {'agent-0': 2.0667765783216865, 'agent-1': 1.7619046009727697, 'agent-2': 0.6719568712370148, 'agent-3': -0.8877593799690615} \n",
      "\n",
      "reward:  {'agent-0': 2.000201740669567, 'agent-1': -5.934709589682015, 'agent-2': -1.9322272768968318, 'agent-3': -5.051115871265097} \n",
      "\n",
      "reward:  {'agent-0': 1.541026176060278, 'agent-1': -0.2408432371698055, 'agent-2': -1.0, 'agent-3': -3.9841445443169334} \n",
      "\n",
      "reward:  {'agent-0': -1.0921060379687262, 'agent-1': -0.6804499128293529, 'agent-2': -0.6068389895076152, 'agent-3': -0.05277874070080202} \n",
      "\n",
      "reward:  {'agent-0': 1.9843436479827545, 'agent-1': -4.361230516737351, 'agent-2': -1.0, 'agent-3': -0.9730822105058365} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.06876184486042547, 'agent-2': -2.5207102956597964, 'agent-3': -3.9588005131838173} \n",
      "\n",
      "reward:  {'agent-0': 1.9915073787512583, 'agent-1': 2.0893478033220276, 'agent-2': 0.6055785375170402, 'agent-3': -4.004599048080522} \n",
      "\n",
      "reward:  {'agent-0': 0.16332256864087924, 'agent-1': -0.9068454128782975, 'agent-2': 2.4881677460069938, 'agent-3': 0.4828818216930415} \n",
      "\n",
      "reward:  {'agent-0': -1.7425763025823926, 'agent-1': 1.537590545385605, 'agent-2': -0.12339510003491228, 'agent-3': 1.9732375765455288} \n",
      "\n",
      "reward:  {'agent-0': 1.6902960948228412, 'agent-1': -4.30160675227922, 'agent-2': 1.7569449955121996, 'agent-3': -0.04102964087694261} \n",
      "\n",
      "reward:  {'agent-0': -0.7691596001656649, 'agent-1': 0.9011682542220427, 'agent-2': -1.5479979015185137, 'agent-3': -1.8188803891525112} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -3.6390672729227163, 'agent-2': 0.27605811058013785, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': 0.7254979089076059, 'agent-1': -3.6136793711105852, 'agent-2': -1.4213878607931605, 'agent-3': -0.6137072413938824} \n",
      "\n",
      "reward:  {'agent-0': 2.038564707313501, 'agent-1': 1.4618792939894618, 'agent-2': 2.185088177390085, 'agent-3': 1.834231542883586} \n",
      "\n",
      "reward:  {'agent-0': 1.276388460602842, 'agent-1': -2.7740387220301415, 'agent-2': 1.6113439825826674, 'agent-3': -0.8875534719841482} \n",
      "\n",
      "reward:  {'agent-0': 2.1481676554443325, 'agent-1': 1.9973748589816012, 'agent-2': 2.9438746906760613, 'agent-3': -1.6821314311320492} \n",
      "\n",
      "reward:  {'agent-0': -0.5128578938486541, 'agent-1': -0.35639702723157995, 'agent-2': 2.922923258768293, 'agent-3': -0.11228787996878964} \n",
      "\n",
      "reward:  {'agent-0': 1.6156136367459268, 'agent-1': 1.4752361678080277, 'agent-2': 1.06698113695343, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -0.9947406972062609, 'agent-1': -1.1935188361386935, 'agent-2': 2.927280483145225, 'agent-3': -0.8933106111679407} \n",
      "\n",
      "reward:  {'agent-0': 0.2275310868727587, 'agent-1': -1.0, 'agent-2': -1.1578016390482304, 'agent-3': -0.9933297360111908} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 1.426063359355247, 'agent-2': 1.6161228624269626, 'agent-3': 2.049979798458267} \n",
      "\n",
      "reward:  {'agent-0': 2.1109471132487947, 'agent-1': -1.0, 'agent-2': -0.9240019289769705, 'agent-3': 1.9481572482118708} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': 1.7709655401990645, 'agent-2': 0.0733519410857042, 'agent-3': -2.947645570165136} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -0.3492931572450857, 'agent-2': -0.09144287999314571, 'agent-3': -0.8592144155457433} \n",
      "\n",
      "reward:  {'agent-0': 0.2868065310275689, 'agent-1': -2.5626131225486475, 'agent-2': 2.580068683112877, 'agent-3': 0.8386286341030953} \n",
      "\n",
      "reward:  {'agent-0': 1.927774114831454, 'agent-1': -3.79459420238787, 'agent-2': -2.8928670767988294, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 0.9712346506294018, 'agent-1': -0.9686818032350644, 'agent-2': -0.025138882688466424, 'agent-3': -1.1141732616773226} \n",
      "\n",
      "reward:  {'agent-0': 2.0492948065088115, 'agent-1': -6.109251893154756, 'agent-2': -1.3312751577668962, 'agent-3': -3.3149151784865083} \n",
      "\n",
      "reward:  {'agent-0': -1.7601372939029147, 'agent-1': -2.347143563511459, 'agent-2': -3.244974038534089, 'agent-3': -0.2398153616841583} \n",
      "\n",
      "reward:  {'agent-0': -0.3303881720309789, 'agent-1': -0.9401505906669954, 'agent-2': 0.11214325591664931, 'agent-3': -1.5181456671379792} \n",
      "\n",
      "reward:  {'agent-0': -0.48476108715465216, 'agent-1': -1.3487154969062516, 'agent-2': 1.0324338322119573, 'agent-3': -0.39469661042608095} \n",
      "\n",
      "reward:  {'agent-0': -3.8961241177778803, 'agent-1': -3.0, 'agent-2': 1.2665002188930998, 'agent-3': -3.0561494159440272} \n",
      "\n",
      "reward:  {'agent-0': 0.16860084350823712, 'agent-1': -0.8136534744649637, 'agent-2': 0.04779656052268422, 'agent-3': -1.14487742463551} \n",
      "\n",
      "reward:  {'agent-0': 1.0012981845806905, 'agent-1': -0.6010435375925312, 'agent-2': -3.0337765289767376, 'agent-3': -1.0} \n",
      "\n",
      "reward:  {'agent-0': -0.7827005808573269, 'agent-1': -3.0, 'agent-2': -0.6993193842197272, 'agent-3': -0.7063619901365001} \n",
      "\n",
      "reward:  {'agent-0': 1.7133152652917722, 'agent-1': -2.4366511314043606, 'agent-2': -1.844380214014734, 'agent-3': -1.1698891293646199} \n",
      "\n",
      "reward:  {'agent-0': 0.9158549591182279, 'agent-1': -3.227266867527703, 'agent-2': 0.9071305110921486, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 1.1305079594065823, 'agent-1': -0.42279561979145086, 'agent-2': -3.2935207502456336, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 1.8722963703953859, 'agent-1': -5.229266384577315, 'agent-2': 0.17648777450320807, 'agent-3': -0.4532475784852963} \n",
      "\n",
      "reward:  {'agent-0': -2.9380766494819532, 'agent-1': -4.673553162597656, 'agent-2': -2.473681670594509, 'agent-3': -3.2877106197097845} \n",
      "\n",
      "reward:  {'agent-0': 0.21179155979828224, 'agent-1': -1.9401334734299027, 'agent-2': -1.0, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': -1.0, 'agent-1': -3.0, 'agent-2': 0.5257831620843447, 'agent-3': -2.156457152170425} \n",
      "\n",
      "reward:  {'agent-0': 1.169895618485345, 'agent-1': -1.1217353594065997, 'agent-2': 0.893668623216314, 'agent-3': -0.5724134224586734} \n",
      "\n",
      "reward:  {'agent-0': 1.4216457339512338, 'agent-1': -3.8000992577617723, 'agent-2': -1.0, 'agent-3': -4.7471726962324965} \n",
      "\n",
      "reward:  {'agent-0': -0.005603625271387358, 'agent-1': -2.0219295199446705, 'agent-2': -0.14381156638907555, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 1.8695260884631182, 'agent-1': 0.7147068201829896, 'agent-2': -0.085414136246726, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 2.44999089942041, 'agent-1': -3.0, 'agent-2': -4.89997990510799, 'agent-3': 0.02946752449165757} \n",
      "\n",
      "reward:  {'agent-0': -1.8713020463243986, 'agent-1': -1.6509047400862116, 'agent-2': -0.17197539118978966, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 1.5228514194382772, 'agent-1': -3.0, 'agent-2': -1.0, 'agent-3': -0.3687334078287634} \n",
      "\n",
      "reward:  {'agent-0': 0.6413874615813437, 'agent-1': 0.08191364144546753, 'agent-2': 0.8347620991468006, 'agent-3': -2.6778776194510527} \n",
      "\n",
      "reward:  {'agent-0': 0.6227542798553269, 'agent-1': -2.477147840639411, 'agent-2': 2.437777507444615, 'agent-3': -2.386585173279556} \n",
      "\n",
      "reward:  {'agent-0': 0.8259563357103161, 'agent-1': -0.4529916715568376, 'agent-2': -1.0, 'agent-3': -2.9605994956292605} \n",
      "\n",
      "reward:  {'agent-0': 0.7547195017595065, 'agent-1': -1.3706871742072124, 'agent-2': -0.719325687264611, 'agent-3': -0.5888312193106557} \n",
      "\n",
      "reward:  {'agent-0': 0.2524405498382265, 'agent-1': -1.992506355766963, 'agent-2': -3.077194640897215, 'agent-3': -6.623027198357661} \n",
      "\n",
      "reward:  {'agent-0': -0.02251784361307685, 'agent-1': -0.15687091351568228, 'agent-2': -2.060195491773058, 'agent-3': -6.6524384014410245} \n",
      "\n",
      "reward:  {'agent-0': -0.011019471941244419, 'agent-1': -3.0, 'agent-2': -1.0, 'agent-3': -0.9064173856728388} \n",
      "\n",
      "reward:  {'agent-0': -0.19939102277959186, 'agent-1': -4.115973163917566, 'agent-2': -0.02725050658033723, 'agent-3': -0.9906920546663898} \n",
      "\n",
      "reward:  {'agent-0': -0.39153507876023497, 'agent-1': -2.1181362753710715, 'agent-2': 0.34664644616495366, 'agent-3': -1.5632180204793258} \n",
      "\n",
      "reward:  {'agent-0': -0.5039922802225387, 'agent-1': -1.00466160785259, 'agent-2': -0.4049135042614367, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': -4.3177060165308205, 'agent-1': -3.0, 'agent-2': 1.511157600559514, 'agent-3': -0.6373563889544656} \n",
      "\n",
      "reward:  {'agent-0': 2.6191540949248946, 'agent-1': -5.353219104998281, 'agent-2': -0.3311135590538754, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 0.4423113529712701, 'agent-1': 0.6306610033494238, 'agent-2': -2.4082774707864054, 'agent-3': -3.299228404753535} \n",
      "\n",
      "reward:  {'agent-0': 3.0026518678646728, 'agent-1': 0.434555199389969, 'agent-2': 0.6215528897801015, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 0.9077713509518972, 'agent-1': -6.351032617494084, 'agent-2': -1.0, 'agent-3': -0.4733561891344351} \n",
      "\n",
      "reward:  {'agent-0': -0.11080216703334145, 'agent-1': -4.082836926282027, 'agent-2': -1.0304414128758026, 'agent-3': -3.496530380481346} \n",
      "\n",
      "reward:  {'agent-0': 0.7281190249105212, 'agent-1': -3.0, 'agent-2': -2.983700765738593, 'agent-3': -3.1085121937423352} \n",
      "\n",
      "reward:  {'agent-0': 0.6282890600435938, 'agent-1': -0.357911421719983, 'agent-2': 0.1840072285313603, 'agent-3': -6.58225842368504} \n",
      "\n",
      "reward:  {'agent-0': 0.8126793750510162, 'agent-1': -1.313368101029674, 'agent-2': -0.9873412152863459, 'agent-3': -3.0} \n",
      "\n",
      "reward:  {'agent-0': 1.641284132043646, 'agent-1': -2.139455258718897, 'agent-2': -0.8156374556788855, 'agent-3': -6.026260372345817} \n",
      "\n",
      "reward:  {'agent-0': 1.638775223617774, 'agent-1': -3.0, 'agent-2': -1.0, 'agent-3': -2.009146828962038} \n",
      "\n",
      "reward:  {'agent-0': 99, 'agent-1': 99, 'agent-2': 99, 'agent-3': 99} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n",
      "reward:  {'agent-0': -1, 'agent-1': -1, 'agent-2': -1, 'agent-3': -1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gymnasium.wrappers.time_limit import TimeLimit\n",
    "\n",
    "trainin_steps = 60\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "    .training(gamma = 0.925, \n",
    "              lr = 0.001,\n",
    "              train_batch_size = 4096, \n",
    "              sgd_minibatch_size = 256, \n",
    "              num_sgd_iter = 30,\n",
    "              #entropy_coeff=0.005,\n",
    "              )\n",
    "    .env_runners(num_env_runners=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3\")\n",
    "    .build()\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "out = \"\"\n",
    "for i in range(trainin_steps):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += ppo_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    simulate_episode(RenderableKeepTheDistance(env_config), algo, 500, sleep_between_frames=0.01, print_reward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18154569baea4387b210510919987a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config_2 = EnvironmentConfiguration(\n",
    "    n_agents = 10,\n",
    "    n_targets = 30,\n",
    "    spawn_area = 300,\n",
    "    max_steps=600,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=2)\n",
    "simulate_episode(RenderableKeepTheDistance(env_config_2), algo, 600, sleep_between_frames=0.01, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Algorithm checkpoint has been created inside directory: 'TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/c/Users/nicol/Desktop/Università/tesi/experiments/RL_experiments/algos/collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 6.850533539305131, 'cur_kl_coeff': 3.417187499999999, 'cur_lr': 0.0010000000000000005, 'total_loss': 8.01003879532218, 'policy_loss': -0.019474794888325656, 'vf_loss': 7.9856410051385565, 'vf_explained_var': 0.17176912014062207, 'kl': 0.012838793924716659, 'entropy': 4.168454428389668, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 256.0, 'num_grad_updates_lifetime': 114240.5, 'diff_num_grad_updates_vs_sampler_policy': 959.5}}, 'num_env_steps_sampled': 245760, 'num_env_steps_trained': 245760, 'num_agent_steps_sampled': 983040, 'num_agent_steps_trained': 983040}, 'sampler_results': {'episode_reward_max': 2397.522829182155, 'episode_reward_min': 832.6234792740323, 'episode_reward_mean': 2105.5878031370885, 'episode_len_mean': 146.24, 'episode_media': {}, 'episodes_this_iter': 23, 'episodes_timesteps_total': 14624, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2133.046603149003, 1988.2090201046947, 2260.443892177175, 2286.7922829409094, 2140.5115118461727, 2111.1864449679224, 1774.493090818275, 2116.062900820729, 2285.381603194537, 2090.8164036800745, 2103.8728103585086, 1866.388008946097, 2202.294764447383, 2232.9229862692046, 2055.7740422427587, 1983.9700023481969, 2076.190892639439, 1969.6634473753577, 1980.4469812436714, 2160.9031073408883, 2321.035602117559, 1978.485802662895, 2306.593287067144, 2111.5458171424475, 2141.48859334442, 2397.522829182155, 2195.8815149215125, 1980.3888954163315, 1996.6074649147904, 2153.7772769525727, 2033.5438952193467, 2207.06217337459, 2295.8263314400388, 2341.787012362229, 2162.1076269339437, 2122.1756485345422, 2082.515582213897, 2161.610900475729, 2123.45784165871, 2166.933953629488, 2266.9673842486836, 1856.19097668361, 2136.986957033053, 2165.0963881661473, 2234.944149111189, 2071.9135427134324, 2133.646273484895, 2290.043955878669, 2151.6563290445747, 2265.8769648328034, 2234.1745481607663, 2253.677627928545, 2207.82981248457, 2069.2648262798502, 2169.194322482531, 1553.3498144181617, 1848.235485854022, 2045.8985365596573, 2167.2981766606163, 2080.798619101917, 2353.862290240667, 2112.7599216655353, 2116.8550708987686, 2128.0080401076575, 2153.0406180402547, 2119.8415600950257, 2120.9186309897214, 2204.417907930899, 2122.0681963273146, 2059.0700426893136, 2201.5998074399618, 1908.6479898513815, 2195.1453132035886, 2173.700176887496, 2263.524731860678, 2016.7667286173119, 2202.662761117742, 1991.248553410505, 2227.0996294287024, 2306.4109963975025, 2059.429934594925, 2235.7025832641243, 2177.8838822279627, 1233.0695468237577, 2207.2150272672216, 2203.4394953084065, 2033.2215366833918, 2055.2165987167127, 2093.058559937222, 2257.7799768640093, 1986.084012985298, 2156.58852581049, 832.6234792740323, 1868.7487927997815, 2159.0532293090637, 2219.1375043426933, 2222.174175804962, 2142.690988982932, 2157.115011480336, 1978.1349464284467], 'episode_lengths': [101, 89, 116, 156, 78, 208, 199, 124, 111, 120, 285, 132, 132, 101, 156, 147, 75, 107, 217, 167, 146, 194, 186, 129, 255, 247, 111, 161, 131, 111, 89, 106, 110, 221, 132, 37, 69, 73, 40, 59, 152, 270, 75, 136, 120, 50, 122, 184, 175, 102, 126, 130, 77, 128, 140, 168, 185, 121, 103, 83, 234, 83, 184, 158, 96, 258, 64, 122, 90, 240, 143, 113, 179, 180, 120, 91, 150, 212, 92, 148, 256, 134, 185, 355, 108, 140, 230, 163, 129, 77, 128, 101, 362, 272, 108, 131, 103, 260, 63, 287]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6523964808997097, 'mean_inference_ms': 1.013421567543766, 'mean_action_processing_ms': 0.3938722556905475, 'mean_env_wait_ms': 1.3963616244606394, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0075533390045166016, 'StateBufferConnector_ms': 0.006699323654174805, 'ViewRequirementAgentConnector_ms': 0.24482393264770508}, 'num_episodes': 23, 'episode_return_max': 2397.522829182155, 'episode_return_min': 832.6234792740323, 'episode_return_mean': 2105.5878031370885}, 'env_runner_results': {'episode_reward_max': 2397.522829182155, 'episode_reward_min': 832.6234792740323, 'episode_reward_mean': 2105.5878031370885, 'episode_len_mean': 146.24, 'episode_media': {}, 'episodes_this_iter': 23, 'episodes_timesteps_total': 14624, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2133.046603149003, 1988.2090201046947, 2260.443892177175, 2286.7922829409094, 2140.5115118461727, 2111.1864449679224, 1774.493090818275, 2116.062900820729, 2285.381603194537, 2090.8164036800745, 2103.8728103585086, 1866.388008946097, 2202.294764447383, 2232.9229862692046, 2055.7740422427587, 1983.9700023481969, 2076.190892639439, 1969.6634473753577, 1980.4469812436714, 2160.9031073408883, 2321.035602117559, 1978.485802662895, 2306.593287067144, 2111.5458171424475, 2141.48859334442, 2397.522829182155, 2195.8815149215125, 1980.3888954163315, 1996.6074649147904, 2153.7772769525727, 2033.5438952193467, 2207.06217337459, 2295.8263314400388, 2341.787012362229, 2162.1076269339437, 2122.1756485345422, 2082.515582213897, 2161.610900475729, 2123.45784165871, 2166.933953629488, 2266.9673842486836, 1856.19097668361, 2136.986957033053, 2165.0963881661473, 2234.944149111189, 2071.9135427134324, 2133.646273484895, 2290.043955878669, 2151.6563290445747, 2265.8769648328034, 2234.1745481607663, 2253.677627928545, 2207.82981248457, 2069.2648262798502, 2169.194322482531, 1553.3498144181617, 1848.235485854022, 2045.8985365596573, 2167.2981766606163, 2080.798619101917, 2353.862290240667, 2112.7599216655353, 2116.8550708987686, 2128.0080401076575, 2153.0406180402547, 2119.8415600950257, 2120.9186309897214, 2204.417907930899, 2122.0681963273146, 2059.0700426893136, 2201.5998074399618, 1908.6479898513815, 2195.1453132035886, 2173.700176887496, 2263.524731860678, 2016.7667286173119, 2202.662761117742, 1991.248553410505, 2227.0996294287024, 2306.4109963975025, 2059.429934594925, 2235.7025832641243, 2177.8838822279627, 1233.0695468237577, 2207.2150272672216, 2203.4394953084065, 2033.2215366833918, 2055.2165987167127, 2093.058559937222, 2257.7799768640093, 1986.084012985298, 2156.58852581049, 832.6234792740323, 1868.7487927997815, 2159.0532293090637, 2219.1375043426933, 2222.174175804962, 2142.690988982932, 2157.115011480336, 1978.1349464284467], 'episode_lengths': [101, 89, 116, 156, 78, 208, 199, 124, 111, 120, 285, 132, 132, 101, 156, 147, 75, 107, 217, 167, 146, 194, 186, 129, 255, 247, 111, 161, 131, 111, 89, 106, 110, 221, 132, 37, 69, 73, 40, 59, 152, 270, 75, 136, 120, 50, 122, 184, 175, 102, 126, 130, 77, 128, 140, 168, 185, 121, 103, 83, 234, 83, 184, 158, 96, 258, 64, 122, 90, 240, 143, 113, 179, 180, 120, 91, 150, 212, 92, 148, 256, 134, 185, 355, 108, 140, 230, 163, 129, 77, 128, 101, 362, 272, 108, 131, 103, 260, 63, 287]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6523964808997097, 'mean_inference_ms': 1.013421567543766, 'mean_action_processing_ms': 0.3938722556905475, 'mean_env_wait_ms': 1.3963616244606394, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0075533390045166016, 'StateBufferConnector_ms': 0.006699323654174805, 'ViewRequirementAgentConnector_ms': 0.24482393264770508}, 'num_episodes': 23, 'episode_return_max': 2397.522829182155, 'episode_return_min': 832.6234792740323, 'episode_return_mean': 2105.5878031370885}, 'episode_reward_max': 2397.522829182155, 'episode_reward_min': 832.6234792740323, 'episode_reward_mean': 2105.5878031370885, 'episode_len_mean': 146.24, 'episodes_this_iter': 23, 'episodes_timesteps_total': 14624, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2133.046603149003, 1988.2090201046947, 2260.443892177175, 2286.7922829409094, 2140.5115118461727, 2111.1864449679224, 1774.493090818275, 2116.062900820729, 2285.381603194537, 2090.8164036800745, 2103.8728103585086, 1866.388008946097, 2202.294764447383, 2232.9229862692046, 2055.7740422427587, 1983.9700023481969, 2076.190892639439, 1969.6634473753577, 1980.4469812436714, 2160.9031073408883, 2321.035602117559, 1978.485802662895, 2306.593287067144, 2111.5458171424475, 2141.48859334442, 2397.522829182155, 2195.8815149215125, 1980.3888954163315, 1996.6074649147904, 2153.7772769525727, 2033.5438952193467, 2207.06217337459, 2295.8263314400388, 2341.787012362229, 2162.1076269339437, 2122.1756485345422, 2082.515582213897, 2161.610900475729, 2123.45784165871, 2166.933953629488, 2266.9673842486836, 1856.19097668361, 2136.986957033053, 2165.0963881661473, 2234.944149111189, 2071.9135427134324, 2133.646273484895, 2290.043955878669, 2151.6563290445747, 2265.8769648328034, 2234.1745481607663, 2253.677627928545, 2207.82981248457, 2069.2648262798502, 2169.194322482531, 1553.3498144181617, 1848.235485854022, 2045.8985365596573, 2167.2981766606163, 2080.798619101917, 2353.862290240667, 2112.7599216655353, 2116.8550708987686, 2128.0080401076575, 2153.0406180402547, 2119.8415600950257, 2120.9186309897214, 2204.417907930899, 2122.0681963273146, 2059.0700426893136, 2201.5998074399618, 1908.6479898513815, 2195.1453132035886, 2173.700176887496, 2263.524731860678, 2016.7667286173119, 2202.662761117742, 1991.248553410505, 2227.0996294287024, 2306.4109963975025, 2059.429934594925, 2235.7025832641243, 2177.8838822279627, 1233.0695468237577, 2207.2150272672216, 2203.4394953084065, 2033.2215366833918, 2055.2165987167127, 2093.058559937222, 2257.7799768640093, 1986.084012985298, 2156.58852581049, 832.6234792740323, 1868.7487927997815, 2159.0532293090637, 2219.1375043426933, 2222.174175804962, 2142.690988982932, 2157.115011480336, 1978.1349464284467], 'episode_lengths': [101, 89, 116, 156, 78, 208, 199, 124, 111, 120, 285, 132, 132, 101, 156, 147, 75, 107, 217, 167, 146, 194, 186, 129, 255, 247, 111, 161, 131, 111, 89, 106, 110, 221, 132, 37, 69, 73, 40, 59, 152, 270, 75, 136, 120, 50, 122, 184, 175, 102, 126, 130, 77, 128, 140, 168, 185, 121, 103, 83, 234, 83, 184, 158, 96, 258, 64, 122, 90, 240, 143, 113, 179, 180, 120, 91, 150, 212, 92, 148, 256, 134, 185, 355, 108, 140, 230, 163, 129, 77, 128, 101, 362, 272, 108, 131, 103, 260, 63, 287]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6523964808997097, 'mean_inference_ms': 1.013421567543766, 'mean_action_processing_ms': 0.3938722556905475, 'mean_env_wait_ms': 1.3963616244606394, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0075533390045166016, 'StateBufferConnector_ms': 0.006699323654174805, 'ViewRequirementAgentConnector_ms': 0.24482393264770508}, 'num_episodes': 23, 'episode_return_max': 2397.522829182155, 'episode_return_min': 832.6234792740323, 'episode_return_mean': 2105.5878031370885, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 983040, 'num_agent_steps_trained': 983040, 'num_env_steps_sampled': 245760, 'num_env_steps_trained': 245760, 'num_env_steps_sampled_this_iter': 4096, 'num_env_steps_trained_this_iter': 4096, 'num_env_steps_sampled_throughput_per_sec': 153.37152215708207, 'num_env_steps_trained_throughput_per_sec': 153.37152215708207, 'timesteps_total': 245760, 'num_env_steps_sampled_lifetime': 245760, 'num_agent_steps_sampled_lifetime': 983040, 'num_steps_trained_this_iter': 4096, 'agent_timesteps_total': 983040, 'timers': {'training_iteration_time_ms': 26702.057, 'restore_workers_time_ms': 0.014, 'training_step_time_ms': 26702.017, 'sample_time_ms': 14023.061, 'load_time_ms': 2.261, 'load_throughput': 1811802.027, 'learn_time_ms': 12671.888, 'learn_throughput': 323.235, 'synch_weights_time_ms': 3.881}, 'counters': {'num_env_steps_sampled': 245760, 'num_env_steps_trained': 245760, 'num_agent_steps_sampled': 983040, 'num_agent_steps_trained': 983040}, 'done': False, 'episodes_total': 1150, 'training_iteration': 60, 'trial_id': 'default', 'date': '2024-06-04_13-02-21', 'timestamp': 1717498941, 'time_this_iter_s': 26.71162748336792, 'time_total_s': 1627.6217823028564, 'pid': 7060, 'hostname': 'LAPTOP-9AD2MD1C', 'node_ip': '172.23.85.106', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.925, 'lr': 0.001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4096, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f4654d616c0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 1627.6217823028564, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 36.99782608695652, 'ram_util_percent': 76.92391304347828}})'.\n"
     ]
    }
   ],
   "source": [
    "save_algo(algo, \"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 5,\n",
    "    spawn_area = 100,\n",
    "    max_steps=500,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=3)\n",
    "register_env(\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4\", lambda _: KeepTheDistance(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:37:36,731\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "2024-06-25 15:37:41,910\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "algo = load_algo(\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainin_steps):\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     clear_output()\n\u001b[1;32m     28\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ppo_result_format(result) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:328\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:873\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    863\u001b[0m     (\n\u001b[1;32m    864\u001b[0m         train_results,\n\u001b[1;32m    865\u001b[0m         eval_results,\n\u001b[1;32m    866\u001b[0m         train_iter_ctx,\n\u001b[1;32m    867\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 873\u001b[0m     train_results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:3156\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_STEP_TIMER]:\n\u001b[0;32m-> 3156\u001b[0m                 results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:428\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_step_new_api_stack()\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# Old and hybrid API stacks (Policy, RolloutWorker, Connector, maybe RLModule,\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# maybe Learner).\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training_step_old_and_hybrid_api_stacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:562\u001b[0m, in \u001b[0;36mPPO._training_step_old_and_hybrid_api_stacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    558\u001b[0m         worker_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers,\n\u001b[1;32m    559\u001b[0m         max_agent_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtotal_train_batch_size,\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mas_multi_agent()\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39magent_steps()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/execution/rollout_ops.py:97\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat, sample_timeout_s, _uses_new_env_runners, _return_metrics)\u001b[0m\n\u001b[1;32m     94\u001b[0m         stats_dicts \u001b[38;5;241m=\u001b[39m [worker_set\u001b[38;5;241m.\u001b[39mlocal_worker()\u001b[38;5;241m.\u001b[39mget_metrics()]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m \u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_return_metrics\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Nothing was returned (maybe all workers are stalling) or no healthy\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# remote workers left: Break.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampled_data \u001b[38;5;129;01mor\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mnum_healthy_remote_workers() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:840\u001b[0m, in \u001b[0;36mEnvRunnerGroup.foreach_worker\u001b[0;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_manager\u001b[38;5;241m.\u001b[39mactor_ids():\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m local_result\n\u001b[0;32m--> 840\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m _handle_remote_call_result_errors(\n\u001b[1;32m    850\u001b[0m     remote_results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_env_runner_failures\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:622\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    616\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[1;32m    617\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    618\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    619\u001b[0m )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:476\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[0;32m--> 476\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/worker.py:2854\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2852\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2853\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2854\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3812\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:571\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gymnasium.wrappers.time_limit import TimeLimit\n",
    "\n",
    "trainin_steps = 45\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "    .training(gamma = 0.95, #0.95\n",
    "              lr = 0.001, #0.001\n",
    "              train_batch_size = 4096, #4096\n",
    "              sgd_minibatch_size = 512, #512 \n",
    "              num_sgd_iter = 30, #30\n",
    "              #entropy_coeff=0.005,\n",
    "              )\n",
    "    .env_runners(num_env_runners=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4\")\n",
    "    .build()\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "out = \"\"\n",
    "for i in range(trainin_steps):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += ppo_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    simulate_episode(RenderableKeepTheDistance(env_config), algo, 500, sleep_between_frames=0.01, print_reward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645714a1e2db49fd8d92e05d8598ed60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config_2 = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 10,\n",
    "    spawn_area = 100,\n",
    "    max_steps=10_000,\n",
    "    agent_range = 1,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=3)\n",
    "simulate_episode(RenderableKeepTheDistance(env_config_2), algo, 10_000, sleep_between_frames=0.01, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Algorithm checkpoint has been created inside directory: 'TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/c/Users/nicol/Desktop/Università/tesi/experiments/RL_experiments/algos/collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 7.273746635143955, 'cur_kl_coeff': 5.125781250000001, 'cur_lr': 0.0010000000000000005, 'total_loss': 8.50477758795023, 'policy_loss': -0.007772307634634975, 'vf_loss': 8.418396555384, 'vf_explained_var': 0.15168431078394254, 'kl': 0.01836858958067756, 'entropy': 3.545297836512327, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 512.0, 'num_grad_updates_lifetime': 42720.5, 'diff_num_grad_updates_vs_sampler_policy': 479.5}}, 'num_env_steps_sampled': 184320, 'num_env_steps_trained': 184320, 'num_agent_steps_sampled': 737280, 'num_agent_steps_trained': 737280}, 'sampler_results': {'episode_reward_max': 2242.434752213775, 'episode_reward_min': 1112.3197397508413, 'episode_reward_mean': 2003.8040254429181, 'episode_len_mean': 186.61, 'episode_media': {}, 'episodes_this_iter': 21, 'episodes_timesteps_total': 18661, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2173.799576516096, 2052.482929494625, 2174.594838811713, 2125.211813130501, 2179.312365781165, 2221.71348014249, 2224.924927380688, 2024.405107688117, 1985.2932966794317, 1890.5980897770953, 1825.1094044372824, 1692.113888318755, 2117.4251881216005, 2133.0073112750547, 1817.1524497857029, 2240.7532743929105, 2045.6561147768423, 1651.7111488016708, 2011.180370201446, 2237.6896869279617, 2012.4056082712466, 1856.7229904112241, 1841.5442133426047, 2075.351989016992, 1757.903176441548, 2098.272998100935, 1920.5023223489227, 1887.988231758556, 2033.4147339016658, 2011.556731892545, 1955.0703119755913, 1819.1599214414844, 1426.1903248343028, 2132.2347943608056, 2242.434752213775, 2030.1026145020628, 1910.2408632156328, 1973.1910511228616, 2110.484624088019, 1845.2873151365943, 1946.288209264045, 2102.422671549187, 2100.575149442737, 2176.991507503346, 1982.2912123551528, 2132.1082916199134, 2141.5212935289683, 2060.8134149630964, 2078.7581122330485, 2028.4117361709184, 2061.1721140606323, 1791.7218432641116, 1807.9295131767337, 2124.0802385870984, 2235.422945960414, 2173.007486372, 1933.8478915962064, 1967.4764686628637, 2149.10162529613, 1929.6346928714395, 1924.6380774578004, 2119.2005956880216, 1985.9705863683669, 2180.2463829404846, 1899.4435924207194, 2199.302289703128, 2025.450351737391, 2187.359723269803, 1948.5067821958287, 2066.60325874736, 1916.5901081183615, 2133.266660742911, 2034.5041171558883, 2183.8494219825575, 1965.8393527640312, 1800.9735730712669, 2194.364426020951, 1820.3431594107149, 1925.8665798215673, 1112.3197397508413, 2042.4449509445526, 2001.388455902209, 2061.664300130091, 2051.9002704667782, 2061.6275807683305, 1922.368204440622, 1672.2490374616923, 2065.586606733951, 1908.9466261975929, 2142.7662756069194, 1881.616524017948, 2172.9650309100807, 1910.370795727632, 2012.43790845267, 1744.9632339235195, 1940.7126513069206, 2145.249147592678, 2145.8802719062955, 2196.138923803014, 1986.7157193337498], 'episode_lengths': [116, 247, 115, 168, 123, 105, 181, 264, 57, 344, 239, 476, 94, 140, 266, 171, 216, 282, 59, 148, 132, 201, 212, 58, 213, 69, 95, 275, 196, 196, 247, 114, 399, 157, 97, 111, 205, 182, 205, 177, 127, 161, 79, 197, 181, 116, 110, 91, 202, 148, 270, 152, 195, 155, 86, 158, 98, 157, 290, 248, 132, 259, 196, 176, 299, 139, 225, 252, 133, 346, 432, 140, 140, 167, 162, 298, 218, 249, 267, 500, 221, 173, 205, 96, 99, 162, 266, 133, 196, 170, 287, 151, 81, 116, 209, 93, 116, 157, 234, 193]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6801442187612872, 'mean_inference_ms': 1.08374243574505, 'mean_action_processing_ms': 0.408986676801248, 'mean_env_wait_ms': 1.726033482914541, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009064435958862305, 'StateBufferConnector_ms': 0.006997346878051758, 'ViewRequirementAgentConnector_ms': 0.25406861305236816}, 'num_episodes': 21, 'episode_return_max': 2242.434752213775, 'episode_return_min': 1112.3197397508413, 'episode_return_mean': 2003.8040254429181}, 'env_runner_results': {'episode_reward_max': 2242.434752213775, 'episode_reward_min': 1112.3197397508413, 'episode_reward_mean': 2003.8040254429181, 'episode_len_mean': 186.61, 'episode_media': {}, 'episodes_this_iter': 21, 'episodes_timesteps_total': 18661, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2173.799576516096, 2052.482929494625, 2174.594838811713, 2125.211813130501, 2179.312365781165, 2221.71348014249, 2224.924927380688, 2024.405107688117, 1985.2932966794317, 1890.5980897770953, 1825.1094044372824, 1692.113888318755, 2117.4251881216005, 2133.0073112750547, 1817.1524497857029, 2240.7532743929105, 2045.6561147768423, 1651.7111488016708, 2011.180370201446, 2237.6896869279617, 2012.4056082712466, 1856.7229904112241, 1841.5442133426047, 2075.351989016992, 1757.903176441548, 2098.272998100935, 1920.5023223489227, 1887.988231758556, 2033.4147339016658, 2011.556731892545, 1955.0703119755913, 1819.1599214414844, 1426.1903248343028, 2132.2347943608056, 2242.434752213775, 2030.1026145020628, 1910.2408632156328, 1973.1910511228616, 2110.484624088019, 1845.2873151365943, 1946.288209264045, 2102.422671549187, 2100.575149442737, 2176.991507503346, 1982.2912123551528, 2132.1082916199134, 2141.5212935289683, 2060.8134149630964, 2078.7581122330485, 2028.4117361709184, 2061.1721140606323, 1791.7218432641116, 1807.9295131767337, 2124.0802385870984, 2235.422945960414, 2173.007486372, 1933.8478915962064, 1967.4764686628637, 2149.10162529613, 1929.6346928714395, 1924.6380774578004, 2119.2005956880216, 1985.9705863683669, 2180.2463829404846, 1899.4435924207194, 2199.302289703128, 2025.450351737391, 2187.359723269803, 1948.5067821958287, 2066.60325874736, 1916.5901081183615, 2133.266660742911, 2034.5041171558883, 2183.8494219825575, 1965.8393527640312, 1800.9735730712669, 2194.364426020951, 1820.3431594107149, 1925.8665798215673, 1112.3197397508413, 2042.4449509445526, 2001.388455902209, 2061.664300130091, 2051.9002704667782, 2061.6275807683305, 1922.368204440622, 1672.2490374616923, 2065.586606733951, 1908.9466261975929, 2142.7662756069194, 1881.616524017948, 2172.9650309100807, 1910.370795727632, 2012.43790845267, 1744.9632339235195, 1940.7126513069206, 2145.249147592678, 2145.8802719062955, 2196.138923803014, 1986.7157193337498], 'episode_lengths': [116, 247, 115, 168, 123, 105, 181, 264, 57, 344, 239, 476, 94, 140, 266, 171, 216, 282, 59, 148, 132, 201, 212, 58, 213, 69, 95, 275, 196, 196, 247, 114, 399, 157, 97, 111, 205, 182, 205, 177, 127, 161, 79, 197, 181, 116, 110, 91, 202, 148, 270, 152, 195, 155, 86, 158, 98, 157, 290, 248, 132, 259, 196, 176, 299, 139, 225, 252, 133, 346, 432, 140, 140, 167, 162, 298, 218, 249, 267, 500, 221, 173, 205, 96, 99, 162, 266, 133, 196, 170, 287, 151, 81, 116, 209, 93, 116, 157, 234, 193]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6801442187612872, 'mean_inference_ms': 1.08374243574505, 'mean_action_processing_ms': 0.408986676801248, 'mean_env_wait_ms': 1.726033482914541, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009064435958862305, 'StateBufferConnector_ms': 0.006997346878051758, 'ViewRequirementAgentConnector_ms': 0.25406861305236816}, 'num_episodes': 21, 'episode_return_max': 2242.434752213775, 'episode_return_min': 1112.3197397508413, 'episode_return_mean': 2003.8040254429181}, 'episode_reward_max': 2242.434752213775, 'episode_reward_min': 1112.3197397508413, 'episode_reward_mean': 2003.8040254429181, 'episode_len_mean': 186.61, 'episodes_this_iter': 21, 'episodes_timesteps_total': 18661, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2173.799576516096, 2052.482929494625, 2174.594838811713, 2125.211813130501, 2179.312365781165, 2221.71348014249, 2224.924927380688, 2024.405107688117, 1985.2932966794317, 1890.5980897770953, 1825.1094044372824, 1692.113888318755, 2117.4251881216005, 2133.0073112750547, 1817.1524497857029, 2240.7532743929105, 2045.6561147768423, 1651.7111488016708, 2011.180370201446, 2237.6896869279617, 2012.4056082712466, 1856.7229904112241, 1841.5442133426047, 2075.351989016992, 1757.903176441548, 2098.272998100935, 1920.5023223489227, 1887.988231758556, 2033.4147339016658, 2011.556731892545, 1955.0703119755913, 1819.1599214414844, 1426.1903248343028, 2132.2347943608056, 2242.434752213775, 2030.1026145020628, 1910.2408632156328, 1973.1910511228616, 2110.484624088019, 1845.2873151365943, 1946.288209264045, 2102.422671549187, 2100.575149442737, 2176.991507503346, 1982.2912123551528, 2132.1082916199134, 2141.5212935289683, 2060.8134149630964, 2078.7581122330485, 2028.4117361709184, 2061.1721140606323, 1791.7218432641116, 1807.9295131767337, 2124.0802385870984, 2235.422945960414, 2173.007486372, 1933.8478915962064, 1967.4764686628637, 2149.10162529613, 1929.6346928714395, 1924.6380774578004, 2119.2005956880216, 1985.9705863683669, 2180.2463829404846, 1899.4435924207194, 2199.302289703128, 2025.450351737391, 2187.359723269803, 1948.5067821958287, 2066.60325874736, 1916.5901081183615, 2133.266660742911, 2034.5041171558883, 2183.8494219825575, 1965.8393527640312, 1800.9735730712669, 2194.364426020951, 1820.3431594107149, 1925.8665798215673, 1112.3197397508413, 2042.4449509445526, 2001.388455902209, 2061.664300130091, 2051.9002704667782, 2061.6275807683305, 1922.368204440622, 1672.2490374616923, 2065.586606733951, 1908.9466261975929, 2142.7662756069194, 1881.616524017948, 2172.9650309100807, 1910.370795727632, 2012.43790845267, 1744.9632339235195, 1940.7126513069206, 2145.249147592678, 2145.8802719062955, 2196.138923803014, 1986.7157193337498], 'episode_lengths': [116, 247, 115, 168, 123, 105, 181, 264, 57, 344, 239, 476, 94, 140, 266, 171, 216, 282, 59, 148, 132, 201, 212, 58, 213, 69, 95, 275, 196, 196, 247, 114, 399, 157, 97, 111, 205, 182, 205, 177, 127, 161, 79, 197, 181, 116, 110, 91, 202, 148, 270, 152, 195, 155, 86, 158, 98, 157, 290, 248, 132, 259, 196, 176, 299, 139, 225, 252, 133, 346, 432, 140, 140, 167, 162, 298, 218, 249, 267, 500, 221, 173, 205, 96, 99, 162, 266, 133, 196, 170, 287, 151, 81, 116, 209, 93, 116, 157, 234, 193]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.6801442187612872, 'mean_inference_ms': 1.08374243574505, 'mean_action_processing_ms': 0.408986676801248, 'mean_env_wait_ms': 1.726033482914541, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009064435958862305, 'StateBufferConnector_ms': 0.006997346878051758, 'ViewRequirementAgentConnector_ms': 0.25406861305236816}, 'num_episodes': 21, 'episode_return_max': 2242.434752213775, 'episode_return_min': 1112.3197397508413, 'episode_return_mean': 2003.8040254429181, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 737280, 'num_agent_steps_trained': 737280, 'num_env_steps_sampled': 184320, 'num_env_steps_trained': 184320, 'num_env_steps_sampled_this_iter': 4096, 'num_env_steps_trained_this_iter': 4096, 'num_env_steps_sampled_throughput_per_sec': 168.30398415399065, 'num_env_steps_trained_throughput_per_sec': 168.30398415399065, 'timesteps_total': 184320, 'num_env_steps_sampled_lifetime': 184320, 'num_agent_steps_sampled_lifetime': 737280, 'num_steps_trained_this_iter': 4096, 'agent_timesteps_total': 737280, 'timers': {'training_iteration_time_ms': 24142.18, 'restore_workers_time_ms': 0.017, 'training_step_time_ms': 24142.138, 'sample_time_ms': 15788.238, 'load_time_ms': 1.942, 'load_throughput': 2108839.17, 'learn_time_ms': 8347.792, 'learn_throughput': 490.669, 'synch_weights_time_ms': 3.575}, 'counters': {'num_env_steps_sampled': 184320, 'num_env_steps_trained': 184320, 'num_agent_steps_sampled': 737280, 'num_agent_steps_trained': 737280}, 'done': False, 'episodes_total': 686, 'training_iteration': 45, 'trial_id': 'default', 'date': '2024-06-04_15-33-06', 'timestamp': 1717507986, 'time_this_iter_s': 24.34232783317566, 'time_total_s': 1112.879643201828, 'pid': 8421, 'hostname': 'LAPTOP-9AD2MD1C', 'node_ip': '172.23.85.106', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.95, 'lr': 0.001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4096, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f2aff722a20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 512, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 1112.879643201828, 'iterations_since_restore': 45, 'perf': {'cpu_util_percent': 32.62619047619048, 'ram_util_percent': 82.67619047619048}})'.\n"
     ]
    }
   ],
   "source": [
    "save_algo(algo, \"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sac_result_format(result):\n",
    "    return (f\"iteration [{result['training_iteration']}] => \" +\n",
    "          f\"episode_reward_mean: {result['sampler_results']['episode_reward_mean']}, \" +\n",
    "          f\"episode_len_mean: {result['sampler_results']['episode_len_mean']},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "env_config = EnvironmentConfiguration(\n",
    "    n_agents = 4,\n",
    "    n_targets = 5,\n",
    "    spawn_area = 100,\n",
    "    max_steps=500,\n",
    "    agent_range = 5,\n",
    "    visible_nbrs = 3,\n",
    "    visible_targets = 3,\n",
    "    cache_size=3)\n",
    "register_env(\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3&algo=SAC\", lambda _: KeepTheDistance(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [1] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "iteration [2] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "iteration [3] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "iteration [4] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "iteration [5] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "iteration [6] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "iteration [7] => episode_reward_mean: nan, episode_len_mean: nan,\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce9a9e438d04ebd9885ad4341e1fabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  {'agent-0': -0.37125787705644875, 'agent-1': -0.6509044995206992, 'agent-2': -0.37678962599022015, 'agent-3': 0.3429164028943781} \n",
      "\n",
      "reward:  {'agent-0': -0.7199175033327307, 'agent-1': -1.5805867236093292, 'agent-2': 0.9454777416586921, 'agent-3': -0.9148120038577545} \n",
      "\n",
      "reward:  {'agent-0': 0.9670014368996078, 'agent-1': -0.11889369208107325, 'agent-2': -0.2008486968326011, 'agent-3': -0.4244301191596058} \n",
      "\n",
      "reward:  {'agent-0': -0.6984928982196621, 'agent-1': 0.01299278479623922, 'agent-2': 0.5198705169391857, 'agent-3': -0.4866003885398982} \n",
      "\n",
      "reward:  {'agent-0': -0.4122201317086063, 'agent-1': -0.8225813022921216, 'agent-2': -0.38378828741863913, 'agent-3': -0.3033477246721503} \n",
      "\n",
      "reward:  {'agent-0': 0.6808888880032207, 'agent-1': -1.9737329703396398, 'agent-2': -0.32261339276276146, 'agent-3': -0.10796925165293914} \n",
      "\n",
      "reward:  {'agent-0': -0.5949797133552046, 'agent-1': -0.9525098642930203, 'agent-2': -1.0852949699878778, 'agent-3': -0.49349787371451015} \n",
      "\n",
      "reward:  {'agent-0': 1.560051186181198, 'agent-1': -0.983947007873752, 'agent-2': -0.6796541570341006, 'agent-3': 0.0008747220855553905} \n",
      "\n",
      "reward:  {'agent-0': 0.30353848926090343, 'agent-1': -1.0914065292093937, 'agent-2': -0.5634947198120699, 'agent-3': 0.3158862628158374} \n",
      "\n",
      "reward:  {'agent-0': 0.3809273527114243, 'agent-1': 0.2394467906981248, 'agent-2': 0.6323811220815756, 'agent-3': -0.6168494624255842} \n",
      "\n",
      "reward:  {'agent-0': -0.2427257513876171, 'agent-1': -0.9135864937875624, 'agent-2': -0.5928159977936573, 'agent-3': -0.7059570916243771} \n",
      "\n",
      "reward:  {'agent-0': 0.9608151173170754, 'agent-1': -0.12726860818202113, 'agent-2': 0.3161889754212197, 'agent-3': -0.493887931373429} \n",
      "\n",
      "reward:  {'agent-0': -0.44524439345518374, 'agent-1': 1.2641533722695044, 'agent-2': 1.4706872705872485, 'agent-3': 0.3883793275805374} \n",
      "\n",
      "reward:  {'agent-0': -0.919788288750965, 'agent-1': -0.9403632427759874, 'agent-2': 0.6489096016335125, 'agent-3': 0.1863001046676871} \n",
      "\n",
      "reward:  {'agent-0': -0.9155124647846051, 'agent-1': -0.9175044126313381, 'agent-2': -1.0087056118925304, 'agent-3': 0.5122685085423271} \n",
      "\n",
      "reward:  {'agent-0': -0.25060232269881055, 'agent-1': -1.8991790146785803, 'agent-2': -0.6053308632637382, 'agent-3': -0.6787513264430558} \n",
      "\n",
      "reward:  {'agent-0': 0.5635486069625806, 'agent-1': 0.6418016517069276, 'agent-2': -0.730231036856793, 'agent-3': -0.0035424417100529126} \n",
      "\n",
      "reward:  {'agent-0': -0.5379362983472689, 'agent-1': 1.1813578671816174, 'agent-2': 0.9017029974683552, 'agent-3': -0.8058121720993299} \n",
      "\n",
      "reward:  {'agent-0': -0.39912949913532003, 'agent-1': -1.0310608375436061, 'agent-2': -1.3445350913814167, 'agent-3': -0.4918129353273599} \n",
      "\n",
      "reward:  {'agent-0': 0.9429327064395885, 'agent-1': -0.634111845714088, 'agent-2': -0.9813455817863215, 'agent-3': -0.4370025735354055} \n",
      "\n",
      "reward:  {'agent-0': 1.29752749649046, 'agent-1': -1.4209352845991674, 'agent-2': -1.0795697110733684, 'agent-3': -1.3057750000566628} \n",
      "\n",
      "reward:  {'agent-0': -0.9360657239178884, 'agent-1': -0.8588389144831154, 'agent-2': -0.8293330041482392, 'agent-3': -0.10389826662711954} \n",
      "\n",
      "reward:  {'agent-0': -0.5218840367699222, 'agent-1': -0.6701132468326705, 'agent-2': -0.7992226583719528, 'agent-3': -0.6661814613883763} \n",
      "\n",
      "reward:  {'agent-0': 0.6417682659987562, 'agent-1': -2.1187957861050677, 'agent-2': -0.36978518693463514, 'agent-3': -0.838751799092968} \n",
      "\n",
      "reward:  {'agent-0': -0.40596267718895973, 'agent-1': -0.6099548204729714, 'agent-2': -1.0124418662394845, 'agent-3': -0.8874163631456362} \n",
      "\n",
      "reward:  {'agent-0': 1.3583544044825278, 'agent-1': -0.8490326945339035, 'agent-2': 0.687595975608815, 'agent-3': -1.3994070583551803} \n",
      "\n",
      "reward:  {'agent-0': 0.13954315714172338, 'agent-1': -1.3635780424209543, 'agent-2': 0.1999374231855242, 'agent-3': -1.0076600451228117} \n",
      "\n",
      "reward:  {'agent-0': -0.7588517536736319, 'agent-1': -0.2110062792559262, 'agent-2': -1.029572998900278, 'agent-3': 0.33543509564011487} \n",
      "\n",
      "reward:  {'agent-0': 0.7505550183759908, 'agent-1': 0.03452428834462751, 'agent-2': -0.5071592241471734, 'agent-3': 1.44160782155474} \n",
      "\n",
      "reward:  {'agent-0': 1.1885263097748222, 'agent-1': -1.1601751561337608, 'agent-2': -0.1081594655880167, 'agent-3': 0.38716156173819627} \n",
      "\n",
      "reward:  {'agent-0': -0.43182560502293654, 'agent-1': -1.4352695612871784, 'agent-2': -0.04202255948204936, 'agent-3': -0.6414586735200061} \n",
      "\n",
      "reward:  {'agent-0': 0.32654297016989275, 'agent-1': -0.858558421741634, 'agent-2': 0.45484595501077507, 'agent-3': -0.977912003748397} \n",
      "\n",
      "reward:  {'agent-0': -0.18976077473596575, 'agent-1': -0.5602846125722039, 'agent-2': -0.9931890191858201, 'agent-3': -0.15177318789380223} \n",
      "\n",
      "reward:  {'agent-0': -0.37088484321087023, 'agent-1': -0.26124327566787997, 'agent-2': 0.09175548453155358, 'agent-3': -0.5206363486073222} \n",
      "\n",
      "reward:  {'agent-0': -0.2983065474026354, 'agent-1': -0.9294460114693663, 'agent-2': 0.16986650329907604, 'agent-3': 0.15458735522512157} \n",
      "\n",
      "reward:  {'agent-0': 1.2450347402195057, 'agent-1': -0.37885457281949186, 'agent-2': -2.213616863110701, 'agent-3': -2.872112946047377} \n",
      "\n",
      "reward:  {'agent-0': -0.7052683573505618, 'agent-1': -0.9984448193682596, 'agent-2': -0.8952658482322704, 'agent-3': -0.8882476744197163} \n",
      "\n",
      "reward:  {'agent-0': -0.26649863944293983, 'agent-1': -0.6050673289020452, 'agent-2': -1.4515047593758368, 'agent-3': -3.115597645044975} \n",
      "\n",
      "reward:  {'agent-0': 0.2573917204770808, 'agent-1': -0.8565454566386563, 'agent-2': -2.486751430413605, 'agent-3': -0.6512442649348458} \n",
      "\n",
      "reward:  {'agent-0': 0.6357563893510676, 'agent-1': -0.8514017305749064, 'agent-2': -0.007522665120006877, 'agent-3': -0.744295048554406} \n",
      "\n",
      "reward:  {'agent-0': -0.17888233405260223, 'agent-1': -0.9093591054935075, 'agent-2': -1.7435584661779302, 'agent-3': -3.056895539109668} \n",
      "\n",
      "reward:  {'agent-0': 0.156439477320653, 'agent-1': -1.8819377099814716, 'agent-2': -3.080470767369569, 'agent-3': -2.0451451482818896} \n",
      "\n",
      "reward:  {'agent-0': -0.7606457080290561, 'agent-1': -0.8685909573075676, 'agent-2': -2.9007730939431937, 'agent-3': -2.3354756709732314} \n",
      "\n",
      "reward:  {'agent-0': -0.8404754726161556, 'agent-1': -0.46900710018520897, 'agent-2': -0.7074111739627327, 'agent-3': 0.5786532273269813} \n",
      "\n",
      "reward:  {'agent-0': 0.07750348969802445, 'agent-1': 1.9649826809638, 'agent-2': -1.5662695343156514, 'agent-3': -2.7206418511470574} \n",
      "\n",
      "reward:  {'agent-0': -0.40388000385756584, 'agent-1': -0.820258590298522, 'agent-2': -0.8291981966637039, 'agent-3': 0.7373045155248619} \n",
      "\n",
      "reward:  {'agent-0': -0.7076019238016116, 'agent-1': -1.1760119366704913, 'agent-2': -0.6993902422119689, 'agent-3': 0.09780746171767873} \n",
      "\n",
      "reward:  {'agent-0': -0.7538864283494604, 'agent-1': 0.1129938461876776, 'agent-2': -0.8017341957557136, 'agent-3': -0.24312832601995638} \n",
      "\n",
      "reward:  {'agent-0': -0.6635788259449704, 'agent-1': -0.37609808594858407, 'agent-2': -0.52151893050101, 'agent-3': -3.2718266524876896} \n",
      "\n",
      "reward:  {'agent-0': -0.1540349106872796, 'agent-1': -1.900715243780951, 'agent-2': -1.9505996792471834, 'agent-3': -1.654614381428832} \n",
      "\n",
      "reward:  {'agent-0': -0.8649860131820191, 'agent-1': -1.0112402716407303, 'agent-2': -2.8065574425946522, 'agent-3': -3.5812509643128365} \n",
      "\n",
      "reward:  {'agent-0': 1.2840745801543072, 'agent-1': -0.17693499657698908, 'agent-2': -2.6332589905108605, 'agent-3': -2.7726195717939106} \n",
      "\n",
      "reward:  {'agent-0': 1.9058995289998535, 'agent-1': -0.27838177100831274, 'agent-2': -3.149029950456878, 'agent-3': -0.27412053377761936} \n",
      "\n",
      "reward:  {'agent-0': -0.016638133874597116, 'agent-1': -0.9013348488471848, 'agent-2': -2.7388370803344557, 'agent-3': -2.85558762822037} \n",
      "\n",
      "reward:  {'agent-0': -0.6837812557389036, 'agent-1': -0.4021229397527506, 'agent-2': -2.0325847989599666, 'agent-3': -0.7616895481691373} \n",
      "\n",
      "reward:  {'agent-0': 0.8701750859699189, 'agent-1': -1.4006438072752445, 'agent-2': -2.8899841981961814, 'agent-3': -1.7287529250725626} \n",
      "\n",
      "reward:  {'agent-0': 1.08533295369039, 'agent-1': 0.048662010507300124, 'agent-2': 0.5153222220754401, 'agent-3': 0.800924752655277} \n",
      "\n",
      "reward:  {'agent-0': 0.6862330177284335, 'agent-1': -0.6405218192418403, 'agent-2': -0.2543170808351505, 'agent-3': -0.9800086447415381} \n",
      "\n",
      "reward:  {'agent-0': -0.6123957716896982, 'agent-1': -1.060124309835352, 'agent-2': -0.6826120055830174, 'agent-3': -0.9428475145218513} \n",
      "\n",
      "reward:  {'agent-0': 0.8113845372300332, 'agent-1': -1.2121808040925757, 'agent-2': -2.005237217359806, 'agent-3': -0.699233909595911} \n",
      "\n",
      "reward:  {'agent-0': 1.0548011620210396, 'agent-1': -0.7942273418354517, 'agent-2': -0.369022798374651, 'agent-3': 0.8723281735456894} \n",
      "\n",
      "reward:  {'agent-0': -0.9853613356253064, 'agent-1': -0.8586701849129597, 'agent-2': -0.3806093754672375, 'agent-3': -0.2488933748052773} \n",
      "\n",
      "reward:  {'agent-0': -0.8611906357165786, 'agent-1': -0.6803334565922725, 'agent-2': -1.0653536781501316, 'agent-3': 0.1724765859183286} \n",
      "\n",
      "reward:  {'agent-0': 0.8752490048131634, 'agent-1': -0.8205570343961597, 'agent-2': 0.5277718985998021, 'agent-3': -0.18678330602421056} \n",
      "\n",
      "reward:  {'agent-0': -1.0010549651443306, 'agent-1': -0.5442331957712128, 'agent-2': 0.010376688663086497, 'agent-3': 1.081321790064841} \n",
      "\n",
      "reward:  {'agent-0': -0.29979973608909205, 'agent-1': -0.0020840572174378735, 'agent-2': -0.7644341348523014, 'agent-3': -1.220421037460099} \n",
      "\n",
      "reward:  {'agent-0': -0.9920783795588655, 'agent-1': -0.18176600274898647, 'agent-2': -0.29692295654772494, 'agent-3': 1.832843147407793} \n",
      "\n",
      "reward:  {'agent-0': 0.5054082185871529, 'agent-1': -0.25199261080655333, 'agent-2': -1.0054242153334059, 'agent-3': -0.5326599700274102} \n",
      "\n",
      "reward:  {'agent-0': 0.9348988185985441, 'agent-1': -0.9392526684816147, 'agent-2': 0.6799248855705997, 'agent-3': -0.7320070774779026} \n",
      "\n",
      "reward:  {'agent-0': -0.3473603188548289, 'agent-1': -0.9098825108509203, 'agent-2': -0.9441618250785169, 'agent-3': -1.1358332882745898} \n",
      "\n",
      "reward:  {'agent-0': -0.21856764586691213, 'agent-1': -0.03231420890822534, 'agent-2': -0.7830148901723177, 'agent-3': 0.9782183212307558} \n",
      "\n",
      "reward:  {'agent-0': 0.08484154240209207, 'agent-1': 1.166917818905766, 'agent-2': -0.356428641818745, 'agent-3': -0.9454163211893061} \n",
      "\n",
      "reward:  {'agent-0': -0.14012948116786106, 'agent-1': 0.1105727289862557, 'agent-2': -0.9795951877504621, 'agent-3': -0.9352530775111774} \n",
      "\n",
      "reward:  {'agent-0': -0.2595029008573846, 'agent-1': -1.834543038514802, 'agent-2': -0.9394554005930971, 'agent-3': -0.6207323262833313} \n",
      "\n",
      "reward:  {'agent-0': -0.921307253905006, 'agent-1': -0.2739091647850742, 'agent-2': -0.9792137335073576, 'agent-3': -0.07615782727464193} \n",
      "\n",
      "reward:  {'agent-0': -0.8327206653413946, 'agent-1': 0.728356690946157, 'agent-2': -1.042406756878023, 'agent-3': -0.1393638570917659} \n",
      "\n",
      "reward:  {'agent-0': -0.040308219579724636, 'agent-1': -0.5900728916068516, 'agent-2': -0.6504460801505019, 'agent-3': 0.9450488188273809} \n",
      "\n",
      "reward:  {'agent-0': -0.9230389917163215, 'agent-1': -1.3703392022881502, 'agent-2': -0.32922005538942045, 'agent-3': 0.3871453228282462} \n",
      "\n",
      "reward:  {'agent-0': 0.49571274852252145, 'agent-1': 1.0568322678045803, 'agent-2': 0.9302545786749761, 'agent-3': 1.1123298538529056} \n",
      "\n",
      "reward:  {'agent-0': -0.8161988623068126, 'agent-1': -1.153436413397884, 'agent-2': 0.18114422155653642, 'agent-3': -0.6723167205323648} \n",
      "\n",
      "reward:  {'agent-0': 1.134607531128804, 'agent-1': -0.8873982344278986, 'agent-2': -1.1613582290433513, 'agent-3': -1.0957324495952676} \n",
      "\n",
      "reward:  {'agent-0': 0.6602946253694597, 'agent-1': 1.4400488858132832, 'agent-2': -0.14943697288570945, 'agent-3': 0.15296368270532668} \n",
      "\n",
      "reward:  {'agent-0': -0.2006872702012963, 'agent-1': 0.00452269262545002, 'agent-2': -0.21280153060561702, 'agent-3': -0.6978042005666865} \n",
      "\n",
      "reward:  {'agent-0': 0.11022619004844358, 'agent-1': -0.9367303361533317, 'agent-2': 0.7616789388471261, 'agent-3': -0.6008070175356153} \n",
      "\n",
      "reward:  {'agent-0': 1.4184912147551785, 'agent-1': 0.2929599624644652, 'agent-2': 1.4460262560646129, 'agent-3': -0.9670268841459944} \n",
      "\n",
      "reward:  {'agent-0': -0.48713758662925954, 'agent-1': -2.398457132332652, 'agent-2': 0.3259616726511112, 'agent-3': 1.305114215155001} \n",
      "\n",
      "reward:  {'agent-0': 0.5285983562772216, 'agent-1': -0.39792280816645587, 'agent-2': -0.46976260167492967, 'agent-3': -0.9028552264606446} \n",
      "\n",
      "reward:  {'agent-0': -0.6390416957048046, 'agent-1': -1.5521215500292556, 'agent-2': -0.6734864909684646, 'agent-3': -0.8695373238192303} \n",
      "\n",
      "reward:  {'agent-0': -0.508980342007078, 'agent-1': -0.20179510585668936, 'agent-2': 0.5839215005095042, 'agent-3': -1.0300898690543576} \n",
      "\n",
      "reward:  {'agent-0': -0.2573627702270933, 'agent-1': -1.0069206871494387, 'agent-2': -0.7239291430851296, 'agent-3': -0.9088798560227538} \n",
      "\n",
      "reward:  {'agent-0': 0.5957315241026038, 'agent-1': -0.19736456286404547, 'agent-2': -0.6841341476442651, 'agent-3': 0.0390800784406693} \n",
      "\n",
      "reward:  {'agent-0': 0.31111409750054975, 'agent-1': -1.0836986391877872, 'agent-2': 1.061461092801224, 'agent-3': 1.102990166867336} \n",
      "\n",
      "reward:  {'agent-0': 1.7250639833687416, 'agent-1': 0.3415452300853872, 'agent-2': -0.8711895897312232, 'agent-3': -0.7501739830831227} \n",
      "\n",
      "reward:  {'agent-0': -0.9256804530643521, 'agent-1': -2.6019363059294562, 'agent-2': -0.8772568514746055, 'agent-3': -0.6255128234868224} \n",
      "\n",
      "reward:  {'agent-0': 1.0463244925896582, 'agent-1': -1.3547340627784195, 'agent-2': 0.4712135530727153, 'agent-3': -0.9690122149573277} \n",
      "\n",
      "reward:  {'agent-0': -0.9611426076350504, 'agent-1': -2.638475240926418, 'agent-2': 0.12528014754358452, 'agent-3': -0.8458831632984634} \n",
      "\n",
      "reward:  {'agent-0': -0.7382347130801605, 'agent-1': -0.3150329258513409, 'agent-2': -0.6346293438206843, 'agent-3': -0.7513002676192428} \n",
      "\n",
      "reward:  {'agent-0': -0.8080861507314339, 'agent-1': -0.21324835391357055, 'agent-2': 0.32139720875668587, 'agent-3': 0.9544105538988248} \n",
      "\n",
      "reward:  {'agent-0': 0.2041549467836603, 'agent-1': -0.7803095611385871, 'agent-2': -0.9870783282165476, 'agent-3': -0.4581928689252237} \n",
      "\n",
      "reward:  {'agent-0': -0.29519543151644356, 'agent-1': 1.347764361664396, 'agent-2': 0.5356262185175851, 'agent-3': -0.47309435412486067} \n",
      "\n",
      "reward:  {'agent-0': -0.6530086645929174, 'agent-1': 0.511762639336709, 'agent-2': -0.6381742423582324, 'agent-3': 0.24867666323051552} \n",
      "\n",
      "reward:  {'agent-0': -0.40786646989058895, 'agent-1': -1.2380466547271567, 'agent-2': -0.7596072389091972, 'agent-3': 0.827627994331678} \n",
      "\n",
      "reward:  {'agent-0': -0.9591280821677444, 'agent-1': -1.8021981654276829, 'agent-2': -0.6801221130043942, 'agent-3': 0.5790073111216074} \n",
      "\n",
      "reward:  {'agent-0': 1.5492763070636109, 'agent-1': -1.2627741496311415, 'agent-2': -0.4202028173693577, 'agent-3': 0.360578792777865} \n",
      "\n",
      "reward:  {'agent-0': 1.1880776759085414, 'agent-1': -0.10334228529902845, 'agent-2': 0.7079999604775224, 'agent-3': 0.16115667260814703} \n",
      "\n",
      "reward:  {'agent-0': -0.5869992011681582, 'agent-1': -1.5095675540701237, 'agent-2': -0.8391966584746626, 'agent-3': -0.3246285786297918} \n",
      "\n",
      "reward:  {'agent-0': -0.5688421077093935, 'agent-1': -1.1463780456284098, 'agent-2': -0.3642236537265049, 'agent-3': -0.8405480464248782} \n",
      "\n",
      "reward:  {'agent-0': 0.95707471785758, 'agent-1': -1.29911980423784, 'agent-2': 0.9391803090361961, 'agent-3': -0.319429262413081} \n",
      "\n",
      "reward:  {'agent-0': -0.9042464692996255, 'agent-1': -0.12130348983512107, 'agent-2': 0.5265426986996857, 'agent-3': -0.08641945067275714} \n",
      "\n",
      "reward:  {'agent-0': -0.41364733350953387, 'agent-1': -2.001426597988825, 'agent-2': -1.15966832181401, 'agent-3': -0.8821845647172424} \n",
      "\n",
      "reward:  {'agent-0': -0.7010221065022364, 'agent-1': -1.930230018026478, 'agent-2': -0.08237634840972419, 'agent-3': -0.013053091206906231} \n",
      "\n",
      "reward:  {'agent-0': 1.4088373106877405, 'agent-1': -0.8236944594069797, 'agent-2': -0.6120973096386564, 'agent-3': -0.9962891695126501} \n",
      "\n",
      "reward:  {'agent-0': 0.28033210120224794, 'agent-1': 0.5524569977329463, 'agent-2': -0.4608049822960325, 'agent-3': -0.36098926493787786} \n",
      "\n",
      "reward:  {'agent-0': 0.12350825434863211, 'agent-1': 1.0960303040562707, 'agent-2': -0.7623332317964682, 'agent-3': -1.0348158468761781} \n",
      "\n",
      "reward:  {'agent-0': 0.19873682692905348, 'agent-1': 0.49612518080856205, 'agent-2': -0.13396769697926914, 'agent-3': -0.8732668417454725} \n",
      "\n",
      "reward:  {'agent-0': -0.3043265198790941, 'agent-1': 1.2584703786338878, 'agent-2': -0.9891401473115025, 'agent-3': -1.5129751742207205} \n",
      "\n",
      "reward:  {'agent-0': -0.28462085130919945, 'agent-1': -0.6975291941588324, 'agent-2': -0.8047542676991739, 'agent-3': -0.33869978347296126} \n",
      "\n",
      "reward:  {'agent-0': -0.87821781964794, 'agent-1': -0.16240319783087642, 'agent-2': -0.6527308040043422, 'agent-3': -0.6707372972563377} \n",
      "\n",
      "reward:  {'agent-0': -0.5132097114822933, 'agent-1': -1.1655755102740812, 'agent-2': 0.5846273656455097, 'agent-3': -0.6879206620051193} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-25 16:18:07,387 E 12970 12970] (raylet) node_manager.cc:3002: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 413823ac1dda67202cb4eab37405d145aede4dadbb9f5687d053051d, IP: 172.22.119.52) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.22.119.52`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  {'agent-0': -0.6611753791131534, 'agent-1': -0.7252976860110039, 'agent-2': -0.29096860264978375, 'agent-3': 0.38193176413039964} \n",
      "\n",
      "reward:  {'agent-0': 0.39431517976832, 'agent-1': -1.31286697545535, 'agent-2': -0.7355794512963598, 'agent-3': -0.550531057244136} \n",
      "\n",
      "reward:  {'agent-0': -0.8172234115523302, 'agent-1': -0.9481728237373588, 'agent-2': -0.32235226170514153, 'agent-3': 0.6551931352581306} \n",
      "\n",
      "reward:  {'agent-0': -0.020276364574890238, 'agent-1': 0.9810277732841968, 'agent-2': -0.8492497142975779, 'agent-3': -1.2911299528347158} \n",
      "\n",
      "reward:  {'agent-0': -0.8487014095163303, 'agent-1': -0.5968470348959158, 'agent-2': -0.5209779189954133, 'agent-3': 0.08966482242551521} \n",
      "\n",
      "reward:  {'agent-0': -0.8626227722176907, 'agent-1': -1.3429256475484266, 'agent-2': -0.6759373725045208, 'agent-3': -0.2949662136358526} \n",
      "\n",
      "reward:  {'agent-0': -0.71127286985406, 'agent-1': -0.39075829490528946, 'agent-2': -0.15626417099606726, 'agent-3': -0.4126635712656537} \n",
      "\n",
      "reward:  {'agent-0': -0.8103701047174781, 'agent-1': -0.12363680316450854, 'agent-2': -0.6949597048061094, 'agent-3': -0.025070195293164232} \n",
      "\n",
      "reward:  {'agent-0': -0.8834256577629525, 'agent-1': 1.509577168213923, 'agent-2': -0.2172963338576679, 'agent-3': -0.477118795538356} \n",
      "\n",
      "reward:  {'agent-0': 0.44945301322998077, 'agent-1': -0.788167238888164, 'agent-2': 0.07198495989734255, 'agent-3': 0.30348280415199014} \n",
      "\n",
      "reward:  {'agent-0': -0.5499463250113266, 'agent-1': -0.892578561933334, 'agent-2': -0.905816030210616, 'agent-3': -0.9711295388795236} \n",
      "\n",
      "reward:  {'agent-0': -0.8041949452240225, 'agent-1': 1.3533760775968062, 'agent-2': -0.8654917965815656, 'agent-3': -0.30810062248905723} \n",
      "\n",
      "reward:  {'agent-0': -0.1616955067343362, 'agent-1': 0.2125831897507311, 'agent-2': -0.20643210947248036, 'agent-3': -0.3381376433196017} \n",
      "\n",
      "reward:  {'agent-0': 0.1141923965190017, 'agent-1': -0.9972367960176385, 'agent-2': -0.6985410091911248, 'agent-3': 0.7695077939066763} \n",
      "\n",
      "reward:  {'agent-0': -0.5616009563091708, 'agent-1': 0.8487460836484502, 'agent-2': 0.42978379827727764, 'agent-3': 0.24247572405653628} \n",
      "\n",
      "reward:  {'agent-0': -0.5353914817079115, 'agent-1': -0.21776664675147117, 'agent-2': -0.9590634297439777, 'agent-3': 0.5960885793076542} \n",
      "\n",
      "reward:  {'agent-0': -0.8394033907279628, 'agent-1': -0.6626729502030742, 'agent-2': -0.6591249483891488, 'agent-3': 0.4286467695393732} \n",
      "\n",
      "reward:  {'agent-0': -0.09825056461423642, 'agent-1': -2.0186418922858707, 'agent-2': 1.1253514108426188, 'agent-3': -0.2676153611863583} \n",
      "\n",
      "reward:  {'agent-0': 0.2610074896965706, 'agent-1': -1.3024718509644515, 'agent-2': -0.9674913212562046, 'agent-3': -1.296476200868593} \n",
      "\n",
      "reward:  {'agent-0': -0.433149664696316, 'agent-1': -0.8836284539783463, 'agent-2': -0.23459057158883923, 'agent-3': 0.6237491822606245} \n",
      "\n",
      "reward:  {'agent-0': 0.7853352287652982, 'agent-1': -0.7054675169861611, 'agent-2': -1.1014962020243075, 'agent-3': 0.5656901380941122} \n",
      "\n",
      "reward:  {'agent-0': -0.9308571230769189, 'agent-1': 0.4356661596645779, 'agent-2': -1.448343785719885, 'agent-3': 1.0123553657658562} \n",
      "\n",
      "reward:  {'agent-0': -0.9784273515108026, 'agent-1': -1.0402495118295079, 'agent-2': -0.04505312265046513, 'agent-3': -0.7365468417584431} \n",
      "\n",
      "reward:  {'agent-0': 1.3507782623469353, 'agent-1': -1.068296542596748, 'agent-2': 1.00176631465758, 'agent-3': -0.1573281018400472} \n",
      "\n",
      "reward:  {'agent-0': -0.3335283014662913, 'agent-1': -0.9598788483519627, 'agent-2': -0.8107062396416822, 'agent-3': 0.855713729322499} \n",
      "\n",
      "reward:  {'agent-0': -0.6519159196962896, 'agent-1': 0.9023892055266245, 'agent-2': -0.29390583070309617, 'agent-3': -1.007118431618558} \n",
      "\n",
      "reward:  {'agent-0': 0.010513855861987054, 'agent-1': 0.06286751165538362, 'agent-2': -1.079615464821572, 'agent-3': -0.49000568448899173} \n",
      "\n",
      "reward:  {'agent-0': -0.9299953803035343, 'agent-1': -1.050650340225424, 'agent-2': -0.9018139536748251, 'agent-3': -1.0271804974646983} \n",
      "\n",
      "reward:  {'agent-0': -0.37041041279188747, 'agent-1': 0.7080178099999159, 'agent-2': 0.8518206342799033, 'agent-3': -0.9870345144866448} \n",
      "\n",
      "reward:  {'agent-0': -0.13352253640900713, 'agent-1': -0.045138927814249996, 'agent-2': -0.4371430817308948, 'agent-3': 0.4748017020832478} \n",
      "\n",
      "reward:  {'agent-0': 0.2484280978235489, 'agent-1': 0.542315160168819, 'agent-2': 0.19484825088665048, 'agent-3': -0.902441048007212} \n",
      "\n",
      "reward:  {'agent-0': -0.18224213664831268, 'agent-1': -1.4410560004788735, 'agent-2': -0.42616837844812494, 'agent-3': -1.1978999479879349} \n",
      "\n",
      "reward:  {'agent-0': -0.14580154994425243, 'agent-1': -1.0048096400831952, 'agent-2': -0.6483387764056445, 'agent-3': -1.1797688282837413} \n",
      "\n",
      "reward:  {'agent-0': -0.2837909417617688, 'agent-1': -1.245051623065919, 'agent-2': 0.5261887809437411, 'agent-3': -0.9167549208547712} \n",
      "\n",
      "reward:  {'agent-0': -0.5433593867977464, 'agent-1': 0.49943302735418627, 'agent-2': -0.28370620786022016, 'agent-3': 0.2825829821170558} \n",
      "\n",
      "reward:  {'agent-0': 0.5581671948264812, 'agent-1': -1.078118910856574, 'agent-2': -0.5993927255545515, 'agent-3': 1.1485568163962796} \n",
      "\n",
      "reward:  {'agent-0': 0.9897025991530768, 'agent-1': -0.7491005909163562, 'agent-2': -0.0014346731576750926, 'agent-3': 0.967997017990605} \n",
      "\n",
      "reward:  {'agent-0': -0.8835001860130944, 'agent-1': -0.019797218791552496, 'agent-2': 0.7843163006650045, 'agent-3': -1.090369700859167} \n",
      "\n",
      "reward:  {'agent-0': 1.9642457338635708, 'agent-1': -0.9090779224478922, 'agent-2': -0.7851588776861362, 'agent-3': -1.063974404952802} \n",
      "\n",
      "reward:  {'agent-0': 0.3199451737942951, 'agent-1': -2.0127900106776764, 'agent-2': 0.19301953527106264, 'agent-3': -0.5333829408824116} \n",
      "\n",
      "reward:  {'agent-0': -0.926109701398893, 'agent-1': -0.5895182882402707, 'agent-2': 0.32896441028385937, 'agent-3': -0.6083311818178956} \n",
      "\n",
      "reward:  {'agent-0': -0.9778340032926387, 'agent-1': 2.0938313398422324, 'agent-2': 0.2916495172584632, 'agent-3': -1.0919238773634703} \n",
      "\n",
      "reward:  {'agent-0': 0.16797357619918785, 'agent-1': -1.2979161885705253, 'agent-2': -0.9702155090012212, 'agent-3': -0.8640596986470328} \n",
      "\n",
      "reward:  {'agent-0': -0.7442807597888432, 'agent-1': -1.3027388685769523, 'agent-2': -1.228459594666198, 'agent-3': 0.723934639456715} \n",
      "\n",
      "reward:  {'agent-0': 1.0454926404931726, 'agent-1': 0.20467842550715432, 'agent-2': -0.9389708180129119, 'agent-3': -0.7326567768703747} \n",
      "\n",
      "reward:  {'agent-0': 1.1195856041959402, 'agent-1': 0.9611056733540124, 'agent-2': 0.27376293830901943, 'agent-3': -0.926815385551393} \n",
      "\n",
      "reward:  {'agent-0': -0.7568915740552242, 'agent-1': -0.982699046049035, 'agent-2': -1.2191640354643596, 'agent-3': -0.4954804368671546} \n",
      "\n",
      "reward:  {'agent-0': -0.6716202719796591, 'agent-1': 0.29015731572136616, 'agent-2': -0.996252248329057, 'agent-3': 0.32293729602455556} \n",
      "\n",
      "reward:  {'agent-0': -0.6731753379040626, 'agent-1': 1.0245160020258766, 'agent-2': -0.4243924520004967, 'agent-3': -0.9500248248217318} \n",
      "\n",
      "reward:  {'agent-0': -0.46735291399814116, 'agent-1': -1.2823504884182597, 'agent-2': -0.22304180323142475, 'agent-3': 0.1609908104704587} \n",
      "\n",
      "reward:  {'agent-0': -0.19114310732034312, 'agent-1': -1.1213179739128094, 'agent-2': -1.0156139520516163, 'agent-3': -0.6401996340927312} \n",
      "\n",
      "reward:  {'agent-0': -0.2127612471560596, 'agent-1': -0.48352162275162414, 'agent-2': -1.0689176335538235, 'agent-3': -0.9944306586184126} \n",
      "\n",
      "reward:  {'agent-0': -0.22064137572533582, 'agent-1': -1.6585085681850416, 'agent-2': 0.47416312820678286, 'agent-3': -0.6883001347206417} \n",
      "\n",
      "reward:  {'agent-0': -0.2728123405956282, 'agent-1': -0.10597185873062642, 'agent-2': -0.8500646370623883, 'agent-3': 0.3292586128454893} \n",
      "\n",
      "reward:  {'agent-0': -0.8889787746518039, 'agent-1': -0.1762911425358027, 'agent-2': -0.8874923249249136, 'agent-3': -0.882377910985241} \n",
      "\n",
      "reward:  {'agent-0': -0.3472768435560596, 'agent-1': -1.1165578867562829, 'agent-2': -0.5409853593267755, 'agent-3': -0.95398144388475} \n",
      "\n",
      "reward:  {'agent-0': -0.9842204732972633, 'agent-1': -1.1157156505942112, 'agent-2': 0.19534145292560368, 'agent-3': -0.7481644399105214} \n",
      "\n",
      "reward:  {'agent-0': -0.34704695787786477, 'agent-1': -1.0441664983907657, 'agent-2': -0.7770111217482523, 'agent-3': -0.6604434788361289} \n",
      "\n",
      "reward:  {'agent-0': -0.3193454134652107, 'agent-1': -0.26464350073079856, 'agent-2': -0.40059946213270337, 'agent-3': -0.16136355592261253} \n",
      "\n",
      "reward:  {'agent-0': 1.6319995433478738, 'agent-1': -1.127616045414996, 'agent-2': -1.0456934014925352, 'agent-3': -0.25616372666758025} \n",
      "\n",
      "reward:  {'agent-0': 0.712961385342858, 'agent-1': 1.4225921690106347, 'agent-2': -0.7092370402081087, 'agent-3': -0.9190804486960431} \n",
      "\n",
      "reward:  {'agent-0': 1.512012575405496, 'agent-1': 0.36909707214718424, 'agent-2': -0.21774297685741573, 'agent-3': 1.3287544844180772} \n",
      "\n",
      "reward:  {'agent-0': -0.05414693467038845, 'agent-1': -1.4710189527751254, 'agent-2': -0.753156683442505, 'agent-3': -0.3689443328243698} \n",
      "\n",
      "reward:  {'agent-0': 1.955905923626375, 'agent-1': -1.0439623508679432, 'agent-2': -0.885191298068392, 'agent-3': 0.16340183764514649} \n",
      "\n",
      "reward:  {'agent-0': 0.2568667376837048, 'agent-1': -1.0895164760507186, 'agent-2': 0.3327840212048301, 'agent-3': -0.7186432850700726} \n",
      "\n",
      "reward:  {'agent-0': 1.4000565157301565, 'agent-1': 1.111764417285407, 'agent-2': -1.5070986392346484, 'agent-3': -0.3098729361180439} \n",
      "\n",
      "reward:  {'agent-0': 0.291423202588291, 'agent-1': -0.5178532761832741, 'agent-2': 0.40313590066482163, 'agent-3': -0.8755942868979929} \n",
      "\n",
      "reward:  {'agent-0': -0.24086793895757808, 'agent-1': -1.2110973389118556, 'agent-2': -0.7113722885893523, 'agent-3': 0.4464133019933527} \n",
      "\n",
      "reward:  {'agent-0': 1.6057355462350529, 'agent-1': -0.8174135309350419, 'agent-2': -1.8334330057329495, 'agent-3': -0.4709517945760098} \n",
      "\n",
      "reward:  {'agent-0': 1.1347328060452817, 'agent-1': -0.6975697808928913, 'agent-2': -1.033932007577448, 'agent-3': -0.7658882476241899} \n",
      "\n",
      "reward:  {'agent-0': -0.5419540762712494, 'agent-1': 1.6716820549155358, 'agent-2': -0.6840931165194846, 'agent-3': -1.2304997551110155} \n",
      "\n",
      "reward:  {'agent-0': -0.5468020405971465, 'agent-1': -1.0231185650119272, 'agent-2': -0.9001941343056288, 'agent-3': -0.6921843927624209} \n",
      "\n",
      "reward:  {'agent-0': 1.095337834081704, 'agent-1': -0.8785343158268901, 'agent-2': -0.7702082356062476, 'agent-3': -0.991479095330277} \n",
      "\n",
      "reward:  {'agent-0': -0.3843298220286151, 'agent-1': -1.7044730815433766, 'agent-2': -1.334419220571391, 'agent-3': -1.0118347976381017} \n",
      "\n",
      "reward:  {'agent-0': 0.07963954377601468, 'agent-1': -1.0017243524945414, 'agent-2': 0.43045544762082244, 'agent-3': -0.7393772168172177} \n",
      "\n",
      "reward:  {'agent-0': -0.18944078043318768, 'agent-1': -0.15268295276376875, 'agent-2': 1.1826848301263269, 'agent-3': -0.42332488430587745} \n",
      "\n",
      "reward:  {'agent-0': 0.13216112454508533, 'agent-1': -1.6999005382569692, 'agent-2': -0.618570724669766, 'agent-3': -0.4401557010708288} \n",
      "\n",
      "reward:  {'agent-0': -0.43154601353609934, 'agent-1': -0.6936183930759654, 'agent-2': -0.8777866402625918, 'agent-3': -1.025794832534487} \n",
      "\n",
      "reward:  {'agent-0': -0.4358138176507751, 'agent-1': -2.0095568799346637, 'agent-2': 0.9487960879294164, 'agent-3': -0.8221823231402396} \n",
      "\n",
      "reward:  {'agent-0': 0.9064356908111151, 'agent-1': -1.1029498717494448, 'agent-2': -0.7603760304115923, 'agent-3': 0.6947477589466793} \n",
      "\n",
      "reward:  {'agent-0': -0.5231586361661371, 'agent-1': -0.14134728507251282, 'agent-2': -0.8149890779636664, 'agent-3': 0.02972868390422434} \n",
      "\n",
      "reward:  {'agent-0': 1.005319272932816, 'agent-1': 0.1758186021698549, 'agent-2': 0.21234785305011883, 'agent-3': 0.0041641037629744915} \n",
      "\n",
      "reward:  {'agent-0': -0.3150470635183993, 'agent-1': -0.2560165594944124, 'agent-2': -0.08894869348293355, 'agent-3': -1.2014898654109771} \n",
      "\n",
      "reward:  {'agent-0': 1.4630832711076778, 'agent-1': 1.3166888392245895, 'agent-2': 0.9582608701999646, 'agent-3': -0.9863747234056319} \n",
      "\n",
      "reward:  {'agent-0': 0.3380646354520245, 'agent-1': -1.1138974714256236, 'agent-2': -0.7233339915090653, 'agent-3': -0.9694304249262444} \n",
      "\n",
      "reward:  {'agent-0': -0.09056448028931285, 'agent-1': 0.05204495516254326, 'agent-2': -0.9875304035254047, 'agent-3': 1.6751569961001493} \n",
      "\n",
      "reward:  {'agent-0': -0.022316457379947252, 'agent-1': -0.2627332722500171, 'agent-2': -1.110434161850371, 'agent-3': 1.0660982457741923} \n",
      "\n",
      "reward:  {'agent-0': -0.9278656386536817, 'agent-1': 0.5954351294380587, 'agent-2': -0.8597151810991406, 'agent-3': -0.6651636713947902} \n",
      "\n",
      "reward:  {'agent-0': -0.9743822669101263, 'agent-1': -0.3179091924585862, 'agent-2': -0.02147805130334035, 'agent-3': 0.7160794979875291} \n",
      "\n",
      "reward:  {'agent-0': -0.0770515203021489, 'agent-1': -0.5035175076534557, 'agent-2': -1.2425193512206079, 'agent-3': -0.44712490385513703} \n",
      "\n",
      "reward:  {'agent-0': -0.9336941417137545, 'agent-1': -0.1891114095818267, 'agent-2': -0.26997981612053934, 'agent-3': -0.8454708187959099} \n",
      "\n",
      "reward:  {'agent-0': -0.9537154189590673, 'agent-1': -0.9838138346931089, 'agent-2': -1.1513741998445965, 'agent-3': -0.743383012514446} \n",
      "\n",
      "reward:  {'agent-0': -0.9587478721757954, 'agent-1': 0.7397729919504314, 'agent-2': -0.8881425634628073, 'agent-3': -0.9214595178159044} \n",
      "\n",
      "reward:  {'agent-0': -0.9665261603862376, 'agent-1': -1.2902996329178293, 'agent-2': -0.9354922650561903, 'agent-3': 0.04674096507091008} \n",
      "\n",
      "reward:  {'agent-0': -0.07385840308061375, 'agent-1': -0.5412352434071366, 'agent-2': 1.1272637476476248, 'agent-3': -1.207188533771621} \n",
      "\n",
      "reward:  {'agent-0': 0.19637991847566738, 'agent-1': -0.7621487548144472, 'agent-2': -0.7566918189883367, 'agent-3': 0.3939446546039136} \n",
      "\n",
      "reward:  {'agent-0': -0.6977627546949492, 'agent-1': 0.381752207146846, 'agent-2': -0.8907199467295541, 'agent-3': -0.1976654486036864} \n",
      "\n",
      "reward:  {'agent-0': 0.9619056658879686, 'agent-1': -1.598273198223346, 'agent-2': 0.9039799248944362, 'agent-3': -0.1692978462010224} \n",
      "\n",
      "reward:  {'agent-0': -0.7011400807982326, 'agent-1': 1.643491633396117, 'agent-2': -1.0100009844424278, 'agent-3': -0.926798005503997} \n",
      "\n",
      "reward:  {'agent-0': -0.015597012471694427, 'agent-1': -0.3582543753387597, 'agent-2': -0.5779341205275159, 'agent-3': -0.9802107054130182} \n",
      "\n",
      "reward:  {'agent-0': -0.5429638671023724, 'agent-1': 0.099419557065346, 'agent-2': -0.5889045867756266, 'agent-3': -0.32879287928955137} \n",
      "\n",
      "reward:  {'agent-0': 1.5713040870760189, 'agent-1': 1.3096648532786048, 'agent-2': 0.8427270740804218, 'agent-3': -0.46139407781299724} \n",
      "\n",
      "reward:  {'agent-0': -0.5020356852828343, 'agent-1': -1.4464847162243757, 'agent-2': 0.40083983694211867, 'agent-3': -1.0374602397973476} \n",
      "\n",
      "reward:  {'agent-0': 0.9303717533780151, 'agent-1': 0.48431846230444364, 'agent-2': -1.2653279045610333, 'agent-3': -0.3449668884981598} \n",
      "\n",
      "reward:  {'agent-0': 1.7654610055975262, 'agent-1': -0.7407422535190875, 'agent-2': -0.7494689040099374, 'agent-3': -0.14256861346657956} \n",
      "\n",
      "reward:  {'agent-0': 2.308672262751635, 'agent-1': -0.6417666630881911, 'agent-2': -0.5917686395947257, 'agent-3': -1.1441729740227906} \n",
      "\n",
      "reward:  {'agent-0': 0.08932566334208403, 'agent-1': 0.11979462956881548, 'agent-2': -0.12480124757271227, 'agent-3': 1.0808418284131491} \n",
      "\n",
      "reward:  {'agent-0': 1.4013453456431257, 'agent-1': -0.5305090156805932, 'agent-2': -0.9940932854173141, 'agent-3': -1.0014206163524904} \n",
      "\n",
      "reward:  {'agent-0': 0.38751121474486183, 'agent-1': -0.33554951361450236, 'agent-2': -0.7352918418142309, 'agent-3': -0.023953782692707648} \n",
      "\n",
      "reward:  {'agent-0': 0.30740692282470405, 'agent-1': -1.0774521238398052, 'agent-2': 0.42575398113922347, 'agent-3': 0.37057261769739824} \n",
      "\n",
      "reward:  {'agent-0': -0.19253334550910495, 'agent-1': 0.9279842157991212, 'agent-2': -0.46603489206435, 'agent-3': -0.8982018519236057} \n",
      "\n",
      "reward:  {'agent-0': 0.710629443402393, 'agent-1': 1.5634259693388302, 'agent-2': -0.19572041101347537, 'agent-3': -0.9224430032832842} \n",
      "\n",
      "reward:  {'agent-0': 0.11388539623151672, 'agent-1': -0.360874559588126, 'agent-2': -0.9246736744827828, 'agent-3': -1.0083944451694862} \n",
      "\n",
      "reward:  {'agent-0': -0.2532372527226663, 'agent-1': -0.6499571327766063, 'agent-2': -0.2789750147913921, 'agent-3': -0.9797750932464773} \n",
      "\n",
      "reward:  {'agent-0': 0.510257996611724, 'agent-1': -0.9958120353608138, 'agent-2': -0.9300917503231361, 'agent-3': -0.3485143498073242} \n",
      "\n",
      "reward:  {'agent-0': -0.42336453995020307, 'agent-1': -1.4329995584052142, 'agent-2': -0.34994149635695493, 'agent-3': -1.5379191686817713} \n",
      "\n",
      "reward:  {'agent-0': -0.48152192294926977, 'agent-1': -1.217034627313005, 'agent-2': -0.8887412584736225, 'agent-3': -0.3666582624185608} \n",
      "\n",
      "reward:  {'agent-0': 0.2222222443143771, 'agent-1': -0.08293844495168656, 'agent-2': 1.3189411317007824, 'agent-3': -0.675355306984514} \n",
      "\n",
      "reward:  {'agent-0': -0.8652718940779138, 'agent-1': 0.08942341096759776, 'agent-2': -0.8864668973823342, 'agent-3': -1.0076091356843122} \n",
      "\n",
      "reward:  {'agent-0': -0.5548633386970856, 'agent-1': -0.9274183942515393, 'agent-2': 0.2522775632848848, 'agent-3': -1.0610245354363173} \n",
      "\n",
      "reward:  {'agent-0': 1.1258043897280814, 'agent-1': -0.8222422475843345, 'agent-2': -0.8695610205841646, 'agent-3': -1.1429328515803476} \n",
      "\n",
      "reward:  {'agent-0': -0.5336896822033523, 'agent-1': 0.5779138666472292, 'agent-2': -0.8654088726297218, 'agent-3': -0.45009459620557735} \n",
      "\n",
      "reward:  {'agent-0': -0.2814041057594743, 'agent-1': -1.2457811102849874, 'agent-2': 0.6313468586347426, 'agent-3': -0.9165883486040158} \n",
      "\n",
      "reward:  {'agent-0': 0.3393987603872972, 'agent-1': -0.9924681913256563, 'agent-2': 0.10328991428229273, 'agent-3': -0.03605583272683077} \n",
      "\n",
      "reward:  {'agent-0': -0.9480981568416524, 'agent-1': -0.1133932945377083, 'agent-2': -0.6868503075490437, 'agent-3': -0.42198061475891535} \n",
      "\n",
      "reward:  {'agent-0': -0.9186964945463956, 'agent-1': -0.2614780013579434, 'agent-2': -0.9709054305812472, 'agent-3': -1.3668399238054398} \n",
      "\n",
      "reward:  {'agent-0': -0.6028492606183349, 'agent-1': -0.7418299187758066, 'agent-2': -0.018888763632219252, 'agent-3': 1.39242998781355} \n",
      "\n",
      "reward:  {'agent-0': 0.7333662395906302, 'agent-1': -0.11134175544471248, 'agent-2': -0.9067884508976078, 'agent-3': 1.671177264376503} \n",
      "\n",
      "reward:  {'agent-0': -0.06504865066335697, 'agent-1': 0.506066978930761, 'agent-2': -1.6197392359288116, 'agent-3': -0.26222605912523633} \n",
      "\n",
      "reward:  {'agent-0': 1.522056647732981, 'agent-1': -2.471676152405891, 'agent-2': 0.15227782216194896, 'agent-3': 1.230233170521501} \n",
      "\n",
      "reward:  {'agent-0': -0.39337943111912566, 'agent-1': -0.48744225225323135, 'agent-2': -0.8301572520011646, 'agent-3': -0.8375205036315378} \n",
      "\n",
      "reward:  {'agent-0': -0.7522130886540346, 'agent-1': -0.7535661943751677, 'agent-2': -1.0063659846979576, 'agent-3': 0.22943512840783242} \n",
      "\n",
      "reward:  {'agent-0': -0.710006386855234, 'agent-1': -1.0985989801616753, 'agent-2': -0.9079513284902063, 'agent-3': 1.3472274511296973} \n",
      "\n",
      "reward:  {'agent-0': 1.6531016113458463, 'agent-1': -0.9221295924809709, 'agent-2': -0.5976731392598822, 'agent-3': -0.8218732555826023} \n",
      "\n",
      "reward:  {'agent-0': -0.044428054698293806, 'agent-1': -0.9411451567831932, 'agent-2': 0.5853792655898857, 'agent-3': 0.07520848855561724} \n",
      "\n",
      "reward:  {'agent-0': -0.2252783947827055, 'agent-1': -0.7263791286934378, 'agent-2': -1.5073304444833724, 'agent-3': 2.013035510407015} \n",
      "\n",
      "reward:  {'agent-0': -0.8096031945003119, 'agent-1': -0.6621591086446728, 'agent-2': -0.570086460553135, 'agent-3': -0.9603545291495941} \n",
      "\n",
      "reward:  {'agent-0': -0.7913191240793118, 'agent-1': -2.4445658709609432, 'agent-2': -0.4579841100644231, 'agent-3': -0.7678531543398286} \n",
      "\n",
      "reward:  {'agent-0': 0.9065457501371199, 'agent-1': -0.08323423228301863, 'agent-2': -0.9342388967857076, 'agent-3': -0.07689197539168191} \n",
      "\n",
      "reward:  {'agent-0': -0.3360516703058032, 'agent-1': -0.5306853919135506, 'agent-2': -0.6754399571951311, 'agent-3': 0.07960822480155016} \n",
      "\n",
      "reward:  {'agent-0': -0.6571085997288115, 'agent-1': 0.2827008171810661, 'agent-2': 0.10728002436700024, 'agent-3': -0.16065484058292867} \n",
      "\n",
      "reward:  {'agent-0': 0.08105836037423941, 'agent-1': -1.6067933667375485, 'agent-2': -0.7168965568541168, 'agent-3': 1.0651397040943706} \n",
      "\n",
      "reward:  {'agent-0': -0.937057443868337, 'agent-1': -0.0865483079717535, 'agent-2': -0.4565961666581799, 'agent-3': -0.23226791988287587} \n",
      "\n",
      "reward:  {'agent-0': -0.2033039374543577, 'agent-1': 0.21108272717627585, 'agent-2': -1.0598833081816892, 'agent-3': -0.8283351464582154} \n",
      "\n",
      "reward:  {'agent-0': 0.9374866119348759, 'agent-1': -0.5400943457296208, 'agent-2': -1.6062110796312723, 'agent-3': 0.006221953259434088} \n",
      "\n",
      "reward:  {'agent-0': 1.3531496511387324, 'agent-1': 0.21439472462711961, 'agent-2': -0.6425550719499498, 'agent-3': -0.7469115452145623} \n",
      "\n",
      "reward:  {'agent-0': -0.8919632883758766, 'agent-1': 1.1248925538382792, 'agent-2': -0.8284401173242841, 'agent-3': -1.3477665658700104} \n",
      "\n",
      "reward:  {'agent-0': 0.05383722392860335, 'agent-1': -0.8540015291155783, 'agent-2': 0.978348588551718, 'agent-3': -0.319802379955874} \n",
      "\n",
      "reward:  {'agent-0': 0.5371532298032591, 'agent-1': -0.8718893135777677, 'agent-2': -0.7416709989851356, 'agent-3': -1.0790308628294554} \n",
      "\n",
      "reward:  {'agent-0': 0.5931262816411618, 'agent-1': 0.09715407592339886, 'agent-2': -0.9579884019255758, 'agent-3': -0.9456962558713329} \n",
      "\n",
      "reward:  {'agent-0': -0.9448247245204584, 'agent-1': 0.29645745332427254, 'agent-2': -0.8746547970720044, 'agent-3': -0.9563543952187601} \n",
      "\n",
      "reward:  {'agent-0': -0.7224540066186691, 'agent-1': 0.5928654058685083, 'agent-2': -0.7974337211865574, 'agent-3': -0.23799947730352855} \n",
      "\n",
      "reward:  {'agent-0': -0.39705766009882737, 'agent-1': -0.3332220934641157, 'agent-2': -0.514503378009465, 'agent-3': -0.9341766826609756} \n",
      "\n",
      "reward:  {'agent-0': 0.02053590651536652, 'agent-1': -0.03404870555755224, 'agent-2': -0.7518771552536734, 'agent-3': 0.41467316224317585} \n",
      "\n",
      "reward:  {'agent-0': 0.9623222624918277, 'agent-1': -0.4297093199828623, 'agent-2': -0.5757702132354012, 'agent-3': 0.8990580778775552} \n",
      "\n",
      "reward:  {'agent-0': -0.7340296905067518, 'agent-1': -1.1377545129489803, 'agent-2': -0.4621599773773539, 'agent-3': -0.5616300554808404} \n",
      "\n",
      "reward:  {'agent-0': -0.7443663538864769, 'agent-1': 0.2908541891720233, 'agent-2': -0.5582990954643137, 'agent-3': -0.992392926142216} \n",
      "\n",
      "reward:  {'agent-0': 0.01978016472784816, 'agent-1': -0.9690747135437405, 'agent-2': -0.9934181389606849, 'agent-3': -0.5753311273290791} \n",
      "\n",
      "reward:  {'agent-0': 0.7259447156779721, 'agent-1': -0.4721911102321883, 'agent-2': -0.5639481467238099, 'agent-3': 1.9509605859851362} \n",
      "\n",
      "reward:  {'agent-0': 0.9851884178988364, 'agent-1': -1.093946448960459, 'agent-2': -0.9839918222404549, 'agent-3': -0.8266931757081082} \n",
      "\n",
      "reward:  {'agent-0': 1.0229428566540193, 'agent-1': 0.5785891599980033, 'agent-2': -0.04175333180464946, 'agent-3': -0.38907890842410353} \n",
      "\n",
      "reward:  {'agent-0': -0.5815646451718024, 'agent-1': -0.8963704780466202, 'agent-2': -0.3077812135600766, 'agent-3': 0.3205271938661127} \n",
      "\n",
      "reward:  {'agent-0': 0.38456827193636833, 'agent-1': -0.4722071405398296, 'agent-2': -0.9640672753457835, 'agent-3': 0.17496828353498017} \n",
      "\n",
      "reward:  {'agent-0': 0.0854626349463885, 'agent-1': -0.9070104387814482, 'agent-2': 0.40054572988697146, 'agent-3': -0.12979815598607303} \n",
      "\n",
      "reward:  {'agent-0': 0.009030642860150095, 'agent-1': -0.672643395023087, 'agent-2': 0.3452587379923884, 'agent-3': -0.21514441582397126} \n",
      "\n",
      "reward:  {'agent-0': 0.4656058007368067, 'agent-1': -0.5308598449205988, 'agent-2': -0.9797348504864516, 'agent-3': -0.037782452945002376} \n",
      "\n",
      "reward:  {'agent-0': 0.22012881490987368, 'agent-1': -1.27422247851149, 'agent-2': 0.6705394569924792, 'agent-3': -1.0070290262324768} \n",
      "\n",
      "reward:  {'agent-0': -0.7685514308211587, 'agent-1': -1.002241581124217, 'agent-2': 1.0059265016209906, 'agent-3': 0.5720332683480471} \n",
      "\n",
      "reward:  {'agent-0': 0.08372739221244885, 'agent-1': -2.2427939949956226, 'agent-2': 0.06250314281438563, 'agent-3': -0.9307787565948473} \n",
      "\n",
      "reward:  {'agent-0': 0.07606408194088843, 'agent-1': -1.766512899957192, 'agent-2': -1.5226938828325771, 'agent-3': 0.8635198503096966} \n",
      "\n",
      "reward:  {'agent-0': 0.16140577580084425, 'agent-1': 0.020088306729533656, 'agent-2': -0.929558389604729, 'agent-3': -0.9944561401129377} \n",
      "\n",
      "reward:  {'agent-0': -0.17439891858793644, 'agent-1': 0.003540349246691221, 'agent-2': -0.9739523250668256, 'agent-3': -0.8505931645256979} \n",
      "\n",
      "reward:  {'agent-0': -0.9483808899270443, 'agent-1': -2.28222785926026, 'agent-2': -1.8424630079218858, 'agent-3': -1.0144976994881887} \n",
      "\n",
      "reward:  {'agent-0': -0.1370113335052494, 'agent-1': -0.6734009325967492, 'agent-2': -0.7020961654740674, 'agent-3': 0.042607289683260774} \n",
      "\n",
      "reward:  {'agent-0': 0.5976270357647309, 'agent-1': -1.6580313729352412, 'agent-2': -0.693823183762305, 'agent-3': 1.1394665691958252} \n",
      "\n",
      "reward:  {'agent-0': 1.114120834594921, 'agent-1': -2.2226071264917806, 'agent-2': 0.8029030438372402, 'agent-3': -0.7618211106404047} \n",
      "\n",
      "reward:  {'agent-0': -0.9617664537011308, 'agent-1': -1.174437050501453, 'agent-2': 0.9168518195243749, 'agent-3': -0.5518233474581002} \n",
      "\n",
      "reward:  {'agent-0': -0.3669228659047761, 'agent-1': -1.821716300563324, 'agent-2': -1.1225231089686005, 'agent-3': -0.856509198713546} \n",
      "\n",
      "reward:  {'agent-0': 1.823610287946991, 'agent-1': 0.10636644390575611, 'agent-2': -1.0418282341287437, 'agent-3': -0.9814152523914572} \n",
      "\n",
      "reward:  {'agent-0': 0.7494182171886727, 'agent-1': -1.2839226762128035, 'agent-2': -0.897045606775265, 'agent-3': -0.918254839075054} \n",
      "\n",
      "reward:  {'agent-0': -0.6294718357109446, 'agent-1': -0.9025914559650658, 'agent-2': -0.580107348868502, 'agent-3': -0.7993562959878915} \n",
      "\n",
      "reward:  {'agent-0': 0.6961443066616066, 'agent-1': -0.9112033716964305, 'agent-2': 0.5262575993930909, 'agent-3': 0.2579505006348519} \n",
      "\n",
      "reward:  {'agent-0': 1.0084618836435908, 'agent-1': -0.21349076738709982, 'agent-2': -0.5062321247672301, 'agent-3': -0.7310120014029131} \n",
      "\n",
      "reward:  {'agent-0': 0.6255309985465018, 'agent-1': 0.07647067957829279, 'agent-2': -1.3661981130742546, 'agent-3': 0.39839972158424075} \n",
      "\n",
      "reward:  {'agent-0': -0.8436008643368993, 'agent-1': -0.8869386857196702, 'agent-2': -1.1253432150780256, 'agent-3': 0.25236468365320164} \n",
      "\n",
      "reward:  {'agent-0': -0.8466026352340119, 'agent-1': -0.4841926947952757, 'agent-2': 1.7359615503221661, 'agent-3': -1.2611920357612227} \n",
      "\n",
      "reward:  {'agent-0': 0.09029112009395135, 'agent-1': -1.5990737325627293, 'agent-2': -0.2177372137865632, 'agent-3': 1.153083663747779} \n",
      "\n",
      "reward:  {'agent-0': -0.6341902938558732, 'agent-1': -3.0407938833269057, 'agent-2': -1.0094600000518525, 'agent-3': 1.2195876500738336} \n",
      "\n",
      "reward:  {'agent-0': 0.055127228246924176, 'agent-1': -1.1230597338227852, 'agent-2': -0.487734147815182, 'agent-3': -0.9841694070575144} \n",
      "\n",
      "reward:  {'agent-0': -0.07975318912705553, 'agent-1': 0.4323314231813171, 'agent-2': -0.9465376678508051, 'agent-3': -1.3190843457118397} \n",
      "\n",
      "reward:  {'agent-0': 0.12347305317416613, 'agent-1': -0.7193517538244123, 'agent-2': -0.37327872310031296, 'agent-3': 0.6110943958213326} \n",
      "\n",
      "reward:  {'agent-0': 0.8348014611813603, 'agent-1': -0.8677402881207428, 'agent-2': -1.19404754831735, 'agent-3': -1.2500878944276472} \n",
      "\n",
      "reward:  {'agent-0': 1.905540164373317, 'agent-1': -2.2350253318518014, 'agent-2': -1.0114439451844675, 'agent-3': -0.8223974135595498} \n",
      "\n",
      "reward:  {'agent-0': 1.2402357698995274, 'agent-1': -1.0406191003041698, 'agent-2': -0.326409580291525, 'agent-3': -0.8691293938008258} \n",
      "\n",
      "reward:  {'agent-0': -0.552263536434463, 'agent-1': -1.0839569768967294, 'agent-2': -0.9932880002905193, 'agent-3': -0.7237347924952573} \n",
      "\n",
      "reward:  {'agent-0': 0.04676697820459452, 'agent-1': -1.0416247866038049, 'agent-2': -0.6300579579534613, 'agent-3': -0.9747915346132885} \n",
      "\n",
      "reward:  {'agent-0': 0.19692252898296658, 'agent-1': 0.21367305422515415, 'agent-2': -1.0446302623736514, 'agent-3': -0.7020979303325348} \n",
      "\n",
      "reward:  {'agent-0': -0.4689673673002588, 'agent-1': -0.993723440530097, 'agent-2': 0.14887451266064033, 'agent-3': -0.023553205680208578} \n",
      "\n",
      "reward:  {'agent-0': -0.23800663206844774, 'agent-1': -0.19180483318034902, 'agent-2': -1.2136878284441366, 'agent-3': -0.6164654207985194} \n",
      "\n",
      "reward:  {'agent-0': 0.9880075303429514, 'agent-1': 0.7152750771745815, 'agent-2': -0.5290268645306639, 'agent-3': 1.7243568868648111} \n",
      "\n",
      "reward:  {'agent-0': -0.6253835000698231, 'agent-1': 0.2428860508773667, 'agent-2': -1.1695848358355292, 'agent-3': -0.27607045688355925} \n",
      "\n",
      "reward:  {'agent-0': 1.0531943897832772, 'agent-1': -0.1760663156469633, 'agent-2': -0.2572742460425559, 'agent-3': 0.33851773249484296} \n",
      "\n",
      "reward:  {'agent-0': -0.3526238306236138, 'agent-1': -1.6141158303896148, 'agent-2': -0.2974886047507752, 'agent-3': 0.5468470547421802} \n",
      "\n",
      "reward:  {'agent-0': -0.3606304908981315, 'agent-1': -1.812189716639594, 'agent-2': 1.8103067134692807, 'agent-3': -0.9563516871791009} \n",
      "\n",
      "reward:  {'agent-0': -0.9264618979888652, 'agent-1': -1.9729118311267797, 'agent-2': -1.2284847729443271, 'agent-3': 0.35638067219397485} \n",
      "\n",
      "reward:  {'agent-0': -0.3033230985257376, 'agent-1': 0.8923846788382122, 'agent-2': -0.9315070039746018, 'agent-3': -1.0148300788939153} \n",
      "\n",
      "reward:  {'agent-0': -0.7257304747787074, 'agent-1': 0.13025943630931636, 'agent-2': -0.37677808367506316, 'agent-3': -1.2405994867463406} \n",
      "\n",
      "reward:  {'agent-0': 0.27069493021376445, 'agent-1': -1.3695301311178127, 'agent-2': -0.6547550271213396, 'agent-3': -0.0880973662183564} \n",
      "\n",
      "reward:  {'agent-0': -0.7844485186025594, 'agent-1': -0.03321343216393302, 'agent-2': -0.11186919586345567, 'agent-3': 1.0263074574120452} \n",
      "\n",
      "reward:  {'agent-0': 0.04524374450992852, 'agent-1': 0.4946414292350312, 'agent-2': -1.2901761098018056, 'agent-3': -0.3884392734095279} \n",
      "\n",
      "reward:  {'agent-0': -0.638004207813335, 'agent-1': -0.5685206726480629, 'agent-2': 0.19668151516075483, 'agent-3': 1.2478978954654423} \n",
      "\n",
      "reward:  {'agent-0': -0.4778672527008432, 'agent-1': -0.9289252418670344, 'agent-2': -0.9771741242904355, 'agent-3': 1.5697613036454001} \n",
      "\n",
      "reward:  {'agent-0': 0.37868300710117, 'agent-1': -0.9675710416129419, 'agent-2': -0.7996264984613646, 'agent-3': -1.0003063444136444} \n",
      "\n",
      "reward:  {'agent-0': 0.34276001474415096, 'agent-1': -0.7909624235384953, 'agent-2': 0.4626555332413176, 'agent-3': -0.9275227461171944} \n",
      "\n",
      "reward:  {'agent-0': 0.1519698251449757, 'agent-1': -1.0375302759965024, 'agent-2': -0.81940111696305, 'agent-3': 0.1259709465755563} \n",
      "\n",
      "reward:  {'agent-0': -0.03809471708622425, 'agent-1': -1.0475880953201795, 'agent-2': -1.068000104042298, 'agent-3': -0.8072596925300495} \n",
      "\n",
      "reward:  {'agent-0': 1.464945804429357, 'agent-1': 0.11825572541761176, 'agent-2': 0.5796525748245571, 'agent-3': 1.0538501861084626} \n",
      "\n",
      "reward:  {'agent-0': 0.34732209461981256, 'agent-1': -0.024134447258383318, 'agent-2': -0.4030324126440519, 'agent-3': -0.987368191169697} \n",
      "\n",
      "reward:  {'agent-0': 0.8721455831920792, 'agent-1': -0.10562388467576511, 'agent-2': 0.1375974135033644, 'agent-3': -1.346798094522434} \n",
      "\n",
      "reward:  {'agent-0': -0.6656470284977836, 'agent-1': 0.9000908084704378, 'agent-2': -0.7517397061840114, 'agent-3': 0.0589369260509649} \n",
      "\n",
      "reward:  {'agent-0': -0.4131141647499277, 'agent-1': -0.6161535315712854, 'agent-2': -0.6453074503792706, 'agent-3': -0.9770187376438457} \n",
      "\n",
      "reward:  {'agent-0': 0.5858802273860597, 'agent-1': -0.3949221838595207, 'agent-2': -0.17912200976264359, 'agent-3': 0.18844428202817198} \n",
      "\n",
      "reward:  {'agent-0': -0.4873340834061999, 'agent-1': -2.2508289888003077, 'agent-2': -0.5519248261987002, 'agent-3': 0.8612650281133156} \n",
      "\n",
      "reward:  {'agent-0': -0.25586047277936075, 'agent-1': -0.7922655065931394, 'agent-2': 0.4465503784758269, 'agent-3': -0.7628413544685451} \n",
      "\n",
      "reward:  {'agent-0': -0.6667526667716412, 'agent-1': 0.7524150750433591, 'agent-2': -0.9212449628880961, 'agent-3': -0.5237263143957023} \n",
      "\n",
      "reward:  {'agent-0': 0.3144878507378088, 'agent-1': -1.1552586163132688, 'agent-2': -0.35059038967041545, 'agent-3': 0.24305760149095335} \n",
      "\n",
      "reward:  {'agent-0': -0.3761364312597877, 'agent-1': -0.8373040695220553, 'agent-2': -0.24661062008583912, 'agent-3': 0.08740601329417075} \n",
      "\n",
      "reward:  {'agent-0': -0.4538210251608952, 'agent-1': 1.1251228421012343, 'agent-2': -0.008814202786453507, 'agent-3': -0.30924426153387685} \n",
      "\n",
      "reward:  {'agent-0': -0.9381546281734323, 'agent-1': 0.7999573442181216, 'agent-2': -0.4835157946350108, 'agent-3': -0.03366900375769433} \n",
      "\n",
      "reward:  {'agent-0': 0.008633068748299166, 'agent-1': -1.7217995763475074, 'agent-2': -0.38119052875699566, 'agent-3': -0.6072379865754378} \n",
      "\n",
      "reward:  {'agent-0': -0.5038809960768056, 'agent-1': -0.9904423192635292, 'agent-2': -0.173054089355567, 'agent-3': -0.21821649300908064} \n",
      "\n",
      "reward:  {'agent-0': -0.9600431861439347, 'agent-1': -0.7063585185404264, 'agent-2': -0.11238411485049937, 'agent-3': -0.00890831821224225} \n",
      "\n",
      "reward:  {'agent-0': -0.22829340301562695, 'agent-1': -1.345598609094651, 'agent-2': -0.13844481676625975, 'agent-3': -0.9408221757404505} \n",
      "\n",
      "reward:  {'agent-0': 0.4046642393138722, 'agent-1': -1.1444669236326916, 'agent-2': -0.8884658309895812, 'agent-3': -0.42680354253528563} \n",
      "\n",
      "reward:  {'agent-0': 0.10314248041391494, 'agent-1': -1.5314891802428292, 'agent-2': -0.617999416225075, 'agent-3': -0.9178408040525525} \n",
      "\n",
      "reward:  {'agent-0': -0.2875110437096353, 'agent-1': -0.8550172021763913, 'agent-2': 0.8141632727948149, 'agent-3': -1.0841045456422407} \n",
      "\n",
      "reward:  {'agent-0': -0.8129670975682828, 'agent-1': 0.8268555337498853, 'agent-2': -0.9379490491112321, 'agent-3': 0.0006870950812114529} \n",
      "\n",
      "reward:  {'agent-0': -0.8920261008785744, 'agent-1': 0.24583597642887867, 'agent-2': -1.0585012575101516, 'agent-3': 0.1792004924580084} \n",
      "\n",
      "reward:  {'agent-0': 0.3461893910740965, 'agent-1': -1.7674652821200425, 'agent-2': -1.2297076500765982, 'agent-3': -1.2116942892176397} \n",
      "\n",
      "reward:  {'agent-0': -0.09605721482886764, 'agent-1': -0.7862407500206174, 'agent-2': -0.6825259967100337, 'agent-3': -0.8838405484802649} \n",
      "\n",
      "reward:  {'agent-0': -0.22226675743204538, 'agent-1': -0.7695699227203079, 'agent-2': -0.8473976681249411, 'agent-3': -1.068328666746595} \n",
      "\n",
      "reward:  {'agent-0': 0.617773588776231, 'agent-1': -0.9716381030282903, 'agent-2': -0.5961080759024426, 'agent-3': -0.9215196158007117} \n",
      "\n",
      "reward:  {'agent-0': -0.5012029626354, 'agent-1': -0.12741240682068167, 'agent-2': -0.7931330989105945, 'agent-3': -1.4744892150463542} \n",
      "\n",
      "reward:  {'agent-0': 0.024910774503222655, 'agent-1': -0.005693228254671112, 'agent-2': -0.991480719841725, 'agent-3': -1.097987401710263} \n",
      "\n",
      "reward:  {'agent-0': -0.421646341410991, 'agent-1': 0.10993159805250485, 'agent-2': 0.18621184446378436, 'agent-3': 0.22919518685221618} \n",
      "\n",
      "reward:  {'agent-0': -0.9913801337973247, 'agent-1': -1.8801798406704293, 'agent-2': -1.0889153818847888, 'agent-3': -0.4501503562119602} \n",
      "\n",
      "reward:  {'agent-0': 0.4125732408615086, 'agent-1': 0.4321885301399391, 'agent-2': -0.860806634850988, 'agent-3': -1.089461544455414} \n",
      "\n",
      "reward:  {'agent-0': 1.2744812361331537, 'agent-1': -0.7602111408547358, 'agent-2': 0.2335899262288521, 'agent-3': -0.7470219755138032} \n",
      "\n",
      "reward:  {'agent-0': 0.026522083356542936, 'agent-1': -0.9549799416345124, 'agent-2': 0.922358197164904, 'agent-3': -0.8562842499280592} \n",
      "\n",
      "reward:  {'agent-0': -0.8831512318811257, 'agent-1': 0.09684302074244755, 'agent-2': 0.23748398249438907, 'agent-3': -0.4623479355056581} \n",
      "\n",
      "reward:  {'agent-0': -0.44648340428543776, 'agent-1': -1.1064852467052404, 'agent-2': 0.6344623741262438, 'agent-3': -0.2702158832701329} \n",
      "\n",
      "reward:  {'agent-0': -0.19008119454854722, 'agent-1': -1.3897349208309606, 'agent-2': -0.26165807857830004, 'agent-3': -0.8494103935829642} \n",
      "\n",
      "reward:  {'agent-0': -0.6579587788705492, 'agent-1': -1.1454606923774264, 'agent-2': -0.1952736399669064, 'agent-3': -0.01443199715166088} \n",
      "\n",
      "reward:  {'agent-0': -0.6323236292642491, 'agent-1': -0.19833742323190506, 'agent-2': 0.5179287445547445, 'agent-3': -0.18847993588193646} \n",
      "\n",
      "reward:  {'agent-0': -0.7643265284294571, 'agent-1': -0.5172190488516719, 'agent-2': 1.9379248879098085, 'agent-3': 1.3404229987959937} \n",
      "\n",
      "reward:  {'agent-0': 0.16121594987072285, 'agent-1': 1.7866163287964412, 'agent-2': -0.730342666881036, 'agent-3': -0.7415721942844371} \n",
      "\n",
      "reward:  {'agent-0': 0.12533962435461277, 'agent-1': -1.473295589384982, 'agent-2': 0.7802451585118817, 'agent-3': -0.944534939856716} \n",
      "\n",
      "reward:  {'agent-0': 0.3451355919081891, 'agent-1': 0.9492971122270717, 'agent-2': -0.2274301428056873, 'agent-3': -0.4297221790780803} \n",
      "\n",
      "reward:  {'agent-0': -0.7326659532332229, 'agent-1': -0.2731614957638939, 'agent-2': -1.0425689279136208, 'agent-3': -2.1063604842165766} \n",
      "\n",
      "reward:  {'agent-0': -0.41646818356259097, 'agent-1': -2.546208754025706, 'agent-2': -0.9270673096868123, 'agent-3': 0.3541342895564057} \n",
      "\n",
      "reward:  {'agent-0': -0.09606131925107242, 'agent-1': -0.7077011584097264, 'agent-2': -0.9747020071860035, 'agent-3': -0.6141962939736274} \n",
      "\n",
      "reward:  {'agent-0': -0.617204212871691, 'agent-1': -1.1271527754804964, 'agent-2': 0.28775347635919957, 'agent-3': -0.5822460477977636} \n",
      "\n",
      "reward:  {'agent-0': -0.05879896903124404, 'agent-1': -1.0295937808853068, 'agent-2': 0.010853206227970702, 'agent-3': -0.6056953366977424} \n",
      "\n",
      "reward:  {'agent-0': -0.6595645034328292, 'agent-1': 0.8567816264259491, 'agent-2': 0.02823079232404524, 'agent-3': -1.0036340660481713} \n",
      "\n",
      "reward:  {'agent-0': 0.33419148319698877, 'agent-1': 0.011836766293171763, 'agent-2': -0.2687437778046373, 'agent-3': -0.0051599847146590605} \n",
      "\n",
      "reward:  {'agent-0': 0.15335619500956454, 'agent-1': 1.1574085121464606, 'agent-2': -2.529549119046216, 'agent-3': -0.30907759464055573} \n",
      "\n",
      "reward:  {'agent-0': -0.9660656968327004, 'agent-1': -0.7770454306756847, 'agent-2': -0.9294014953385101, 'agent-3': -0.344785691552957} \n",
      "\n",
      "reward:  {'agent-0': -0.10941535408404235, 'agent-1': -0.921149651017295, 'agent-2': 0.18719777063437704, 'agent-3': -0.6088787010795897} \n",
      "\n",
      "reward:  {'agent-0': 0.4089478125330608, 'agent-1': -1.4605115732530791, 'agent-2': 0.3452063512492529, 'agent-3': 1.6402171971768382} \n",
      "\n",
      "reward:  {'agent-0': -0.03596696246263775, 'agent-1': -1.0835303148842144, 'agent-2': 2.245627501871809, 'agent-3': 1.0060821694663034} \n",
      "\n",
      "reward:  {'agent-0': -0.8481772898507316, 'agent-1': -0.08263618323955768, 'agent-2': -0.8400997620274993, 'agent-3': -0.7581755653846756} \n",
      "\n",
      "reward:  {'agent-0': -0.9614166733397838, 'agent-1': 0.8426326862182023, 'agent-2': 1.2066192792711377, 'agent-3': -0.8030700173766476} \n",
      "\n",
      "reward:  {'agent-0': 0.785831820659677, 'agent-1': -1.1766206269986057, 'agent-2': -0.38997520793611073, 'agent-3': -0.7314132014473529} \n",
      "\n",
      "reward:  {'agent-0': -0.2053524073296522, 'agent-1': -0.7632981504180805, 'agent-2': -0.6522705271405087, 'agent-3': 1.3074919062755797} \n",
      "\n",
      "reward:  {'agent-0': -0.9270519689089483, 'agent-1': 0.3342932103255549, 'agent-2': -0.6425663854150585, 'agent-3': -0.9266453612783963} \n",
      "\n",
      "reward:  {'agent-0': -0.9184304198967332, 'agent-1': -0.385100440377002, 'agent-2': -0.9288275152909549, 'agent-3': -0.9734994217112174} \n",
      "\n",
      "reward:  {'agent-0': -0.3275286561219275, 'agent-1': -0.25900559500601616, 'agent-2': 0.11780703310898133, 'agent-3': 0.284941202115256} \n",
      "\n",
      "reward:  {'agent-0': 0.4303067646615286, 'agent-1': 1.6307226152919299, 'agent-2': -0.7075706288358035, 'agent-3': 0.6694456034558343} \n",
      "\n",
      "reward:  {'agent-0': -0.4927893827671497, 'agent-1': -1.0284005050774354, 'agent-2': -0.9908477619010725, 'agent-3': 0.776397644728597} \n",
      "\n",
      "reward:  {'agent-0': 1.3089690353038517, 'agent-1': -0.5499398907104265, 'agent-2': -0.8780145173195493, 'agent-3': -0.5653120678332932} \n",
      "\n",
      "reward:  {'agent-0': 0.6850942029657077, 'agent-1': -1.1506463985855717, 'agent-2': 0.8343613449095386, 'agent-3': 0.8888159842431982} \n",
      "\n",
      "reward:  {'agent-0': -0.9886887977207603, 'agent-1': -1.2236720730254618, 'agent-2': 0.5772964236917986, 'agent-3': -0.5159284922709766} \n",
      "\n",
      "reward:  {'agent-0': -0.4873447872685617, 'agent-1': -0.8863224405434806, 'agent-2': 0.6930595200979184, 'agent-3': -0.8635207680819619} \n",
      "\n",
      "reward:  {'agent-0': -0.40357159960400146, 'agent-1': -0.5816512303327102, 'agent-2': 0.10498795250208559, 'agent-3': 0.4849520955299802} \n",
      "\n",
      "reward:  {'agent-0': 0.29533716072333505, 'agent-1': 0.7284283068920558, 'agent-2': -0.5246571443160235, 'agent-3': -0.8647612373898852} \n",
      "\n",
      "reward:  {'agent-0': 0.5794318020818565, 'agent-1': -1.5976656559812525, 'agent-2': -0.10927557421231171, 'agent-3': -1.270043388868359} \n",
      "\n",
      "reward:  {'agent-0': -0.16564736915210077, 'agent-1': -0.2755096929243024, 'agent-2': -1.0826223230400487, 'agent-3': -0.8209459268407961} \n",
      "\n",
      "reward:  {'agent-0': -0.5460483636970199, 'agent-1': -1.0096270022443434, 'agent-2': -0.4403467603197413, 'agent-3': -0.12864694619148764} \n",
      "\n",
      "reward:  {'agent-0': -0.7388694875770252, 'agent-1': -0.4904689290469264, 'agent-2': -0.9880959029949281, 'agent-3': -0.856904841201235} \n",
      "\n",
      "reward:  {'agent-0': 0.03370729690511354, 'agent-1': -0.5121243150630335, 'agent-2': -0.9582514325339844, 'agent-3': -0.531243799103585} \n",
      "\n",
      "reward:  {'agent-0': -0.8699328076063892, 'agent-1': 0.6485633303890879, 'agent-2': -0.9447602370758688, 'agent-3': -0.5796850899465511} \n",
      "\n",
      "reward:  {'agent-0': -0.7196574046558197, 'agent-1': 1.7147166589629705, 'agent-2': 0.3791945238028376, 'agent-3': 1.5034957894444325} \n",
      "\n",
      "reward:  {'agent-0': -0.13127927854030297, 'agent-1': -1.7972437713174827, 'agent-2': 0.8714965284212113, 'agent-3': -0.5133569396875259} \n",
      "\n",
      "reward:  {'agent-0': -0.8848118420795537, 'agent-1': 0.4976199000761312, 'agent-2': -1.0262857662417844, 'agent-3': -0.931993064596476} \n",
      "\n",
      "reward:  {'agent-0': 1.7825119868928763, 'agent-1': 0.1756741581289134, 'agent-2': 1.4791241602003424, 'agent-3': 0.334305068825401} \n",
      "\n",
      "reward:  {'agent-0': 0.6887006616876725, 'agent-1': -1.686959891534734, 'agent-2': -0.5064661674927606, 'agent-3': -0.5572475070438436} \n",
      "\n",
      "reward:  {'agent-0': -0.7288975470728651, 'agent-1': -0.7454351537991357, 'agent-2': -1.1602320563386925, 'agent-3': -1.0077808981923155} \n",
      "\n",
      "reward:  {'agent-0': 1.078410817497634, 'agent-1': -0.36338623882234344, 'agent-2': -0.4807628542165787, 'agent-3': 0.6748427583461165} \n",
      "\n",
      "reward:  {'agent-0': 0.44099054553777606, 'agent-1': -0.9979100629071951, 'agent-2': -0.3941439512146232, 'agent-3': -0.21525479043242157} \n",
      "\n",
      "reward:  {'agent-0': 0.013509540448161772, 'agent-1': 0.2719203690071481, 'agent-2': -0.9579887541775847, 'agent-3': 1.5332482459848293} \n",
      "\n",
      "reward:  {'agent-0': 0.9796229057423353, 'agent-1': 0.9327485382880099, 'agent-2': 1.673043065701144, 'agent-3': 0.6697331797152586} \n",
      "\n",
      "reward:  {'agent-0': -0.024855926596565325, 'agent-1': -1.4401670433626563, 'agent-2': 0.06329295554697723, 'agent-3': 0.6983865420180173} \n",
      "\n",
      "reward:  {'agent-0': -0.08003997446683542, 'agent-1': -0.5263832320743802, 'agent-2': -0.2475952951011351, 'agent-3': -0.7430407034333548} \n",
      "\n",
      "reward:  {'agent-0': -0.5850108188365137, 'agent-1': -1.4502382636658808, 'agent-2': -1.0169429398028242, 'agent-3': -0.6039049475235672} \n",
      "\n",
      "reward:  {'agent-0': 0.3968024518090498, 'agent-1': -2.321551815576747, 'agent-2': 0.5071850334964481, 'agent-3': 0.30412984402421017} \n",
      "\n",
      "reward:  {'agent-0': -0.18332038311255516, 'agent-1': -2.2430721787955434, 'agent-2': 0.7555579634679432, 'agent-3': 1.0001352990345609} \n",
      "\n",
      "reward:  {'agent-0': 0.15542445456977383, 'agent-1': 0.962704861638187, 'agent-2': -0.36159899898489556, 'agent-3': 1.4347510072656036} \n",
      "\n",
      "reward:  {'agent-0': -0.040675895101875525, 'agent-1': 0.3351877422442371, 'agent-2': 0.8526857327904693, 'agent-3': 2.075154180736355} \n",
      "\n",
      "reward:  {'agent-0': 0.07167920918725912, 'agent-1': -0.7123823702036276, 'agent-2': -0.8147954476461265, 'agent-3': -0.02504986963538869} \n",
      "\n",
      "reward:  {'agent-0': -0.7156372723232192, 'agent-1': -0.9100531679577557, 'agent-2': 0.24969510232156011, 'agent-3': -1.1570687596437068} \n",
      "\n",
      "reward:  {'agent-0': 0.8312983066128723, 'agent-1': -1.1071600926624257, 'agent-2': 0.46708001466579674, 'agent-3': -0.8084046703047321} \n",
      "\n",
      "reward:  {'agent-0': 0.4152302351208803, 'agent-1': -0.11474296072002232, 'agent-2': 1.1487926477924404, 'agent-3': -0.7957892072949235} \n",
      "\n",
      "reward:  {'agent-0': -0.888207592092435, 'agent-1': 1.1164493334925965, 'agent-2': -0.9514478295586883, 'agent-3': 0.5748814936257887} \n",
      "\n",
      "reward:  {'agent-0': 0.28170015706141527, 'agent-1': -1.0289485111769636, 'agent-2': 0.03190583545651293, 'agent-3': -0.9093744682342724} \n",
      "\n",
      "reward:  {'agent-0': 1.5220733917097355, 'agent-1': -1.6276772413840916, 'agent-2': -1.0258800180785883, 'agent-3': -0.9153970182168862} \n",
      "\n",
      "reward:  {'agent-0': -0.8992919073658463, 'agent-1': 0.5033504863255445, 'agent-2': 0.19470295028244067, 'agent-3': -0.8719931098209841} \n",
      "\n",
      "reward:  {'agent-0': -0.9510854896129501, 'agent-1': -0.36922772543680793, 'agent-2': -1.5517799909647039, 'agent-3': 0.24009292756593226} \n",
      "\n",
      "reward:  {'agent-0': -0.8769800174263125, 'agent-1': -2.3571242628172584, 'agent-2': -1.644218115507691, 'agent-3': -0.6134600625208648} \n",
      "\n",
      "reward:  {'agent-0': 0.34761824461125457, 'agent-1': -1.3558344825377446, 'agent-2': -0.9405062246903171, 'agent-3': -1.217283456804715} \n",
      "\n",
      "reward:  {'agent-0': -0.1504929445283807, 'agent-1': -0.6883321508362883, 'agent-2': -1.010428722948845, 'agent-3': -0.9480936568409497} \n",
      "\n",
      "reward:  {'agent-0': -0.40841717820750034, 'agent-1': -1.4459079311778353, 'agent-2': -1.240573525757739, 'agent-3': -1.336862307282992} \n",
      "\n",
      "reward:  {'agent-0': -0.551432004874993, 'agent-1': -0.36775885755169213, 'agent-2': -0.1565481694063493, 'agent-3': 0.9613318326777076} \n",
      "\n",
      "reward:  {'agent-0': -0.16277593101171917, 'agent-1': -0.4024459086778478, 'agent-2': -1.6111579267960252, 'agent-3': -0.5287452462046289} \n",
      "\n",
      "reward:  {'agent-0': -0.9420035747144269, 'agent-1': 1.1982079383978288, 'agent-2': -0.4867185151680147, 'agent-3': -0.12825451303780255} \n",
      "\n",
      "reward:  {'agent-0': -0.013241721822929264, 'agent-1': -1.3525287640332238, 'agent-2': 0.06011905241551574, 'agent-3': 0.29084984093681143} \n",
      "\n",
      "reward:  {'agent-0': -0.06935293828399836, 'agent-1': -0.02873083403952137, 'agent-2': -0.9574407451304836, 'agent-3': -0.11782201778559198} \n",
      "\n",
      "reward:  {'agent-0': -0.8730355836346462, 'agent-1': 0.5008251703920052, 'agent-2': -0.33180369731855563, 'agent-3': -0.8316325069171313} \n",
      "\n",
      "reward:  {'agent-0': -0.8822394552486799, 'agent-1': -1.2064396778222104, 'agent-2': -1.051510146480183, 'agent-3': -0.3844068883843228} \n",
      "\n",
      "reward:  {'agent-0': -0.044390714133818676, 'agent-1': 0.3391406621803412, 'agent-2': -0.9767957131518727, 'agent-3': -0.8320093042334236} \n",
      "\n",
      "reward:  {'agent-0': -0.2602624851919728, 'agent-1': -0.7397524020540374, 'agent-2': 0.421063746725423, 'agent-3': 0.5790311193349282} \n",
      "\n",
      "reward:  {'agent-0': -0.8289175528760495, 'agent-1': -0.42941153082803396, 'agent-2': -1.0168845566834932, 'agent-3': -1.3648252854922305} \n",
      "\n",
      "reward:  {'agent-0': -0.48682313691891466, 'agent-1': 0.2675465271644981, 'agent-2': -1.536835385216314, 'agent-3': 0.5305909320928315} \n",
      "\n",
      "reward:  {'agent-0': 0.38390916136901154, 'agent-1': 0.12138648463978541, 'agent-2': -1.2704777638270173, 'agent-3': 0.6710654719737263} \n",
      "\n",
      "reward:  {'agent-0': 0.12368295425315878, 'agent-1': -0.8859706121267763, 'agent-2': -0.2535316575281499, 'agent-3': -0.29503459626505446} \n",
      "\n",
      "reward:  {'agent-0': -0.7039388477253326, 'agent-1': -0.9427694333580234, 'agent-2': -0.5447017232806317, 'agent-3': -0.2782016396025213} \n",
      "\n",
      "reward:  {'agent-0': 0.37413416417854606, 'agent-1': -2.624833630260653, 'agent-2': 0.052971667075595974, 'agent-3': -0.3209082606954965} \n",
      "\n",
      "reward:  {'agent-0': -0.9676978367283411, 'agent-1': -0.2809432660315281, 'agent-2': -0.7674375219469738, 'agent-3': -0.7518280712519143} \n",
      "\n",
      "reward:  {'agent-0': -0.938069939037323, 'agent-1': 1.1963401847950408, 'agent-2': -1.0488456882684005, 'agent-3': -0.7858433980628057} \n",
      "\n",
      "reward:  {'agent-0': 1.3881461905692163, 'agent-1': -0.3263336165842219, 'agent-2': 0.5271507363851455, 'agent-3': 1.155132092032396} \n",
      "\n",
      "reward:  {'agent-0': -0.7666624372374233, 'agent-1': -0.6234585288686532, 'agent-2': 0.8572344121125468, 'agent-3': -0.8418873980668877} \n",
      "\n",
      "reward:  {'agent-0': 0.7102949925679951, 'agent-1': -0.050970577655697014, 'agent-2': -1.4142488857895614, 'agent-3': -0.9836121982576884} \n",
      "\n",
      "reward:  {'agent-0': -1.1012912646615582, 'agent-1': 0.07791780777084512, 'agent-2': -0.07792075009286492, 'agent-3': -0.15462587637715686} \n",
      "\n",
      "reward:  {'agent-0': -0.7914379002964935, 'agent-1': -0.9633582964424008, 'agent-2': -0.5231677565475792, 'agent-3': -0.6103565585320254} \n",
      "\n",
      "reward:  {'agent-0': -0.9834386135615034, 'agent-1': -0.9951102696231118, 'agent-2': 0.03149521327202365, 'agent-3': 2.3983836193317956} \n",
      "\n",
      "reward:  {'agent-0': -0.8244767915520299, 'agent-1': -1.199656602613942, 'agent-2': -0.19822622150836366, 'agent-3': -0.1741107204866701} \n",
      "\n",
      "reward:  {'agent-0': 0.969536493708901, 'agent-1': -2.8781724807422577, 'agent-2': 0.39632742328106474, 'agent-3': -0.6527497405322613} \n",
      "\n",
      "reward:  {'agent-0': -0.8319650360545623, 'agent-1': -1.4998037238715227, 'agent-2': -0.6516144641246058, 'agent-3': -1.3972869126010536} \n",
      "\n",
      "reward:  {'agent-0': -1.6458624355283895, 'agent-1': 0.5620629126333654, 'agent-2': -0.8833499576434249, 'agent-3': -0.7158592205865659} \n",
      "\n",
      "reward:  {'agent-0': -0.7729767590039387, 'agent-1': -1.6835955452307445, 'agent-2': -0.33364999860150846, 'agent-3': 0.13254420747386675} \n",
      "\n",
      "reward:  {'agent-0': 0.07443694117498723, 'agent-1': -0.5786663275340942, 'agent-2': -0.9987966182375914, 'agent-3': 0.6737449381885199} \n",
      "\n",
      "reward:  {'agent-0': -0.6779353547073992, 'agent-1': -0.9154499336541448, 'agent-2': -1.0075161463675428, 'agent-3': -0.4877797146168419} \n",
      "\n",
      "reward:  {'agent-0': 0.9207352694098283, 'agent-1': -0.18803951954235743, 'agent-2': -1.6853533028075063, 'agent-3': 0.15227012854852262} \n",
      "\n",
      "reward:  {'agent-0': -0.8937191819352552, 'agent-1': -1.9504383876197835, 'agent-2': 0.47608654436535147, 'agent-3': -1.1262474341755535} \n",
      "\n",
      "reward:  {'agent-0': -0.7619495167169976, 'agent-1': -1.5982046056877905, 'agent-2': -0.9364802777921142, 'agent-3': -0.8382090552286954} \n",
      "\n",
      "reward:  {'agent-0': -1.2747315953644964, 'agent-1': -0.7751336530006583, 'agent-2': -1.1748000204978268, 'agent-3': -1.0295127649925284} \n",
      "\n",
      "reward:  {'agent-0': -0.27652680437877564, 'agent-1': -2.3742956733669587, 'agent-2': 0.3688875886694305, 'agent-3': -0.6310902085768291} \n",
      "\n",
      "reward:  {'agent-0': -0.5509051089620556, 'agent-1': -0.9451878941867022, 'agent-2': -0.9147095243861685, 'agent-3': -0.7608066690588728} \n",
      "\n",
      "reward:  {'agent-0': -0.5408676890246227, 'agent-1': -0.9590700177070062, 'agent-2': -0.15427713103162688, 'agent-3': -0.35808814670380684} \n",
      "\n",
      "reward:  {'agent-0': 1.0090325247644802, 'agent-1': -0.8010379083809482, 'agent-2': -1.1327601591913918, 'agent-3': 1.3107747527776752} \n",
      "\n",
      "reward:  {'agent-0': -0.02389158081766496, 'agent-1': 0.11717063638023717, 'agent-2': 0.48947361157468094, 'agent-3': -0.3430659283652595} \n",
      "\n",
      "reward:  {'agent-0': 0.5174102282407844, 'agent-1': -0.5459304897812132, 'agent-2': 0.7409686829629791, 'agent-3': -0.9972810217546098} \n",
      "\n",
      "reward:  {'agent-0': -0.03871421919778584, 'agent-1': -0.7986433512033386, 'agent-2': -0.9556624897913011, 'agent-3': 1.6882384768728755} \n",
      "\n",
      "reward:  {'agent-0': -0.5753113915317414, 'agent-1': 0.6053828758423379, 'agent-2': -0.9062767422759137, 'agent-3': -0.7299151782917512} \n",
      "\n",
      "reward:  {'agent-0': -0.8708196634590379, 'agent-1': 0.4729250386886861, 'agent-2': -0.016543282811689153, 'agent-3': 0.9203043983847934} \n",
      "\n",
      "reward:  {'agent-0': -0.2456341523910197, 'agent-1': -0.9512498087473347, 'agent-2': -0.9289438663199476, 'agent-3': 1.433940587990449} \n",
      "\n",
      "reward:  {'agent-0': 0.9257965280897125, 'agent-1': -1.3262546787842524, 'agent-2': 1.6588729814184262, 'agent-3': -0.9851350973562489} \n",
      "\n",
      "reward:  {'agent-0': 0.3975462242409922, 'agent-1': 0.15303607948136744, 'agent-2': -2.1502314248396104, 'agent-3': -0.9854850929001131} \n",
      "\n",
      "reward:  {'agent-0': 1.3871598803200413, 'agent-1': -1.1074158072911615, 'agent-2': 0.5505296493214757, 'agent-3': -0.47822750544409587} \n",
      "\n",
      "reward:  {'agent-0': 1.354429983027977, 'agent-1': -1.0146012044163797, 'agent-2': -0.816457183524669, 'agent-3': 0.9559141236664814} \n",
      "\n",
      "reward:  {'agent-0': 1.3916251826451642, 'agent-1': 1.719450711579256, 'agent-2': -0.05770192756482828, 'agent-3': -0.9939138988926928} \n",
      "\n",
      "reward:  {'agent-0': 0.05640217026957828, 'agent-1': -1.6122944219688335, 'agent-2': -0.23288973234731714, 'agent-3': 0.2415103094126394} \n",
      "\n",
      "reward:  {'agent-0': -0.5271286702187865, 'agent-1': -1.0067606367581732, 'agent-2': -0.6067982005067876, 'agent-3': -0.33934609750488676} \n",
      "\n",
      "reward:  {'agent-0': -0.8135886268785946, 'agent-1': -1.0358630313319566, 'agent-2': -0.47230376545866903, 'agent-3': -1.2393917322925176} \n",
      "\n",
      "reward:  {'agent-0': 0.5733859762566667, 'agent-1': -0.6913118360795352, 'agent-2': -0.7131794736994124, 'agent-3': 0.9806292549447484} \n",
      "\n",
      "reward:  {'agent-0': -0.37703620130004367, 'agent-1': -1.4598964848474196, 'agent-2': -0.6587059666195927, 'agent-3': 1.2191545505117745} \n",
      "\n",
      "reward:  {'agent-0': 0.08686089929697083, 'agent-1': -0.07179469834009922, 'agent-2': -0.1709665804973568, 'agent-3': -0.9490400046513798} \n",
      "\n",
      "reward:  {'agent-0': -0.20991326567175683, 'agent-1': -0.12882728132811394, 'agent-2': -0.8748612311473849, 'agent-3': 1.7056213102896187} \n",
      "\n",
      "reward:  {'agent-0': 0.5206607503103093, 'agent-1': 0.014242782139824328, 'agent-2': -1.2724822702968837, 'agent-3': -0.6080017706101657} \n",
      "\n",
      "reward:  {'agent-0': 0.25680154178360226, 'agent-1': 0.06784794000136429, 'agent-2': -0.7884503190128811, 'agent-3': 0.36217599724229643} \n",
      "\n",
      "reward:  {'agent-0': -0.9401366890304956, 'agent-1': -0.7744184209353193, 'agent-2': -0.9066812991583291, 'agent-3': -0.9182595476902584} \n",
      "\n",
      "reward:  {'agent-0': -0.08660625213080309, 'agent-1': -0.8560658362895026, 'agent-2': 0.8178663229228533, 'agent-3': -0.7533744192660627} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 16:18:13,447\tERROR actor_manager.py:519 -- Ray error, taking actor 4 out of service. The actor 8b2935e68f5ea61eee49c2c501000000 is unavailable: The actor is temporarily unavailable: IOError: The actor is restarting.. The task may or maynot have been executed on the actor.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainin_steps):\n\u001b[0;32m---> 38\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     clear_output()\n\u001b[1;32m     40\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sac_result_format(result) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:328\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:873\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    863\u001b[0m     (\n\u001b[1;32m    864\u001b[0m         train_results,\n\u001b[1;32m    865\u001b[0m         eval_results,\n\u001b[1;32m    866\u001b[0m         train_iter_ctx,\n\u001b[1;32m    867\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 873\u001b[0m     train_results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:3152\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train_iter_ctx\u001b[38;5;241m.\u001b[39mshould_stop(results):\n\u001b[1;32m   3150\u001b[0m     \u001b[38;5;66;03m# Before training step, try to bring failed workers back.\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[RESTORE_WORKERS_TIMER]:\n\u001b[0;32m-> 3152\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3154\u001b[0m     \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_STEP_TIMER]:\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:1554\u001b[0m, in \u001b[0;36mAlgorithm.restore_workers\u001b[0;34m(self, workers)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;66;03m# This is really cheap, since probe_unhealthy_workers() is a no-op\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;66;03m# if there are no unhealthy workers.\u001b[39;00m\n\u001b[0;32m-> 1554\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe_unhealthy_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m restored:\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# Count the restored workers.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_num_restored_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(restored)\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:1078\u001b[0m, in \u001b[0;36mEnvRunnerGroup.probe_unhealthy_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;129m@DeveloperAPI\u001b[39m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprobe_unhealthy_workers\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks for unhealthy workers and tries restoring their states.\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m        List of IDs of the workers that were restored.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe_unhealthy_actors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_runner_health_probe_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:859\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.probe_unhealthy_actors\u001b[0;34m(self, timeout_seconds, mark_healthy)\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m restored_actors\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# Some unhealthy actors -> `ping()` all of them to trigger a new fetch and\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;66;03m# capture all restored ones.\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munhealthy_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We specifically want to ping unhealthy actors.\u001b[39;49;00m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Return previously restored actors AND actors restored via the `ping()` call.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restored_actors \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m    869\u001b[0m     result\u001b[38;5;241m.\u001b[39mactor_id \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m remote_results \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mok\n\u001b[1;32m    870\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:622\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    616\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[1;32m    617\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    618\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    619\u001b[0m )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:476\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[0;32m--> 476\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rayEnv/lib/python3.11/site-packages/ray/_private/worker.py:2854\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2852\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2853\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2854\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gymnasium.wrappers.time_limit import TimeLimit\n",
    "\n",
    "trainin_steps = 45\n",
    "\n",
    "algo = (\n",
    "    SACConfig()\n",
    "    .rollouts(\n",
    "        num_rollout_workers=4,  # Number of parallel workers\n",
    "        create_env_on_local_worker=False,\n",
    "        rollout_fragment_length=1,\n",
    "        batch_mode='truncate_episodes'\n",
    "    )\n",
    "    .training(\n",
    "        gamma=0.99,  # Discount factor\n",
    "        train_batch_size=512,  # Training batch size\n",
    "        optimizer={\"actor_lr\": 3e-4, \"critic_lr\": 3e-4, \"entropy_lr\": 3e-4},\n",
    "        tau=0.005,  # Target smoothing coefficient\n",
    "        target_network_update_freq=1,  # Frequency of target network updates\n",
    "        replay_buffer_config={\n",
    "            \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n",
    "            \"prioritized_replay_alpha\": 0.6,\n",
    "            \"prioritized_replay_beta\": 0.4,\n",
    "            \"prioritized_replay_eps\": 1e-6,\n",
    "        }\n",
    "    )\n",
    "    .env_runners(num_env_runners=4)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"collect_the_items?visible_nbrs=3&visible_targets=3&cache_size=3&algo=SAC\")\n",
    "    .build()\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "out = \"\"\n",
    "for i in range(trainin_steps):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += sac_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    simulate_episode(RenderableKeepTheDistance(env_config), algo, 500, sleep_between_frames=0.01, print_reward=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
