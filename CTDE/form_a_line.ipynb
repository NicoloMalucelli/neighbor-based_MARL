{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form a Line\n",
    "\n",
    "an agent is randomly nominated line leader and the other agents have to arrange themselves to form a line having as center the leader agent\n",
    "\n",
    "observation: \n",
    "- the relative position from the leader\n",
    "- the relative position from the leftmost member of the line\n",
    "- the relative position from the rightmost member of the line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vectors import Vector2D\n",
    "from utils.canvas import CanvasWithBorders\n",
    "from utils.algo_utils import (save_algo, load_algo)\n",
    "from utils.simulations import (simulate_episode, simulate_random_episode, ppo_result_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "import random as rnd\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiDiscrete\n",
    "from gymnasium.spaces.utils import flatten, flatten_space\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "\n",
    "class EnvironmentConfiguration: \n",
    "    def __init__(self, n_agents, collision_radius, spawn_area=100, max_steps=None):\n",
    "        self.n_agents = n_agents\n",
    "        self.max_steps = max_steps\n",
    "        self.spawn_area = spawn_area\n",
    "        self.collision_radius = collision_radius\n",
    "\n",
    "class FormALine(MultiAgentEnv):\n",
    "    canvas = None\n",
    "    CANVAS_WIDTH, CANVAS_HEIGHT = 300.0, 300.0\n",
    "    LINE_TOLLERANCE_Y = 1\n",
    "    LINE_TOLLERANCE_X = 5\n",
    "\n",
    "    def __init__(self, config: EnvironmentConfiguration):\n",
    "        self.n_agents = config.n_agents\n",
    "        self.collision_radius = config.collision_radius\n",
    "        self.max_steps = config.max_steps\n",
    "        self.spawn_area = config.spawn_area\n",
    "\n",
    "        self.agents_ids = ['agent-' + str(i) for i in range(self.n_agents)]\n",
    "        self.agent_colors = {agent: self.rgb_to_hex(rnd.randint(0, 255), rnd.randint(0, 255), rnd.randint(0, 255)) for agent in self.agents_ids}\n",
    "        self.observation_space = self.observation_space('agent-0')\n",
    "        self.action_space = self.action_space(\"\")\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.steps = 0\n",
    "        self.agents_pos = {agent: Vector2D.get_random_point(max_x=self.spawn_area, max_y=self.spawn_area) for agent in self.agents_ids}\n",
    "        self.leader = 'agent-0'\n",
    "        self.distance_from_line = {agent: abs(self.agents_pos[self.leader].y - self.agents_pos[agent].y) \n",
    "                                   for agent in self.__get_other_agents(self.leader)}\n",
    "\n",
    "        return {agent: self.__get_observation(agent) for agent in self.__get_other_agents(self.leader)}, {}\n",
    "    \n",
    "    def unflatten_observation_space(self, agent):\n",
    "        direction = Box(low=-1, high=1, shape=(2,1), dtype=np.float32)\n",
    "        distance = Box(low=-np.inf, high=np.inf, shape=(1,1), dtype=np.float32)\n",
    "        return Dict({member: Dict({'direction': direction, 'distance': distance}) for member in ['leftmost','leader','rightmost']})\n",
    "\n",
    "    def observation_space(self, agent):\n",
    "        return flatten_space(self.unflatten_observation_space(agent))\n",
    "\n",
    "    def action_space(self, agent):\n",
    "        direction = Box(low=-1.0, high=1.0, shape=(2,1), dtype=np.float32)\n",
    "        speed = Box(0.0, 1.0, dtype=np.float32)\n",
    "        return flatten_space(Tuple([direction, speed]))\n",
    "    \n",
    "    def __get_observation(self, agent):\n",
    "        obs = {}\n",
    "        leader_distance_vector = Vector2D.distance_vector(self.agents_pos[self.leader], self.agents_pos[agent])\n",
    "        obs['leftmost'] = {\"direction\": Vector2D(0,0).to_np_array(), \"distance\": 0}\n",
    "        obs['rightmost'] = {\"direction\": Vector2D(0,0).to_np_array(), \"distance\": 0}\n",
    "        obs['leader'] = {\"direction\": Vector2D.unit_vector(leader_distance_vector).to_np_array(), \n",
    "                         \"distance\": np.log(1 + Vector2D.norm(leader_distance_vector))}\n",
    "\n",
    "        return flatten(self.unflatten_observation_space(agent), obs)\n",
    "\n",
    "    def __get_other_agents(self, agent):\n",
    "        return [other for other in self.agents_ids if other != agent]\n",
    "    \n",
    "    def __is_aligned_with_the_leader(self, agent):\n",
    "        leader_pos = self.agents_pos[self.leader]\n",
    "        agent_pos = self.agents_pos[agent]\n",
    "        return abs(agent_pos.y - leader_pos.y) <= self.LINE_TOLLERANCE_Y\n",
    "\n",
    "    def __get_local_reward(self, agent, action):\n",
    "        # reward 0: how much I improved the distance from the agent y\n",
    "        old_distance_from_line = self.distance_from_line[agent]\n",
    "        new_distance_from_line = abs(self.agents_pos[agent].y - self.agents_pos[self.leader].y)\n",
    "        reward_0 = old_distance_from_line - new_distance_from_line \n",
    "        self.distance_from_line[agent] = new_distance_from_line\n",
    "\n",
    "        # reward 1: bonus if is aligned with the leader (linear)\n",
    "        reward_1 = max(0, 1 - new_distance_from_line) \n",
    "\n",
    "        # reward 2: penalize the movement\n",
    "        reward_2 = -action[2]\n",
    "\n",
    "        # reward 3: penalize the movement if the agent is very close to the perfect y\n",
    "        reward_3 = -action[2] if old_distance_from_line <= 0.5 else 0\n",
    "\n",
    "        # reward 4: bonus if the agent is very close to the perfect y\n",
    "        reward_4 = new_distance_from_line == 0 \n",
    "\n",
    "        # reward 5: bonus if is aligned with the leader (exponential)\n",
    "        reward_5 = pow(4, -new_distance_from_line)\n",
    "\n",
    "        # reward 6: punish collisions\n",
    "        reward_6 = sum([1 \n",
    "                    if Vector2D.distance(self.agents_pos[agent], self.agents_pos[other]) <= 2*self.collision_radius \n",
    "                    else 0\n",
    "                    for other in self.__get_other_agents(agent)])\n",
    "\n",
    "        return reward_0 + reward_1 + reward_2/10.0 + reward_5\n",
    "    \n",
    "    def __get_global_reward(self):\n",
    "        return 0\n",
    "    \n",
    "    def __update_agent_position(self, agent, action):\n",
    "        unit_movement = Vector2D(action[0], action[1])\n",
    "        self.agents_pos[agent] = Vector2D.sum(self.agents_pos[agent], Vector2D.mul(unit_movement, action[2]))\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.steps += 1\n",
    "        observations, rewards, terminated, truncated, infos = {}, {}, {}, {}, {}\n",
    "\n",
    "        for agent, action in actions.items():\n",
    "            self.__update_agent_position(agent, action)\n",
    "\n",
    "        for agent, action in actions.items():\n",
    "            observations[agent] = self.__get_observation(agent)\n",
    "            rewards[agent] = self.__get_local_reward(agent, action) + self.__get_global_reward()\n",
    "            terminated[agent] = False\n",
    "            truncated[agent] = False\n",
    "            infos[agent] = {\"dst\": self.distance_from_line[agent]}\n",
    "\n",
    "        truncated['__all__'] = False\n",
    "        if self.max_steps != None and self.steps == self.max_steps:\n",
    "            terminated['__all__'] = True\n",
    "        else:\n",
    "            terminated['__all__'] = False\n",
    "\n",
    "        return observations, rewards, terminated, truncated, infos\n",
    "    \n",
    "    def rgb_to_hex(self, r, g, b):\n",
    "        return f'#{r:02x}{g:02x}{b:02x}'\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def get_agent_ids(self):\n",
    "       return self.agents\n",
    "    \n",
    "\n",
    "class RenderableFormALine(FormALine):\n",
    "    def render(self):\n",
    "        if self.canvas is None:\n",
    "            self.canvas = CanvasWithBorders(width=self.CANVAS_WIDTH, height=self.CANVAS_HEIGHT)\n",
    "            display(self.canvas)\n",
    "        \n",
    "        with hold_canvas():\n",
    "            agent_size = max(self.CANVAS_WIDTH/float(self.spawn_area),1)\n",
    "            collision_radius_size = (self.CANVAS_WIDTH/float(self.spawn_area))*self.collision_radius\n",
    "            top_left = (0.0,0.0)\n",
    "            bottom_right = (self.spawn_area, self.spawn_area)\n",
    "            self.canvas.clear()\n",
    "\n",
    "            for agent in self.agents_ids:\n",
    "                raw_pos = self.agents_pos[agent].to_np_array()\n",
    "                color = self.agent_colors[agent]\n",
    "                \n",
    "                agent_pos_in_frame = [((raw_pos[0]-top_left[0])/(bottom_right[0]-top_left[0]))*self.CANVAS_WIDTH,\n",
    "                            ((raw_pos[1]-top_left[1])/(bottom_right[1]-top_left[1]))*self.CANVAS_HEIGHT,]\n",
    "\n",
    "                self.canvas.fill_style = color\n",
    "                self.canvas.fill_circle(\n",
    "                    agent_pos_in_frame[0],\n",
    "                    agent_pos_in_frame[1],\n",
    "                    agent_size/2.0\n",
    "                )\n",
    "                \n",
    "                self.canvas.stroke_style = \"black\"\n",
    "                self.canvas.stroke_circle(\n",
    "                    agent_pos_in_frame[0],\n",
    "                    agent_pos_in_frame[1],\n",
    "                    agent_size/2.0\n",
    "                )\n",
    "\n",
    "                if self.collision_radius > 0:\n",
    "                    self.canvas.stroke_style = \"red\"\n",
    "                    self.canvas.stroke_circle(\n",
    "                        agent_pos_in_frame[0],\n",
    "                        agent_pos_in_frame[1],\n",
    "                        collision_radius_size\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c5d1d28687444099afd54a04145133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config = EnvironmentConfiguration(n_agents=10, collision_radius=5, max_steps=500, spawn_area=100)\n",
    "env = RenderableFormALine(env_config)\n",
    "\n",
    "env.reset()\n",
    "#env.render()\n",
    "simulate_random_episode(env, 100, print_info=False, sleep_between_frames=0.1)\n",
    "#env.step({'agent-1': (1,1,1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## policy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FormALine_align_y\n",
    "\n",
    "align the agents at the same y as the leader not caring about their x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "env_config = EnvironmentConfiguration(n_agents=2, collision_radius=5, max_steps=500, spawn_area=100)\n",
    "register_env(\"FormALine_align_y\", lambda _: FormALine(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = load_algo(\"FormALine_align_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [61] => episode_reward_mean: 807.2520174006892, episode_len_mean: 500.0, agent_steps_trained: 249856, env_steps_trained: 249856, entropy: 2.915201820929845, learning_rate: 0.0010000000000000005\n",
      "iteration [62] => episode_reward_mean: 806.9810169364544, episode_len_mean: 500.0, agent_steps_trained: 253952, env_steps_trained: 253952, entropy: 3.2331853161255517, learning_rate: 0.0010000000000000005\n",
      "iteration [63] => episode_reward_mean: 810.176767425222, episode_len_mean: 500.0, agent_steps_trained: 258048, env_steps_trained: 258048, entropy: 2.9921262289086976, learning_rate: 0.0010000000000000005\n",
      "iteration [64] => episode_reward_mean: 813.4085314334421, episode_len_mean: 500.0, agent_steps_trained: 262144, env_steps_trained: 262144, entropy: 2.8091236571470897, learning_rate: 0.0010000000000000005\n",
      "iteration [65] => episode_reward_mean: 820.8583668698349, episode_len_mean: 500.0, agent_steps_trained: 266240, env_steps_trained: 266240, entropy: 2.999361576139927, learning_rate: 0.0010000000000000005\n",
      "iteration [66] => episode_reward_mean: 820.0728663950323, episode_len_mean: 500.0, agent_steps_trained: 270336, env_steps_trained: 270336, entropy: 2.785883021851381, learning_rate: 0.0010000000000000005\n",
      "iteration [67] => episode_reward_mean: 824.4071409316614, episode_len_mean: 500.0, agent_steps_trained: 274432, env_steps_trained: 274432, entropy: 2.6101110766331357, learning_rate: 0.0010000000000000005\n",
      "iteration [68] => episode_reward_mean: 825.7564231697612, episode_len_mean: 500.0, agent_steps_trained: 278528, env_steps_trained: 278528, entropy: 2.7904595558842025, learning_rate: 0.0010000000000000005\n",
      "iteration [69] => episode_reward_mean: 823.4398109244992, episode_len_mean: 500.0, agent_steps_trained: 282624, env_steps_trained: 282624, entropy: 3.0028345341483753, learning_rate: 0.0010000000000000005\n",
      "iteration [70] => episode_reward_mean: 827.889817737373, episode_len_mean: 500.0, agent_steps_trained: 286720, env_steps_trained: 286720, entropy: 3.271615184346835, learning_rate: 0.0010000000000000005\n",
      "iteration [71] => episode_reward_mean: 828.4521908097511, episode_len_mean: 500.0, agent_steps_trained: 290816, env_steps_trained: 290816, entropy: 2.8858096559842425, learning_rate: 0.0010000000000000005\n",
      "iteration [72] => episode_reward_mean: 828.9146248844776, episode_len_mean: 500.0, agent_steps_trained: 294912, env_steps_trained: 294912, entropy: 2.812280157705148, learning_rate: 0.0010000000000000005\n",
      "iteration [73] => episode_reward_mean: 831.4716389320223, episode_len_mean: 500.0, agent_steps_trained: 299008, env_steps_trained: 299008, entropy: 2.7378105262915295, learning_rate: 0.0010000000000000005\n",
      "iteration [74] => episode_reward_mean: 835.7272930749247, episode_len_mean: 500.0, agent_steps_trained: 303104, env_steps_trained: 303104, entropy: 2.7335323810577394, learning_rate: 0.0010000000000000005\n",
      "iteration [75] => episode_reward_mean: 839.6777761568316, episode_len_mean: 500.0, agent_steps_trained: 307200, env_steps_trained: 307200, entropy: 2.859557006259759, learning_rate: 0.0010000000000000005\n",
      "iteration [76] => episode_reward_mean: 839.8804363891649, episode_len_mean: 500.0, agent_steps_trained: 311296, env_steps_trained: 311296, entropy: 2.900906021396319, learning_rate: 0.0010000000000000005\n",
      "iteration [77] => episode_reward_mean: 842.7829641407745, episode_len_mean: 500.0, agent_steps_trained: 315392, env_steps_trained: 315392, entropy: 2.800839086373647, learning_rate: 0.0010000000000000005\n",
      "iteration [78] => episode_reward_mean: 843.6434174027797, episode_len_mean: 500.0, agent_steps_trained: 319488, env_steps_trained: 319488, entropy: 2.760371892154217, learning_rate: 0.0010000000000000005\n",
      "iteration [79] => episode_reward_mean: 844.6744043976889, episode_len_mean: 500.0, agent_steps_trained: 323584, env_steps_trained: 323584, entropy: 2.8688588504989943, learning_rate: 0.0010000000000000005\n",
      "iteration [80] => episode_reward_mean: 844.3067677720907, episode_len_mean: 500.0, agent_steps_trained: 327680, env_steps_trained: 327680, entropy: 2.8890069474776587, learning_rate: 0.0010000000000000005\n",
      "iteration [81] => episode_reward_mean: 843.9717581918718, episode_len_mean: 500.0, agent_steps_trained: 331776, env_steps_trained: 331776, entropy: 2.791705605387688, learning_rate: 0.0010000000000000005\n",
      "iteration [82] => episode_reward_mean: 847.1238852412046, episode_len_mean: 500.0, agent_steps_trained: 335872, env_steps_trained: 335872, entropy: 2.7145845353603364, learning_rate: 0.0010000000000000005\n",
      "iteration [83] => episode_reward_mean: 848.5559041021311, episode_len_mean: 500.0, agent_steps_trained: 339968, env_steps_trained: 339968, entropy: 2.874890489131212, learning_rate: 0.0010000000000000005\n",
      "iteration [84] => episode_reward_mean: 850.4207812618945, episode_len_mean: 500.0, agent_steps_trained: 344064, env_steps_trained: 344064, entropy: 2.937834026912848, learning_rate: 0.0010000000000000005\n",
      "iteration [85] => episode_reward_mean: 851.1484024385095, episode_len_mean: 500.0, agent_steps_trained: 348160, env_steps_trained: 348160, entropy: 2.7932509616017343, learning_rate: 0.0010000000000000005\n",
      "iteration [86] => episode_reward_mean: 851.8934311381624, episode_len_mean: 500.0, agent_steps_trained: 352256, env_steps_trained: 352256, entropy: 3.1229836265246074, learning_rate: 0.0010000000000000005\n",
      "iteration [87] => episode_reward_mean: 854.3929207345869, episode_len_mean: 500.0, agent_steps_trained: 356352, env_steps_trained: 356352, entropy: 3.4399774526556333, learning_rate: 0.0010000000000000005\n",
      "iteration [88] => episode_reward_mean: 853.7147292829584, episode_len_mean: 500.0, agent_steps_trained: 360448, env_steps_trained: 360448, entropy: 2.9036293665568036, learning_rate: 0.0010000000000000005\n",
      "iteration [89] => episode_reward_mean: 856.1427883095186, episode_len_mean: 500.0, agent_steps_trained: 364544, env_steps_trained: 364544, entropy: 3.436185387770335, learning_rate: 0.0010000000000000005\n",
      "iteration [90] => episode_reward_mean: 859.6424491927819, episode_len_mean: 500.0, agent_steps_trained: 368640, env_steps_trained: 368640, entropy: 3.4696590453386307, learning_rate: 0.0010000000000000005\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78756eae1bc64601b3c3905263b871f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:  {'agent-1': {'dst': 1.0}}\n",
      "info:  {'agent-1': {'dst': 0.5948020815849304}}\n",
      "info:  {'agent-1': {'dst': 0.03444129228591919}}\n",
      "info:  {'agent-1': {'dst': 0.00013205409049987793}}\n",
      "info:  {'agent-1': {'dst': 0.00013205409049987793}}\n",
      "info:  {'agent-1': {'dst': 0.039071228355169296}}\n",
      "info:  {'agent-1': {'dst': 0.039071228355169296}}\n",
      "info:  {'agent-1': {'dst': 0.5399658419191837}}\n",
      "info:  {'agent-1': {'dst': 0.24049431458115578}}\n",
      "info:  {'agent-1': {'dst': 0.24049431458115578}}\n",
      "info:  {'agent-1': {'dst': 0.24049431458115578}}\n",
      "info:  {'agent-1': {'dst': 0.19005734100937843}}\n",
      "info:  {'agent-1': {'dst': 0.19446153193712234}}\n",
      "info:  {'agent-1': {'dst': 0.19446153193712234}}\n",
      "info:  {'agent-1': {'dst': 0.14852000027894974}}\n",
      "info:  {'agent-1': {'dst': 0.14852000027894974}}\n",
      "info:  {'agent-1': {'dst': 0.14852000027894974}}\n",
      "info:  {'agent-1': {'dst': 0.14852000027894974}}\n",
      "info:  {'agent-1': {'dst': 0.1341201588511467}}\n",
      "info:  {'agent-1': {'dst': 0.1341201588511467}}\n",
      "info:  {'agent-1': {'dst': 0.8658798411488533}}\n",
      "info:  {'agent-1': {'dst': 0.8658798411488533}}\n",
      "info:  {'agent-1': {'dst': 0.6038354709744453}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.4052437022328377}}\n",
      "info:  {'agent-1': {'dst': 0.28185952454805374}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.2885607862845063}}\n",
      "info:  {'agent-1': {'dst': 0.217204668559134}}\n",
      "info:  {'agent-1': {'dst': 0.217204668559134}}\n",
      "info:  {'agent-1': {'dst': 0.217204668559134}}\n",
      "info:  {'agent-1': {'dst': 0.17269731406122446}}\n",
      "info:  {'agent-1': {'dst': 0.17269731406122446}}\n",
      "info:  {'agent-1': {'dst': 0.08476496580988169}}\n",
      "info:  {'agent-1': {'dst': 0.08476496580988169}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.014284334145486355}}\n",
      "info:  {'agent-1': {'dst': 0.33553455118089914}}\n",
      "info:  {'agent-1': {'dst': 0.33553455118089914}}\n",
      "info:  {'agent-1': {'dst': 0.08838380221277475}}\n",
      "info:  {'agent-1': {'dst': 0.08838380221277475}}\n",
      "info:  {'agent-1': {'dst': 0.08838380221277475}}\n",
      "info:  {'agent-1': {'dst': 0.11098962184041739}}\n",
      "info:  {'agent-1': {'dst': 0.11098962184041739}}\n",
      "info:  {'agent-1': {'dst': 0.11098962184041739}}\n",
      "info:  {'agent-1': {'dst': 0.11098962184041739}}\n",
      "info:  {'agent-1': {'dst': 0.11098962184041739}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.006143459118902683}}\n",
      "info:  {'agent-1': {'dst': 0.032861956395208836}}\n",
      "info:  {'agent-1': {'dst': 0.032861956395208836}}\n",
      "info:  {'agent-1': {'dst': 0.032861956395208836}}\n",
      "info:  {'agent-1': {'dst': 0.032861956395208836}}\n",
      "info:  {'agent-1': {'dst': 0.09966217633336782}}\n",
      "info:  {'agent-1': {'dst': 0.09966217633336782}}\n",
      "info:  {'agent-1': {'dst': 0.09966217633336782}}\n",
      "info:  {'agent-1': {'dst': 0.09966217633336782}}\n",
      "info:  {'agent-1': {'dst': 0.09966217633336782}}\n",
      "info:  {'agent-1': {'dst': 0.10209516528993845}}\n",
      "info:  {'agent-1': {'dst': 0.10209516528993845}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.021860667504370213}}\n",
      "info:  {'agent-1': {'dst': 0.019191297702491283}}\n",
      "info:  {'agent-1': {'dst': 0.019191297702491283}}\n",
      "info:  {'agent-1': {'dst': 0.019191297702491283}}\n",
      "info:  {'agent-1': {'dst': 0.019191297702491283}}\n",
      "info:  {'agent-1': {'dst': 0.019191297702491283}}\n",
      "info:  {'agent-1': {'dst': 0.019191297702491283}}\n",
      "info:  {'agent-1': {'dst': 0.19428508263081312}}\n",
      "info:  {'agent-1': {'dst': 0.19428508263081312}}\n",
      "info:  {'agent-1': {'dst': 0.6272003771737218}}\n",
      "info:  {'agent-1': {'dst': 0.6272003771737218}}\n",
      "info:  {'agent-1': {'dst': 0.31479082722216845}}\n",
      "info:  {'agent-1': {'dst': 0.3032200336456299}}\n",
      "info:  {'agent-1': {'dst': 0.3032200336456299}}\n",
      "info:  {'agent-1': {'dst': 0.3032200336456299}}\n",
      "info:  {'agent-1': {'dst': 0.04208984971046448}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n",
      "info:  {'agent-1': {'dst': 0.029452422633767128}}\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gymnasium.wrappers.time_limit import TimeLimit\n",
    "\n",
    "trainin_steps = 90\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "    .training(gamma = 0.95, \n",
    "              lr = 0.001,\n",
    "              train_batch_size = 4096, \n",
    "              sgd_minibatch_size = 256, \n",
    "              num_sgd_iter = 30,\n",
    "              #entropy_coeff=0.005,\n",
    "              )\n",
    "    .env_runners(num_env_runners=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"FormALine_align_y\")\n",
    "    .build()\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "out = \"\"\n",
    "for i in range(trainin_steps):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += ppo_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    simulate_episode(RenderableFormALine(env_config), algo, 200, sleep_between_frames=0.01, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bea2c4aae94e2da37e35765ef62943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_config_2 = EnvironmentConfiguration(n_agents=10, collision_radius=5, max_steps=500, spawn_area=100)\n",
    "simulate_episode(RenderableFormALine(env_config_2), algo, 300, sleep_between_frames=0.01, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Algorithm checkpoint has been created inside directory: 'TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/c/Users/nicol/Desktop/Universit√†/tesi/experiments/RL_experiments/algos/FormALine_align_y), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 11.9410849476854, 'cur_kl_coeff': 2.1624389648437505, 'cur_lr': 0.0010000000000000005, 'total_loss': 2.2055642472124117, 'policy_loss': -0.0021745497370526815, 'vf_loss': 2.177628695395106, 'vf_explained_var': 0.2545866960038741, 'kl': 0.013924137522894852, 'entropy': 3.4696590453386307, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 256.0, 'num_grad_updates_lifetime': 42960.5, 'diff_num_grad_updates_vs_sampler_policy': 239.5}}, 'num_env_steps_sampled': 368640, 'num_env_steps_trained': 368640, 'num_agent_steps_sampled': 368640, 'num_agent_steps_trained': 368640}, 'sampler_results': {'episode_reward_max': 968.7617170922598, 'episode_reward_min': 696.6854573319209, 'episode_reward_mean': 859.6424491927819, 'episode_len_mean': 500.0, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 50000, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [833.205689651777, 965.1155843302474, 872.1020258554294, 825.198171228218, 859.8101536714701, 696.6854573319209, 847.1658069724087, 865.3772355036089, 853.5567605370798, 788.3158372371579, 782.709237533672, 763.3795809915218, 780.7242607623137, 897.1763985084748, 856.787056535915, 938.4859104966476, 881.5753601825338, 882.55187506065, 822.9018342480189, 847.9090573096407, 910.6910556388284, 815.8058966196334, 839.6475021475594, 786.1384759694524, 814.5913683348829, 742.0341966924817, 845.2636508424688, 911.9730343669917, 825.9955709114911, 919.2658903722128, 904.4606876576639, 810.8590680971996, 788.6525910229409, 968.7617170922598, 834.557918798077, 807.9840569682037, 846.3613400550171, 835.2870042234837, 839.8841764419076, 926.8586899215284, 781.632825267427, 945.1586220405958, 829.7768734075489, 826.2015991725351, 859.2905893828483, 763.1173514595141, 886.1485763080767, 916.5030678838983, 955.5880050436529, 880.399225601721, 847.7380902171167, 809.2383355441003, 888.0797315917283, 790.2840660583413, 873.5346668359929, 905.8565542633676, 780.5662351973674, 897.0951954303208, 827.2868507004204, 806.1758028419349, 873.3351141452401, 868.2887349739327, 910.1544624315821, 845.771479585324, 939.4350875760042, 848.0806276681004, 818.2247396103916, 902.6645131717847, 936.744424894742, 907.9291952770424, 941.6523950378588, 822.8422528467855, 900.3646482533026, 889.6264322004806, 807.9821190286026, 828.6908289790122, 811.3740056469416, 909.9617880624801, 880.5397334277701, 887.5765880036381, 903.8628409605735, 831.0695014972544, 828.7503829672482, 802.7875797883765, 835.7050854889505, 952.4950342996669, 963.5167367769961, 799.489833753224, 951.0874209680155, 847.7035599860347, 834.7269400131013, 848.4267871303429, 920.2324543102013, 928.7095748225444, 866.3057607350839, 862.5041967487183, 826.2383347300859, 912.9754923983014, 871.9136509171733, 939.025129793777], 'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.19786175374106724, 'mean_inference_ms': 0.7385441159271476, 'mean_action_processing_ms': 0.13321225340670306, 'mean_env_wait_ms': 0.21342205703369133, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0036211013793945312, 'StateBufferConnector_ms': 0.0030608177185058594, 'ViewRequirementAgentConnector_ms': 0.07476592063903809}, 'num_episodes': 8, 'episode_return_max': 968.7617170922598, 'episode_return_min': 696.6854573319209, 'episode_return_mean': 859.6424491927819}, 'env_runner_results': {'episode_reward_max': 968.7617170922598, 'episode_reward_min': 696.6854573319209, 'episode_reward_mean': 859.6424491927819, 'episode_len_mean': 500.0, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 50000, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [833.205689651777, 965.1155843302474, 872.1020258554294, 825.198171228218, 859.8101536714701, 696.6854573319209, 847.1658069724087, 865.3772355036089, 853.5567605370798, 788.3158372371579, 782.709237533672, 763.3795809915218, 780.7242607623137, 897.1763985084748, 856.787056535915, 938.4859104966476, 881.5753601825338, 882.55187506065, 822.9018342480189, 847.9090573096407, 910.6910556388284, 815.8058966196334, 839.6475021475594, 786.1384759694524, 814.5913683348829, 742.0341966924817, 845.2636508424688, 911.9730343669917, 825.9955709114911, 919.2658903722128, 904.4606876576639, 810.8590680971996, 788.6525910229409, 968.7617170922598, 834.557918798077, 807.9840569682037, 846.3613400550171, 835.2870042234837, 839.8841764419076, 926.8586899215284, 781.632825267427, 945.1586220405958, 829.7768734075489, 826.2015991725351, 859.2905893828483, 763.1173514595141, 886.1485763080767, 916.5030678838983, 955.5880050436529, 880.399225601721, 847.7380902171167, 809.2383355441003, 888.0797315917283, 790.2840660583413, 873.5346668359929, 905.8565542633676, 780.5662351973674, 897.0951954303208, 827.2868507004204, 806.1758028419349, 873.3351141452401, 868.2887349739327, 910.1544624315821, 845.771479585324, 939.4350875760042, 848.0806276681004, 818.2247396103916, 902.6645131717847, 936.744424894742, 907.9291952770424, 941.6523950378588, 822.8422528467855, 900.3646482533026, 889.6264322004806, 807.9821190286026, 828.6908289790122, 811.3740056469416, 909.9617880624801, 880.5397334277701, 887.5765880036381, 903.8628409605735, 831.0695014972544, 828.7503829672482, 802.7875797883765, 835.7050854889505, 952.4950342996669, 963.5167367769961, 799.489833753224, 951.0874209680155, 847.7035599860347, 834.7269400131013, 848.4267871303429, 920.2324543102013, 928.7095748225444, 866.3057607350839, 862.5041967487183, 826.2383347300859, 912.9754923983014, 871.9136509171733, 939.025129793777], 'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.19786175374106724, 'mean_inference_ms': 0.7385441159271476, 'mean_action_processing_ms': 0.13321225340670306, 'mean_env_wait_ms': 0.21342205703369133, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0036211013793945312, 'StateBufferConnector_ms': 0.0030608177185058594, 'ViewRequirementAgentConnector_ms': 0.07476592063903809}, 'num_episodes': 8, 'episode_return_max': 968.7617170922598, 'episode_return_min': 696.6854573319209, 'episode_return_mean': 859.6424491927819}, 'episode_reward_max': 968.7617170922598, 'episode_reward_min': 696.6854573319209, 'episode_reward_mean': 859.6424491927819, 'episode_len_mean': 500.0, 'episodes_this_iter': 8, 'episodes_timesteps_total': 50000, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [833.205689651777, 965.1155843302474, 872.1020258554294, 825.198171228218, 859.8101536714701, 696.6854573319209, 847.1658069724087, 865.3772355036089, 853.5567605370798, 788.3158372371579, 782.709237533672, 763.3795809915218, 780.7242607623137, 897.1763985084748, 856.787056535915, 938.4859104966476, 881.5753601825338, 882.55187506065, 822.9018342480189, 847.9090573096407, 910.6910556388284, 815.8058966196334, 839.6475021475594, 786.1384759694524, 814.5913683348829, 742.0341966924817, 845.2636508424688, 911.9730343669917, 825.9955709114911, 919.2658903722128, 904.4606876576639, 810.8590680971996, 788.6525910229409, 968.7617170922598, 834.557918798077, 807.9840569682037, 846.3613400550171, 835.2870042234837, 839.8841764419076, 926.8586899215284, 781.632825267427, 945.1586220405958, 829.7768734075489, 826.2015991725351, 859.2905893828483, 763.1173514595141, 886.1485763080767, 916.5030678838983, 955.5880050436529, 880.399225601721, 847.7380902171167, 809.2383355441003, 888.0797315917283, 790.2840660583413, 873.5346668359929, 905.8565542633676, 780.5662351973674, 897.0951954303208, 827.2868507004204, 806.1758028419349, 873.3351141452401, 868.2887349739327, 910.1544624315821, 845.771479585324, 939.4350875760042, 848.0806276681004, 818.2247396103916, 902.6645131717847, 936.744424894742, 907.9291952770424, 941.6523950378588, 822.8422528467855, 900.3646482533026, 889.6264322004806, 807.9821190286026, 828.6908289790122, 811.3740056469416, 909.9617880624801, 880.5397334277701, 887.5765880036381, 903.8628409605735, 831.0695014972544, 828.7503829672482, 802.7875797883765, 835.7050854889505, 952.4950342996669, 963.5167367769961, 799.489833753224, 951.0874209680155, 847.7035599860347, 834.7269400131013, 848.4267871303429, 920.2324543102013, 928.7095748225444, 866.3057607350839, 862.5041967487183, 826.2383347300859, 912.9754923983014, 871.9136509171733, 939.025129793777], 'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.19786175374106724, 'mean_inference_ms': 0.7385441159271476, 'mean_action_processing_ms': 0.13321225340670306, 'mean_env_wait_ms': 0.21342205703369133, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0036211013793945312, 'StateBufferConnector_ms': 0.0030608177185058594, 'ViewRequirementAgentConnector_ms': 0.07476592063903809}, 'num_episodes': 8, 'episode_return_max': 968.7617170922598, 'episode_return_min': 696.6854573319209, 'episode_return_mean': 859.6424491927819, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 368640, 'num_agent_steps_trained': 368640, 'num_env_steps_sampled': 368640, 'num_env_steps_trained': 368640, 'num_env_steps_sampled_this_iter': 4096, 'num_env_steps_trained_this_iter': 4096, 'num_env_steps_sampled_throughput_per_sec': 521.0526017221921, 'num_env_steps_trained_throughput_per_sec': 521.0526017221921, 'timesteps_total': 368640, 'num_env_steps_sampled_lifetime': 368640, 'num_agent_steps_sampled_lifetime': 368640, 'num_steps_trained_this_iter': 4096, 'agent_timesteps_total': 368640, 'timers': {'training_iteration_time_ms': 8069.426, 'restore_workers_time_ms': 0.018, 'training_step_time_ms': 8069.373, 'sample_time_ms': 5057.224, 'load_time_ms': 0.763, 'load_throughput': 5367031.923, 'learn_time_ms': 3007.213, 'learn_throughput': 1362.059, 'synch_weights_time_ms': 3.69}, 'counters': {'num_env_steps_sampled': 368640, 'num_env_steps_trained': 368640, 'num_agent_steps_sampled': 368640, 'num_agent_steps_trained': 368640}, 'done': False, 'episodes_total': 737, 'training_iteration': 90, 'trial_id': 'default', 'date': '2024-05-30_14-44-18', 'timestamp': 1717073058, 'time_this_iter_s': 7.864757061004639, 'time_total_s': 766.3723819255829, 'pid': 3943, 'hostname': 'LAPTOP-9AD2MD1C', 'node_ip': '172.23.92.2', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'FormALine_align_y', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.95, 'lr': 0.001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4096, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7ff1615914e0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 256, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 1}, 'time_since_restore': 766.3723819255829, 'iterations_since_restore': 90, 'perf': {'cpu_util_percent': 34.053333333333335, 'ram_util_percent': 70.35333333333331}})'.\n"
     ]
    }
   ],
   "source": [
    "save_algo(algo, \"FormALine_align_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FormALine_align_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 15:09:28,335\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "2024-05-30 15:09:34,533\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "base_algo = load_algo(\"FormALine_align_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "env_config = EnvironmentConfiguration(n_agents=5, collision_radius=5, max_steps=500, spawn_area=100)\n",
    "register_env(\"FormALine_align_x\", lambda _: FormALine(env_config))\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "    .training(gamma = 0.95, \n",
    "              lr = 0.001,\n",
    "              train_batch_size = 4092, \n",
    "              sgd_minibatch_size = 128, \n",
    "              num_sgd_iter = 30,\n",
    "              #entropy_coeff=0.005,\n",
    "              )\n",
    "    .env_runners(num_env_runners=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"FormALine_align_x\")\n",
    "    .build()\n",
    ")\n",
    "clear_output()\n",
    "algo.set_weights(base_algo.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = load_algo(\"FormALine_align_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [1] => episode_reward_mean: 318.20808245314856, episode_len_mean: 500.0, agent_steps_trained: 16368, env_steps_trained: 4092, entropy: 4.285577949513914, learning_rate: 0.0010000000000000005\n",
      "iteration [2] => episode_reward_mean: 493.8949219933791, episode_len_mean: 500.0, agent_steps_trained: 32736, env_steps_trained: 8184, entropy: 4.269192019785483, learning_rate: 0.0010000000000000005\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785b3cf192f44438b20d6812b1837ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CanvasWithBorders(height=300, width=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:  {'agent-1': {'dst': 26.148744836449623}, 'agent-2': {'dst': 54.70322436094284}, 'agent-3': {'dst': 29.0}, 'agent-4': {'dst': 25.584942162036896}}\n",
      "info:  {'agent-1': {'dst': 26.050019294023514}, 'agent-2': {'dst': 53.812951028347015}, 'agent-3': {'dst': 29.01897190697491}, 'agent-4': {'dst': 25.397972285747528}}\n",
      "info:  {'agent-1': {'dst': 25.078371554613113}, 'agent-2': {'dst': 53.812951028347015}, 'agent-3': {'dst': 29.01897190697491}, 'agent-4': {'dst': 24.609527230262756}}\n",
      "info:  {'agent-1': {'dst': 25.078371554613113}, 'agent-2': {'dst': 53.79117308743298}, 'agent-3': {'dst': 28.682591186836362}, 'agent-4': {'dst': 24.609527230262756}}\n",
      "info:  {'agent-1': {'dst': 24.997239738702774}, 'agent-2': {'dst': 53.79117308743298}, 'agent-3': {'dst': 28.26979743130505}, 'agent-4': {'dst': 24.609527230262756}}\n",
      "info:  {'agent-1': {'dst': 24.969401609152555}, 'agent-2': {'dst': 53.894499169662595}, 'agent-3': {'dst': 27.6284326184541}, 'agent-4': {'dst': 25.24173927307129}}\n",
      "info:  {'agent-1': {'dst': 25.01430184021592}, 'agent-2': {'dst': 53.941124675795436}, 'agent-3': {'dst': 27.429237904027104}, 'agent-4': {'dst': 26.03459894657135}}\n",
      "info:  {'agent-1': {'dst': 25.64220357313752}, 'agent-2': {'dst': 54.6910475473851}, 'agent-3': {'dst': 27.158569546416402}, 'agent-4': {'dst': 26.60693669319153}}\n",
      "info:  {'agent-1': {'dst': 25.64220357313752}, 'agent-2': {'dst': 54.51168328337371}, 'agent-3': {'dst': 27.158569546416402}, 'agent-4': {'dst': 26.995135694742203}}\n",
      "info:  {'agent-1': {'dst': 25.88950051739812}, 'agent-2': {'dst': 53.72778755240142}, 'agent-3': {'dst': 27.158569546416402}, 'agent-4': {'dst': 26.73168581724167}}\n",
      "info:  {'agent-1': {'dst': 25.49040501192212}, 'agent-2': {'dst': 54.07708617858589}, 'agent-3': {'dst': 27.158569546416402}, 'agent-4': {'dst': 26.73168581724167}}\n",
      "info:  {'agent-1': {'dst': 26.06946997717023}, 'agent-2': {'dst': 55.07708617858589}, 'agent-3': {'dst': 27.390916677191854}, 'agent-4': {'dst': 26.430188566446304}}\n",
      "info:  {'agent-1': {'dst': 25.977620255202055}, 'agent-2': {'dst': 55.159509716555476}, 'agent-3': {'dst': 27.134370239451528}, 'agent-4': {'dst': 26.52758325636387}}\n",
      "info:  {'agent-1': {'dst': 25.94016507267952}, 'agent-2': {'dst': 55.19188237376511}, 'agent-3': {'dst': 27.915136130526662}, 'agent-4': {'dst': 26.65869103372097}}\n",
      "info:  {'agent-1': {'dst': 25.94016507267952}, 'agent-2': {'dst': 54.19188237376511}, 'agent-3': {'dst': 28.438577802851796}, 'agent-4': {'dst': 26.65869103372097}}\n",
      "info:  {'agent-1': {'dst': 26.399112820625305}, 'agent-2': {'dst': 53.85886132903397}, 'agent-3': {'dst': 28.775792570784688}, 'agent-4': {'dst': 27.27847419679165}}\n",
      "info:  {'agent-1': {'dst': 26.399112820625305}, 'agent-2': {'dst': 54.47177708335221}, 'agent-3': {'dst': 27.95923754759133}, 'agent-4': {'dst': 27.30471165291965}}\n",
      "info:  {'agent-1': {'dst': 26.399112820625305}, 'agent-2': {'dst': 54.017003597691655}, 'agent-3': {'dst': 27.722389431670308}, 'agent-4': {'dst': 27.143250403925776}}\n",
      "info:  {'agent-1': {'dst': 26.296364955604076}, 'agent-2': {'dst': 54.302541675046086}, 'agent-3': {'dst': 27.50553554482758}, 'agent-4': {'dst': 27.08138402737677}}\n",
      "info:  {'agent-1': {'dst': 26.06343073397875}, 'agent-2': {'dst': 54.319006541743875}, 'agent-3': {'dst': 27.523967321962118}, 'agent-4': {'dst': 26.08138402737677}}\n",
      "info:  {'agent-1': {'dst': 26.096802704036236}, 'agent-2': {'dst': 53.866314658895135}, 'agent-3': {'dst': 27.690074261277914}, 'agent-4': {'dst': 26.11566243134439}}\n",
      "info:  {'agent-1': {'dst': 27.086560420691967}, 'agent-2': {'dst': 53.89210095256567}, 'agent-3': {'dst': 27.02448856458068}, 'agent-4': {'dst': 26.06901836208999}}\n",
      "info:  {'agent-1': {'dst': 27.188131019473076}, 'agent-2': {'dst': 53.640276454389095}, 'agent-3': {'dst': 27.02448856458068}, 'agent-4': {'dst': 26.015535613521934}}\n",
      "info:  {'agent-1': {'dst': 27.188131019473076}, 'agent-2': {'dst': 53.59088588133454}, 'agent-3': {'dst': 26.940546665340662}, 'agent-4': {'dst': 26.015535613521934}}\n",
      "info:  {'agent-1': {'dst': 26.852285400032997}, 'agent-2': {'dst': 53.54018400609493}, 'agent-3': {'dst': 26.747552815824747}, 'agent-4': {'dst': 26.156022181734443}}\n",
      "info:  {'agent-1': {'dst': 26.852285400032997}, 'agent-2': {'dst': 53.54018400609493}, 'agent-3': {'dst': 26.876335863023996}, 'agent-4': {'dst': 26.13611294515431}}\n",
      "info:  {'agent-1': {'dst': 26.852285400032997}, 'agent-2': {'dst': 53.58502387627959}, 'agent-3': {'dst': 27.005883995443583}, 'agent-4': {'dst': 25.75457157380879}}\n",
      "info:  {'agent-1': {'dst': 26.38472218811512}, 'agent-2': {'dst': 53.353997360914946}, 'agent-3': {'dst': 26.531699750572443}, 'agent-4': {'dst': 25.523367600515485}}\n",
      "info:  {'agent-1': {'dst': 27.262884989380836}, 'agent-2': {'dst': 53.38435046374798}, 'agent-3': {'dst': 26.090030167251825}, 'agent-4': {'dst': 25.523367600515485}}\n",
      "info:  {'agent-1': {'dst': 26.758153215050697}, 'agent-2': {'dst': 53.79951827228069}, 'agent-3': {'dst': 26.124738089740276}, 'agent-4': {'dst': 25.53212578780949}}\n",
      "info:  {'agent-1': {'dst': 26.249201133847237}, 'agent-2': {'dst': 53.1161355227232}, 'agent-3': {'dst': 26.464389495551586}, 'agent-4': {'dst': 25.645816871896386}}\n",
      "info:  {'agent-1': {'dst': 26.043154016137123}, 'agent-2': {'dst': 53.19252336770296}, 'agent-3': {'dst': 27.035318784415722}, 'agent-4': {'dst': 25.677649719640613}}\n",
      "info:  {'agent-1': {'dst': 25.795914739370346}, 'agent-2': {'dst': 53.19252336770296}, 'agent-3': {'dst': 26.537181548774242}, 'agent-4': {'dst': 25.865571109578013}}\n",
      "info:  {'agent-1': {'dst': 25.795914739370346}, 'agent-2': {'dst': 53.98633302003145}, 'agent-3': {'dst': 26.856217823922634}, 'agent-4': {'dst': 25.865571109578013}}\n",
      "info:  {'agent-1': {'dst': 25.658740609884262}, 'agent-2': {'dst': 53.801133550703526}, 'agent-3': {'dst': 27.523224733769894}, 'agent-4': {'dst': 25.71627208404243}}\n",
      "info:  {'agent-1': {'dst': 25.60974569618702}, 'agent-2': {'dst': 53.57845865935087}, 'agent-3': {'dst': 27.99699743837118}, 'agent-4': {'dst': 25.71627208404243}}\n",
      "info:  {'agent-1': {'dst': 25.60974569618702}, 'agent-2': {'dst': 53.30695008486509}, 'agent-3': {'dst': 27.81070164591074}, 'agent-4': {'dst': 25.71627208404243}}\n",
      "info:  {'agent-1': {'dst': 25.54985363408923}, 'agent-2': {'dst': 53.38200755417347}, 'agent-3': {'dst': 27.81070164591074}, 'agent-4': {'dst': 25.71627208404243}}\n",
      "info:  {'agent-1': {'dst': 24.54985363408923}, 'agent-2': {'dst': 53.38200755417347}, 'agent-3': {'dst': 26.98950807005167}, 'agent-4': {'dst': 25.76000746153295}}\n",
      "info:  {'agent-1': {'dst': 25.3387704603374}, 'agent-2': {'dst': 53.38200755417347}, 'agent-3': {'dst': 27.086619064211845}, 'agent-4': {'dst': 26.626290699467063}}\n",
      "info:  {'agent-1': {'dst': 25.23983820900321}, 'agent-2': {'dst': 53.38200755417347}, 'agent-3': {'dst': 26.860895916819572}, 'agent-4': {'dst': 27.52541478537023}}\n",
      "info:  {'agent-1': {'dst': 25.051722716540098}, 'agent-2': {'dst': 53.38200755417347}, 'agent-3': {'dst': 26.747207015752792}, 'agent-4': {'dst': 27.326224764809012}}\n",
      "info:  {'agent-1': {'dst': 24.681712102144957}, 'agent-2': {'dst': 53.45400221645832}, 'agent-3': {'dst': 26.463621765375137}, 'agent-4': {'dst': 27.288460543379188}}\n",
      "info:  {'agent-1': {'dst': 24.577933568507433}, 'agent-2': {'dst': 53.69438944756985}, 'agent-3': {'dst': 25.91321960091591}, 'agent-4': {'dst': 26.717685034498572}}\n",
      "info:  {'agent-1': {'dst': 24.093826312571764}, 'agent-2': {'dst': 53.69438944756985}, 'agent-3': {'dst': 25.817840605974197}, 'agent-4': {'dst': 26.717685034498572}}\n",
      "info:  {'agent-1': {'dst': 23.69410501793027}, 'agent-2': {'dst': 52.69438944756985}, 'agent-3': {'dst': 25.534281611442566}, 'agent-4': {'dst': 26.71254247846082}}\n",
      "info:  {'agent-1': {'dst': 24.498062301427126}, 'agent-2': {'dst': 52.60409216582775}, 'agent-3': {'dst': 25.373603776097298}, 'agent-4': {'dst': 26.62903202744201}}\n",
      "info:  {'agent-1': {'dst': 24.366397876292467}, 'agent-2': {'dst': 52.392206966876984}, 'agent-3': {'dst': 25.493786051869392}, 'agent-4': {'dst': 25.93590981932357}}\n",
      "info:  {'agent-1': {'dst': 25.06738068535924}, 'agent-2': {'dst': 52.6500064432621}, 'agent-3': {'dst': 26.078153505921364}, 'agent-4': {'dst': 26.435893010813743}}\n",
      "info:  {'agent-1': {'dst': 25.06738068535924}, 'agent-2': {'dst': 52.08445301651955}, 'agent-3': {'dst': 25.997650429606438}, 'agent-4': {'dst': 27.122783910948783}}\n",
      "info:  {'agent-1': {'dst': 25.42556269839406}, 'agent-2': {'dst': 51.976247914135456}, 'agent-3': {'dst': 26.997650429606438}, 'agent-4': {'dst': 27.126667303964496}}\n",
      "info:  {'agent-1': {'dst': 25.51355566456914}, 'agent-2': {'dst': 51.976247914135456}, 'agent-3': {'dst': 26.919248208403587}, 'agent-4': {'dst': 26.35326830856502}}\n",
      "info:  {'agent-1': {'dst': 25.560447707772255}, 'agent-2': {'dst': 51.976247914135456}, 'agent-3': {'dst': 27.62957201898098}, 'agent-4': {'dst': 26.6193216573447}}\n",
      "info:  {'agent-1': {'dst': 25.044347062706947}, 'agent-2': {'dst': 51.96252256445587}, 'agent-3': {'dst': 28.153899416327477}, 'agent-4': {'dst': 26.77905240468681}}\n",
      "info:  {'agent-1': {'dst': 25.094270426779985}, 'agent-2': {'dst': 52.620864210650325}, 'agent-3': {'dst': 27.29359470307827}, 'agent-4': {'dst': 26.03755202703178}}\n",
      "info:  {'agent-1': {'dst': 25.24540438130498}, 'agent-2': {'dst': 52.620864210650325}, 'agent-3': {'dst': 27.54637311398983}, 'agent-4': {'dst': 26.11614960990846}}\n",
      "info:  {'agent-1': {'dst': 25.22094114124775}, 'agent-2': {'dst': 52.242859868332744}, 'agent-3': {'dst': 27.791367515921593}, 'agent-4': {'dst': 26.11614960990846}}\n",
      "info:  {'agent-1': {'dst': 25.272189289331436}, 'agent-2': {'dst': 52.53455853275955}, 'agent-3': {'dst': 27.962378844618797}, 'agent-4': {'dst': 27.11614960990846}}\n",
      "info:  {'agent-1': {'dst': 25.272189289331436}, 'agent-2': {'dst': 52.53455853275955}, 'agent-3': {'dst': 27.962378844618797}, 'agent-4': {'dst': 26.846976494416595}}\n",
      "info:  {'agent-1': {'dst': 25.254576925188303}, 'agent-2': {'dst': 53.526481507346034}, 'agent-3': {'dst': 27.998800456523895}, 'agent-4': {'dst': 27.08151409588754}}\n",
      "info:  {'agent-1': {'dst': 24.84510440006852}, 'agent-2': {'dst': 52.89116304926574}, 'agent-3': {'dst': 27.084607779979706}, 'agent-4': {'dst': 26.931131279096007}}\n",
      "info:  {'agent-1': {'dst': 24.697856966406107}, 'agent-2': {'dst': 52.421869603917}, 'agent-3': {'dst': 27.893218636512756}, 'agent-4': {'dst': 27.31695238314569}}\n",
      "info:  {'agent-1': {'dst': 24.800795320421457}, 'agent-2': {'dst': 52.11274948529899}, 'agent-3': {'dst': 27.893218636512756}, 'agent-4': {'dst': 27.315991184674203}}\n",
      "info:  {'agent-1': {'dst': 24.794024996459484}, 'agent-2': {'dst': 52.04216985963285}, 'agent-3': {'dst': 27.893218636512756}, 'agent-4': {'dst': 27.19326316472143}}\n",
      "info:  {'agent-1': {'dst': 24.794024996459484}, 'agent-2': {'dst': 51.32607673667371}, 'agent-3': {'dst': 27.893218636512756}, 'agent-4': {'dst': 26.85395999904722}}\n",
      "info:  {'agent-1': {'dst': 24.770504098385572}, 'agent-2': {'dst': 50.836578300222754}, 'agent-3': {'dst': 27.22163486480713}, 'agent-4': {'dst': 26.85395999904722}}\n",
      "info:  {'agent-1': {'dst': 24.957711827009916}, 'agent-2': {'dst': 50.69309218786657}, 'agent-3': {'dst': 28.22163486480713}, 'agent-4': {'dst': 27.234540126286447}}\n",
      "info:  {'agent-1': {'dst': 24.949285004287958}, 'agent-2': {'dst': 51.15532370470464}, 'agent-3': {'dst': 28.20578859746456}, 'agent-4': {'dst': 27.234540126286447}}\n",
      "info:  {'agent-1': {'dst': 24.820233080536127}, 'agent-2': {'dst': 51.09487213753164}, 'agent-3': {'dst': 27.57264982163906}, 'agent-4': {'dst': 26.79973845835775}}\n",
      "info:  {'agent-1': {'dst': 25.39089623466134}, 'agent-2': {'dst': 50.61472972296178}, 'agent-3': {'dst': 28.57264982163906}, 'agent-4': {'dst': 26.79973845835775}}\n",
      "info:  {'agent-1': {'dst': 25.39089623466134}, 'agent-2': {'dst': 50.61472972296178}, 'agent-3': {'dst': 27.580829367041588}, 'agent-4': {'dst': 26.79973845835775}}\n",
      "info:  {'agent-1': {'dst': 25.806812439113855}, 'agent-2': {'dst': 50.58128579892218}, 'agent-3': {'dst': 27.580829367041588}, 'agent-4': {'dst': 26.79973845835775}}\n",
      "info:  {'agent-1': {'dst': 26.14401600137353}, 'agent-2': {'dst': 50.58128579892218}, 'agent-3': {'dst': 27.12826730310917}, 'agent-4': {'dst': 27.127106360159814}}\n",
      "info:  {'agent-1': {'dst': 26.13124604243785}, 'agent-2': {'dst': 50.58128579892218}, 'agent-3': {'dst': 27.12059989850968}, 'agent-4': {'dst': 27.127106360159814}}\n",
      "info:  {'agent-1': {'dst': 26.13124604243785}, 'agent-2': {'dst': 50.969929153099656}, 'agent-3': {'dst': 27.47510579507798}, 'agent-4': {'dst': 26.738240501843393}}\n",
      "info:  {'agent-1': {'dst': 26.13124604243785}, 'agent-2': {'dst': 50.89939791150391}, 'agent-3': {'dst': 28.47510579507798}, 'agent-4': {'dst': 25.859726808033884}}\n",
      "info:  {'agent-1': {'dst': 26.140001830644906}, 'agent-2': {'dst': 50.89939791150391}, 'agent-3': {'dst': 28.999520572833717}, 'agent-4': {'dst': 25.801143846474588}}\n",
      "info:  {'agent-1': {'dst': 25.582809385843575}, 'agent-2': {'dst': 50.89939791150391}, 'agent-3': {'dst': 28.999520572833717}, 'agent-4': {'dst': 25.760223641060293}}\n",
      "info:  {'agent-1': {'dst': 25.803479579277337}, 'agent-2': {'dst': 50.89939791150391}, 'agent-3': {'dst': 29.39648589771241}, 'agent-4': {'dst': 25.083962156437337}}\n",
      "info:  {'agent-1': {'dst': 25.18648108560592}, 'agent-2': {'dst': 50.73574978299439}, 'agent-3': {'dst': 29.415413140319288}, 'agent-4': {'dst': 25.083962156437337}}\n",
      "info:  {'agent-1': {'dst': 25.47897466737777}, 'agent-2': {'dst': 50.72303059604019}, 'agent-3': {'dst': 29.24107217695564}, 'agent-4': {'dst': 24.96953411307186}}\n",
      "info:  {'agent-1': {'dst': 25.532737229950726}, 'agent-2': {'dst': 50.1697239568457}, 'agent-3': {'dst': 29.24491777573712}, 'agent-4': {'dst': 24.96953411307186}}\n",
      "info:  {'agent-1': {'dst': 25.532737229950726}, 'agent-2': {'dst': 50.281446068547666}, 'agent-3': {'dst': 29.24491777573712}, 'agent-4': {'dst': 25.43733142223209}}\n",
      "info:  {'agent-1': {'dst': 25.532737229950726}, 'agent-2': {'dst': 50.281446068547666}, 'agent-3': {'dst': 29.549703832017258}, 'agent-4': {'dst': 25.120555146597326}}\n",
      "info:  {'agent-1': {'dst': 25.38601363170892}, 'agent-2': {'dst': 50.281446068547666}, 'agent-3': {'dst': 29.400055404054}, 'agent-4': {'dst': 25.347987501882017}}\n",
      "info:  {'agent-1': {'dst': 25.324963145889342}, 'agent-2': {'dst': 50.281446068547666}, 'agent-3': {'dst': 28.400055404054}, 'agent-4': {'dst': 25.14763744082302}}\n",
      "info:  {'agent-1': {'dst': 25.324963145889342}, 'agent-2': {'dst': 50.39646559860557}, 'agent-3': {'dst': 28.84247853909619}, 'agent-4': {'dst': 25.11734961438924}}\n",
      "info:  {'agent-1': {'dst': 25.324963145889342}, 'agent-2': {'dst': 50.90261489059776}, 'agent-3': {'dst': 29.24611436878331}, 'agent-4': {'dst': 24.11734961438924}}\n",
      "info:  {'agent-1': {'dst': 25.903082543052733}, 'agent-2': {'dst': 50.88534818124026}, 'agent-3': {'dst': 28.39046537433751}, 'agent-4': {'dst': 23.11734961438924}}\n",
      "info:  {'agent-1': {'dst': 26.903082543052733}, 'agent-2': {'dst': 49.97686044406146}, 'agent-3': {'dst': 28.39046537433751}, 'agent-4': {'dst': 23.191456918604672}}\n",
      "info:  {'agent-1': {'dst': 27.08984560612589}, 'agent-2': {'dst': 49.33727590274066}, 'agent-3': {'dst': 28.016885693417862}, 'agent-4': {'dst': 23.172905611805618}}\n",
      "info:  {'agent-1': {'dst': 26.394568630494177}, 'agent-2': {'dst': 48.33727590274066}, 'agent-3': {'dst': 27.969783029751852}, 'agent-4': {'dst': 23.172905611805618}}\n",
      "info:  {'agent-1': {'dst': 26.382683941163123}, 'agent-2': {'dst': 47.754993240348995}, 'agent-3': {'dst': 27.969783029751852}, 'agent-4': {'dst': 23.03322963695973}}\n",
      "info:  {'agent-1': {'dst': 26.382683941163123}, 'agent-2': {'dst': 47.74454216938466}, 'agent-3': {'dst': 27.969783029751852}, 'agent-4': {'dst': 23.03322963695973}}\n",
      "info:  {'agent-1': {'dst': 26.382683941163123}, 'agent-2': {'dst': 47.9009047774598}, 'agent-3': {'dst': 27.182887754635885}, 'agent-4': {'dst': 23.440794366411865}}\n",
      "info:  {'agent-1': {'dst': 26.47174317482859}, 'agent-2': {'dst': 47.78912752401084}, 'agent-3': {'dst': 27.182887754635885}, 'agent-4': {'dst': 23.179488229565322}}\n",
      "info:  {'agent-1': {'dst': 26.42622583080083}, 'agent-2': {'dst': 47.420528705231845}, 'agent-3': {'dst': 26.182887754635885}, 'agent-4': {'dst': 23.042888942174613}}\n",
      "info:  {'agent-1': {'dst': 26.42622583080083}, 'agent-2': {'dst': 47.420528705231845}, 'agent-3': {'dst': 26.182887754635885}, 'agent-4': {'dst': 22.320885005407035}}\n",
      "info:  {'agent-1': {'dst': 26.784719635732472}, 'agent-2': {'dst': 47.861440177075565}, 'agent-3': {'dst': 25.277923605637625}, 'agent-4': {'dst': 22.690824481658638}}\n",
      "info:  {'agent-1': {'dst': 26.784719635732472}, 'agent-2': {'dst': 48.70558595191687}, 'agent-3': {'dst': 25.277923605637625}, 'agent-4': {'dst': 22.41572583001107}}\n",
      "info:  {'agent-1': {'dst': 26.784719635732472}, 'agent-2': {'dst': 48.777185956947505}, 'agent-3': {'dst': 25.68127681990154}, 'agent-4': {'dst': 22.219030800275505}}\n",
      "info:  {'agent-1': {'dst': 26.784719635732472}, 'agent-2': {'dst': 48.777185956947505}, 'agent-3': {'dst': 24.932521782116964}, 'agent-4': {'dst': 22.296918164007366}}\n",
      "info:  {'agent-1': {'dst': 26.81637340877205}, 'agent-2': {'dst': 49.48189048003405}, 'agent-3': {'dst': 24.168529234128073}, 'agent-4': {'dst': 21.44681693147868}}\n",
      "info:  {'agent-1': {'dst': 26.277877987362444}, 'agent-2': {'dst': 49.41845582704991}, 'agent-3': {'dst': 24.150649302871898}, 'agent-4': {'dst': 21.60102895926684}}\n",
      "info:  {'agent-1': {'dst': 26.19243882689625}, 'agent-2': {'dst': 49.71403996925801}, 'agent-3': {'dst': 24.468229198129848}, 'agent-4': {'dst': 22.030030976049602}}\n",
      "info:  {'agent-1': {'dst': 26.19243882689625}, 'agent-2': {'dst': 48.899089383892715}, 'agent-3': {'dst': 24.468229198129848}, 'agent-4': {'dst': 22.334928612224758}}\n",
      "info:  {'agent-1': {'dst': 25.71364222560078}, 'agent-2': {'dst': 48.583110141567886}, 'agent-3': {'dst': 24.468229198129848}, 'agent-4': {'dst': 22.27773444633931}}\n",
      "info:  {'agent-1': {'dst': 25.35758622083813}, 'agent-2': {'dst': 49.15339814405888}, 'agent-3': {'dst': 25.07595964637585}, 'agent-4': {'dst': 22.783844876103103}}\n",
      "info:  {'agent-1': {'dst': 26.158500508405268}, 'agent-2': {'dst': 48.15339814405888}, 'agent-3': {'dst': 25.0462456245441}, 'agent-4': {'dst': 22.783844876103103}}\n",
      "info:  {'agent-1': {'dst': 25.541051999665797}, 'agent-2': {'dst': 49.092764186672866}, 'agent-3': {'dst': 25.575123061658815}, 'agent-4': {'dst': 22.607000696472824}}\n",
      "info:  {'agent-1': {'dst': 25.404537902213633}, 'agent-2': {'dst': 49.03762311767787}, 'agent-3': {'dst': 24.92968522501178}, 'agent-4': {'dst': 22.605027314741164}}\n",
      "info:  {'agent-1': {'dst': 25.404537902213633}, 'agent-2': {'dst': 49.03762311767787}, 'agent-3': {'dst': 25.92968522501178}, 'agent-4': {'dst': 22.77971347840503}}\n",
      "info:  {'agent-1': {'dst': 25.168039322830737}, 'agent-2': {'dst': 48.32440740894526}, 'agent-3': {'dst': 25.363330592634156}, 'agent-4': {'dst': 22.473175134975463}}\n",
      "info:  {'agent-1': {'dst': 25.073967621661723}, 'agent-2': {'dst': 48.32440740894526}, 'agent-3': {'dst': 24.363330592634156}, 'agent-4': {'dst': 22.202257808763534}}\n",
      "info:  {'agent-1': {'dst': 25.29846190009266}, 'agent-2': {'dst': 48.26031618844718}, 'agent-3': {'dst': 23.72213148069568}, 'agent-4': {'dst': 21.51509076030925}}\n",
      "info:  {'agent-1': {'dst': 25.211044357158244}, 'agent-2': {'dst': 48.26031618844718}, 'agent-3': {'dst': 24.522643198492005}, 'agent-4': {'dst': 21.523166827391833}}\n",
      "info:  {'agent-1': {'dst': 25.190382323227823}, 'agent-2': {'dst': 48.26031618844718}, 'agent-3': {'dst': 24.49690362927504}, 'agent-4': {'dst': 21.523166827391833}}\n",
      "info:  {'agent-1': {'dst': 25.190382323227823}, 'agent-2': {'dst': 47.612337107770145}, 'agent-3': {'dst': 24.122624517651275}, 'agent-4': {'dst': 21.546034462284297}}\n",
      "info:  {'agent-1': {'dst': 25.190382323227823}, 'agent-2': {'dst': 47.37709432374686}, 'agent-3': {'dst': 24.404934854479507}, 'agent-4': {'dst': 20.99455464584753}}\n",
      "info:  {'agent-1': {'dst': 25.190382323227823}, 'agent-2': {'dst': 48.11070191394538}, 'agent-3': {'dst': 24.217495740624145}, 'agent-4': {'dst': 21.089167035650462}}\n",
      "info:  {'agent-1': {'dst': 25.321695319376886}, 'agent-2': {'dst': 47.15400647651404}, 'agent-3': {'dst': 24.13308506575413}, 'agent-4': {'dst': 20.794903881382197}}\n",
      "info:  {'agent-1': {'dst': 25.056164703331888}, 'agent-2': {'dst': 47.377334023825824}, 'agent-3': {'dst': 23.97021230426617}, 'agent-4': {'dst': 21.674481577705592}}\n",
      "info:  {'agent-1': {'dst': 25.331736556254327}, 'agent-2': {'dst': 47.323785639368}, 'agent-3': {'dst': 23.20327123370953}, 'agent-4': {'dst': 22.012201852630824}}\n",
      "info:  {'agent-1': {'dst': 25.17205052729696}, 'agent-2': {'dst': 47.051181769929826}, 'agent-3': {'dst': 22.94789915648289}, 'agent-4': {'dst': 21.298499054741114}}\n",
      "info:  {'agent-1': {'dst': 25.122656329534948}, 'agent-2': {'dst': 46.967795117758214}, 'agent-3': {'dst': 22.51311864820309}, 'agent-4': {'dst': 20.882307834457606}}\n",
      "info:  {'agent-1': {'dst': 25.230815215967596}, 'agent-2': {'dst': 47.12544096913189}, 'agent-3': {'dst': 21.51311864820309}, 'agent-4': {'dst': 20.882307834457606}}\n",
      "info:  {'agent-1': {'dst': 25.230815215967596}, 'agent-2': {'dst': 46.6572073539719}, 'agent-3': {'dst': 21.835348033579066}, 'agent-4': {'dst': 20.72726612491533}}\n",
      "info:  {'agent-1': {'dst': 25.230815215967596}, 'agent-2': {'dst': 46.6572073539719}, 'agent-3': {'dst': 21.825723845744506}, 'agent-4': {'dst': 20.72020351095125}}\n",
      "info:  {'agent-1': {'dst': 25.57175876107067}, 'agent-2': {'dst': 47.036867453716695}, 'agent-3': {'dst': 21.13344993093051}, 'agent-4': {'dst': 19.72020351095125}}\n",
      "info:  {'agent-1': {'dst': 24.989178790710866}, 'agent-2': {'dst': 47.036867453716695}, 'agent-3': {'dst': 21.11371561908163}, 'agent-4': {'dst': 19.602576955687255}}\n",
      "info:  {'agent-1': {'dst': 24.300050391815603}, 'agent-2': {'dst': 47.036867453716695}, 'agent-3': {'dst': 20.265947312349454}, 'agent-4': {'dst': 19.602576955687255}}\n",
      "info:  {'agent-1': {'dst': 24.347442413680255}, 'agent-2': {'dst': 46.177193774841726}, 'agent-3': {'dst': 20.078079655999318}, 'agent-4': {'dst': 19.602576955687255}}\n",
      "info:  {'agent-1': {'dst': 25.126701678149402}, 'agent-2': {'dst': 46.177193774841726}, 'agent-3': {'dst': 20.12560572498478}, 'agent-4': {'dst': 18.81792788160965}}\n",
      "info:  {'agent-1': {'dst': 24.126701678149402}, 'agent-2': {'dst': 46.70541806425899}, 'agent-3': {'dst': 20.14713517972268}, 'agent-4': {'dst': 18.53437666548416}}\n",
      "info:  {'agent-1': {'dst': 23.392141724936664}, 'agent-2': {'dst': 46.70541806425899}, 'agent-3': {'dst': 20.167960688704625}, 'agent-4': {'dst': 18.425212405156344}}\n",
      "info:  {'agent-1': {'dst': 23.392141724936664}, 'agent-2': {'dst': 46.75284088682383}, 'agent-3': {'dst': 20.167960688704625}, 'agent-4': {'dst': 18.13763817353174}}\n",
      "info:  {'agent-1': {'dst': 22.392141724936664}, 'agent-2': {'dst': 46.88255281280726}, 'agent-3': {'dst': 20.167960688704625}, 'agent-4': {'dst': 18.48941247863695}}\n",
      "info:  {'agent-1': {'dst': 21.726047362200916}, 'agent-2': {'dst': 46.85181132052094}, 'agent-3': {'dst': 21.167960688704625}, 'agent-4': {'dst': 18.0517875473015}}\n",
      "info:  {'agent-1': {'dst': 21.54715862404555}, 'agent-2': {'dst': 47.428960711695254}, 'agent-3': {'dst': 21.167960688704625}, 'agent-4': {'dst': 18.16016126377508}}\n",
      "info:  {'agent-1': {'dst': 21.58116517867893}, 'agent-2': {'dst': 47.2339493194595}, 'agent-3': {'dst': 21.167960688704625}, 'agent-4': {'dst': 18.16016126377508}}\n",
      "info:  {'agent-1': {'dst': 22.065078153274953}, 'agent-2': {'dst': 47.2339493194595}, 'agent-3': {'dst': 21.507085725897923}, 'agent-4': {'dst': 17.411827869247645}}\n",
      "info:  {'agent-1': {'dst': 22.02375206258148}, 'agent-2': {'dst': 47.91816057357937}, 'agent-3': {'dst': 21.42424799525179}, 'agent-4': {'dst': 17.230057589244097}}\n",
      "info:  {'agent-1': {'dst': 22.093153997324407}, 'agent-2': {'dst': 48.111791581846774}, 'agent-3': {'dst': 21.273490712279454}, 'agent-4': {'dst': 17.630313865374774}}\n",
      "info:  {'agent-1': {'dst': 22.56725652422756}, 'agent-2': {'dst': 47.86425903532654}, 'agent-3': {'dst': 21.223511938238516}, 'agent-4': {'dst': 17.82191639347002}}\n",
      "info:  {'agent-1': {'dst': 22.065429403446615}, 'agent-2': {'dst': 47.86425903532654}, 'agent-3': {'dst': 20.223511938238516}, 'agent-4': {'dst': 17.9794899742119}}\n",
      "info:  {'agent-1': {'dst': 22.065429403446615}, 'agent-2': {'dst': 47.858468401711434}, 'agent-3': {'dst': 20.258565709227696}, 'agent-4': {'dst': 17.9794899742119}}\n",
      "info:  {'agent-1': {'dst': 21.756138487719}, 'agent-2': {'dst': 47.787368963938206}, 'agent-3': {'dst': 20.086276084417477}, 'agent-4': {'dst': 17.9794899742119}}\n",
      "info:  {'agent-1': {'dst': 21.756138487719}, 'agent-2': {'dst': 47.339284907560796}, 'agent-3': {'dst': 21.024560362333432}, 'agent-4': {'dst': 17.700903497170657}}\n",
      "info:  {'agent-1': {'dst': 21.75033295666799}, 'agent-2': {'dst': 47.101154800038785}, 'agent-3': {'dst': 20.981980446958914}, 'agent-4': {'dst': 17.166919908951968}}\n",
      "info:  {'agent-1': {'dst': 21.719687703531235}, 'agent-2': {'dst': 46.23547613201663}, 'agent-3': {'dst': 19.981980446958914}, 'agent-4': {'dst': 17.491951398085803}}\n",
      "info:  {'agent-1': {'dst': 20.897232237737626}, 'agent-2': {'dst': 46.24006165843457}, 'agent-3': {'dst': 19.981980446958914}, 'agent-4': {'dst': 17.599106959532946}}\n",
      "info:  {'agent-1': {'dst': 21.127086225431412}, 'agent-2': {'dst': 46.16908934246749}, 'agent-3': {'dst': 19.850034196162596}, 'agent-4': {'dst': 17.30391912860796}}\n",
      "info:  {'agent-1': {'dst': 21.06415284750983}, 'agent-2': {'dst': 46.17087753827218}, 'agent-3': {'dst': 19.850034196162596}, 'agent-4': {'dst': 17.30391912860796}}\n",
      "info:  {'agent-1': {'dst': 21.006051957141608}, 'agent-2': {'dst': 45.894042484113015}, 'agent-3': {'dst': 19.411457736277953}, 'agent-4': {'dst': 16.983268849086016}}\n",
      "info:  {'agent-1': {'dst': 20.96720254002139}, 'agent-2': {'dst': 45.894042484113015}, 'agent-3': {'dst': 19.411457736277953}, 'agent-4': {'dst': 16.983268849086016}}\n",
      "info:  {'agent-1': {'dst': 21.35988848982379}, 'agent-2': {'dst': 45.894042484113015}, 'agent-3': {'dst': 19.471874118084088}, 'agent-4': {'dst': 16.76110342843458}}\n",
      "info:  {'agent-1': {'dst': 21.343118730466813}, 'agent-2': {'dst': 45.82941941882018}, 'agent-3': {'dst': 20.197196662658826}, 'agent-4': {'dst': 16.76110342843458}}\n",
      "info:  {'agent-1': {'dst': 20.35521412221715}, 'agent-2': {'dst': 45.82941941882018}, 'agent-3': {'dst': 19.197196662658826}, 'agent-4': {'dst': 16.95632008416578}}\n",
      "info:  {'agent-1': {'dst': 20.35521412221715}, 'agent-2': {'dst': 45.82941941882018}, 'agent-3': {'dst': 19.197196662658826}, 'agent-4': {'dst': 16.996151148807257}}\n",
      "info:  {'agent-1': {'dst': 20.27638392476365}, 'agent-2': {'dst': 45.82941941882018}, 'agent-3': {'dst': 19.23919102572836}, 'agent-4': {'dst': 17.00089711882174}}\n",
      "info:  {'agent-1': {'dst': 20.689824867527932}, 'agent-2': {'dst': 45.48255242372397}, 'agent-3': {'dst': 19.48527380847372}, 'agent-4': {'dst': 16.184465358033776}}\n",
      "info:  {'agent-1': {'dst': 21.100145566742867}, 'agent-2': {'dst': 46.221171691664495}, 'agent-3': {'dst': 18.495824724668637}, 'agent-4': {'dst': 16.250510530546308}}\n",
      "info:  {'agent-1': {'dst': 21.04971545888111}, 'agent-2': {'dst': 46.367675304063596}, 'agent-3': {'dst': 18.560389891499653}, 'agent-4': {'dst': 15.944491432979703}}\n",
      "info:  {'agent-1': {'dst': 21.04971545888111}, 'agent-2': {'dst': 45.367675304063596}, 'agent-3': {'dst': 18.70561282359995}, 'agent-4': {'dst': 15.944491432979703}}\n",
      "info:  {'agent-1': {'dst': 21.53072404814884}, 'agent-2': {'dst': 45.367675304063596}, 'agent-3': {'dst': 18.68428622209467}, 'agent-4': {'dst': 15.767920197919011}}\n",
      "info:  {'agent-1': {'dst': 20.883535742294043}, 'agent-2': {'dst': 46.367675304063596}, 'agent-3': {'dst': 17.843187019461766}, 'agent-4': {'dst': 16.044611336663365}}\n",
      "info:  {'agent-1': {'dst': 20.86697014560923}, 'agent-2': {'dst': 46.34809827769641}, 'agent-3': {'dst': 17.843187019461766}, 'agent-4': {'dst': 16.045752784470096}}\n",
      "info:  {'agent-1': {'dst': 21.144682580139488}, 'agent-2': {'dst': 45.82713317836169}, 'agent-3': {'dst': 17.542347237700596}, 'agent-4': {'dst': 15.045752784470096}}\n",
      "info:  {'agent-1': {'dst': 21.144781578477705}, 'agent-2': {'dst': 45.82713317836169}, 'agent-3': {'dst': 17.542347237700596}, 'agent-4': {'dst': 15.67077281163074}}\n",
      "info:  {'agent-1': {'dst': 21.144781578477705}, 'agent-2': {'dst': 45.82713317836169}, 'agent-3': {'dst': 17.718848407501355}, 'agent-4': {'dst': 15.206715991953388}}\n",
      "info:  {'agent-1': {'dst': 21.044423412677133}, 'agent-2': {'dst': 44.82713317836169}, 'agent-3': {'dst': 17.718848407501355}, 'agent-4': {'dst': 15.479005357483402}}\n",
      "info:  {'agent-1': {'dst': 21.919451367255533}, 'agent-2': {'dst': 44.59077548945788}, 'agent-3': {'dst': 17.52524445974268}, 'agent-4': {'dst': 15.861515214899555}}\n",
      "info:  {'agent-1': {'dst': 22.347563605901087}, 'agent-2': {'dst': 43.59077548945788}, 'agent-3': {'dst': 16.52524445974268}, 'agent-4': {'dst': 15.63368964777328}}\n",
      "info:  {'agent-1': {'dst': 22.347563605901087}, 'agent-2': {'dst': 43.59077548945788}, 'agent-3': {'dst': 17.361603901023045}, 'agent-4': {'dst': 15.517798586050048}}\n",
      "info:  {'agent-1': {'dst': 21.81200061380514}, 'agent-2': {'dst': 43.687253124662675}, 'agent-3': {'dst': 16.361603901023045}, 'agent-4': {'dst': 15.974459512392059}}\n",
      "info:  {'agent-1': {'dst': 21.232179802056635}, 'agent-2': {'dst': 43.749961711117066}, 'agent-3': {'dst': 17.010193273657933}, 'agent-4': {'dst': 15.974459512392059}}\n",
      "info:  {'agent-1': {'dst': 20.289346378442133}, 'agent-2': {'dst': 43.749961711117066}, 'agent-3': {'dst': 16.794195637339726}, 'agent-4': {'dst': 15.002910597482696}}\n",
      "info:  {'agent-1': {'dst': 20.289346378442133}, 'agent-2': {'dst': 43.749961711117066}, 'agent-3': {'dst': 16.74440137320198}, 'agent-4': {'dst': 15.002910597482696}}\n",
      "info:  {'agent-1': {'dst': 20.35139862835058}, 'agent-2': {'dst': 43.285695977159776}, 'agent-3': {'dst': 16.517609276110306}, 'agent-4': {'dst': 14.656217916170135}}\n",
      "info:  {'agent-1': {'dst': 20.066155593987787}, 'agent-2': {'dst': 43.285695977159776}, 'agent-3': {'dst': 16.77556661539711}, 'agent-4': {'dst': 14.153660757699981}}\n",
      "info:  {'agent-1': {'dst': 20.726630728837335}, 'agent-2': {'dst': 42.995817429968156}, 'agent-3': {'dst': 16.71414840244688}, 'agent-4': {'dst': 13.39433882967569}}\n",
      "info:  {'agent-1': {'dst': 20.765167404111708}, 'agent-2': {'dst': 42.38966924662236}, 'agent-3': {'dst': 16.998818397754803}, 'agent-4': {'dst': 13.30108772055246}}\n",
      "info:  {'agent-1': {'dst': 20.765167404111708}, 'agent-2': {'dst': 42.48210228199605}, 'agent-3': {'dst': 16.998818397754803}, 'agent-4': {'dst': 14.30108772055246}}\n",
      "info:  {'agent-1': {'dst': 21.515441585477674}, 'agent-2': {'dst': 42.48210228199605}, 'agent-3': {'dst': 16.17253053211607}, 'agent-4': {'dst': 14.277104681590572}}\n",
      "info:  {'agent-1': {'dst': 21.323557663854444}, 'agent-2': {'dst': 42.798827893682756}, 'agent-3': {'dst': 15.17253053211607}, 'agent-4': {'dst': 14.277104681590572}}\n",
      "info:  {'agent-1': {'dst': 21.319007762387628}, 'agent-2': {'dst': 42.322755790897645}, 'agent-3': {'dst': 15.08063042187132}, 'agent-4': {'dst': 14.6061893759761}}\n",
      "info:  {'agent-1': {'dst': 21.759194620564813}, 'agent-2': {'dst': 41.87910438294057}, 'agent-3': {'dst': 14.421107232803479}, 'agent-4': {'dst': 15.57804829464294}}\n",
      "info:  {'agent-1': {'dst': 21.79418409304344}, 'agent-2': {'dst': 42.097470901557244}, 'agent-3': {'dst': 14.07317128800787}, 'agent-4': {'dst': 16.12077129469253}}\n",
      "info:  {'agent-1': {'dst': 21.79418409304344}, 'agent-2': {'dst': 42.097470901557244}, 'agent-3': {'dst': 14.410046220058575}, 'agent-4': {'dst': 16.136268880451098}}\n",
      "info:  {'agent-1': {'dst': 21.201193635031814}, 'agent-2': {'dst': 41.77022021228913}, 'agent-3': {'dst': 14.379974888870493}, 'agent-4': {'dst': 15.98405633517541}}\n",
      "info:  {'agent-1': {'dst': 21.201193635031814}, 'agent-2': {'dst': 41.655502751120366}, 'agent-3': {'dst': 13.585757540771738}, 'agent-4': {'dst': 16.98405633517541}}\n",
      "info:  {'agent-1': {'dst': 21.154026739910478}, 'agent-2': {'dst': 41.43999667430762}, 'agent-3': {'dst': 13.97903953702189}, 'agent-4': {'dst': 16.98405633517541}}\n",
      "info:  {'agent-1': {'dst': 21.0355406931194}, 'agent-2': {'dst': 41.50505300576333}, 'agent-3': {'dst': 13.228901135036722}, 'agent-4': {'dst': 16.551810931647196}}\n",
      "info:  {'agent-1': {'dst': 21.0355406931194}, 'agent-2': {'dst': 41.78771691734437}, 'agent-3': {'dst': 12.725229250499979}, 'agent-4': {'dst': 16.5141618961934}}\n",
      "info:  {'agent-1': {'dst': 21.275067560985917}, 'agent-2': {'dst': 42.05288683588151}, 'agent-3': {'dst': 12.896836685249582}, 'agent-4': {'dst': 16.241339337313548}}\n",
      "info:  {'agent-1': {'dst': 21.48463725359761}, 'agent-2': {'dst': 41.27712260896806}, 'agent-3': {'dst': 12.896836685249582}, 'agent-4': {'dst': 16.138748776400462}}\n",
      "info:  {'agent-1': {'dst': 22.385693304851884}, 'agent-2': {'dst': 41.27712260896806}, 'agent-3': {'dst': 13.70578102977015}, 'agent-4': {'dst': 15.94274539896287}}\n",
      "info:  {'agent-1': {'dst': 22.317520522192353}, 'agent-2': {'dst': 41.27712260896806}, 'agent-3': {'dst': 13.434915499994531}, 'agent-4': {'dst': 16.516599726164714}}\n",
      "info:  {'agent-1': {'dst': 22.406617530301446}, 'agent-2': {'dst': 40.87299128586892}, 'agent-3': {'dst': 13.509283701190725}, 'agent-4': {'dst': 17.324108969653025}}\n",
      "info:  {'agent-1': {'dst': 21.679118045285577}, 'agent-2': {'dst': 40.87299128586892}, 'agent-3': {'dst': 13.509280435480832}, 'agent-4': {'dst': 16.691303860628977}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainin_steps):\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     clear_output()\n\u001b[1;32m     12\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ppo_result_format(result) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py:328\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:873\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    863\u001b[0m     (\n\u001b[1;32m    864\u001b[0m         train_results,\n\u001b[1;32m    865\u001b[0m         eval_results,\n\u001b[1;32m    866\u001b[0m         train_iter_ctx,\n\u001b[1;32m    867\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 873\u001b[0m     train_results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:3156\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_STEP_TIMER]:\n\u001b[0;32m-> 3156\u001b[0m                 results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:428\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_step_new_api_stack()\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# Old and hybrid API stacks (Policy, RolloutWorker, Connector, maybe RLModule,\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# maybe Learner).\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training_step_old_and_hybrid_api_stacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:562\u001b[0m, in \u001b[0;36mPPO._training_step_old_and_hybrid_api_stacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    558\u001b[0m         worker_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers,\n\u001b[1;32m    559\u001b[0m         max_agent_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtotal_train_batch_size,\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mas_multi_agent()\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39magent_steps()\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/execution/rollout_ops.py:97\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat, sample_timeout_s, _uses_new_env_runners, _return_metrics)\u001b[0m\n\u001b[1;32m     94\u001b[0m         stats_dicts \u001b[38;5;241m=\u001b[39m [worker_set\u001b[38;5;241m.\u001b[39mlocal_worker()\u001b[38;5;241m.\u001b[39mget_metrics()]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m \u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_return_metrics\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Nothing was returned (maybe all workers are stalling) or no healthy\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# remote workers left: Break.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampled_data \u001b[38;5;129;01mor\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mnum_healthy_remote_workers() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py:840\u001b[0m, in \u001b[0;36mEnvRunnerGroup.foreach_worker\u001b[0;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_manager\u001b[38;5;241m.\u001b[39mactor_ids():\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m local_result\n\u001b[0;32m--> 840\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m _handle_remote_call_result_errors(\n\u001b[1;32m    850\u001b[0m     remote_results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_env_runner_failures\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:622\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    616\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[1;32m    617\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    618\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    619\u001b[0m )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py:476\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[0;32m--> 476\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tianEnv/lib/python3.11/site-packages/ray/_private/worker.py:2854\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2852\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2853\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2854\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3812\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:571\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from gymnasium.wrappers.time_limit import TimeLimit\n",
    "\n",
    "trainin_steps = 30\n",
    "\n",
    "out = \"\"\n",
    "for i in range(trainin_steps):\n",
    "    result = algo.train()\n",
    "    clear_output()\n",
    "    out += ppo_result_format(result) + \"\\n\"\n",
    "    print(out)\n",
    "    simulate_episode(RenderableFormALine(env_config), algo, 200, sleep_between_frames=0.01, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
